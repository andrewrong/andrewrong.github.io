<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>nomoshen</title>
  <subtitle>尽可能努力一点点</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2020-07-06T07:51:32.698Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>nomoshen</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>LevelDB源码(四、leveldb open流程)</title>
    <link href="http://yoursite.com/2020/07/06/LevelDB%E6%BA%90%E7%A0%81-%E5%9B%9B%E3%80%81leveldb-open%E6%B5%81%E7%A8%8B/"/>
    <id>http://yoursite.com/2020/07/06/LevelDB源码-四、leveldb-open流程/</id>
    <published>2020-07-06T03:15:42.000Z</published>
    <updated>2020-07-06T07:51:32.698Z</updated>
    
    <content type="html"><![CDATA[<p>终于到了正常讲流程的，对于leveldb来说，让我来看最主要的几个关键点在于：</p>
<ul>
<li>打开leveldb的过程；涉及到了数据如何从文件中恢复回来的问题；</li>
<li>write流程</li>
<li>open流程</li>
<li>compaction</li>
<li>版本管理</li>
</ul>
<p>今天这文章主要讲到的是db open的流程，这个过程中会涉及到很多的相关的组建，靠着这些组件才能保证持久化数据的完整性; 对leveldb的文件进行分类并且的功能介绍：</p>
<ul>
<li>sstable: 数据持久化,真正用来存储数据</li>
<li>manifest: 所有的version、versionEdit都会按照顺序写入到这个文件中；</li>
<li>WAL: 以log为结尾，wal日志，顺序写，保证数据恢复使用;</li>
<li>CURRENT: 里面记录了当前真正在使用的manifest</li>
<li>LOCK：文件锁</li>
<li>LOG.*: 表示日志文件;</li>
</ul>
<h3 id="1-打开Leveldb"><a href="#1-打开Leveldb" class="headerlink" title="1. 打开Leveldb"></a>1. 打开Leveldb</h3><p>在open db的过程中，leveldb主要做了三件事情：</p>
<ul>
<li>初始化一个最初的dbimpl对象，这个对象包含了很多内容，在系列第三篇文章中有介绍;</li>
<li>恢复版本管理的的内容，主要是从manifest文章中读出来VersionEdit，然后慢慢的构造最新的version</li>
<li>恢复wal中的数据，并不是所有的wal都需要恢复，但是在version恢复过程中可以获得需要恢复的内容;</li>
</ul>
<p>核心代码:</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line">Status DB::Open(<span class="keyword">const</span> Options&amp; options, <span class="keyword">const</span> <span class="built_in">std</span>::<span class="built_in">string</span>&amp; dbname, DB** dbptr) &#123;</span><br><span class="line">  *dbptr = <span class="literal">nullptr</span>;</span><br><span class="line"></span><br><span class="line">  DBImpl* impl = <span class="keyword">new</span> DBImpl(options, dbname);</span><br><span class="line">  impl-&gt;mutex_.Lock();</span><br><span class="line">  VersionEdit edit;</span><br><span class="line">  </span><br><span class="line">  <span class="comment">// Recover handles create_if_missing, error_if_exists</span></span><br><span class="line">  <span class="keyword">bool</span> save_manifest = <span class="literal">false</span>;</span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">   * 恢复version和wal</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  Status s = impl-&gt;Recover(&amp;edit, &amp;save_manifest);</span><br><span class="line">  <span class="keyword">if</span> (s.ok() &amp;&amp; impl-&gt;mem_ == <span class="literal">nullptr</span>) &#123;</span><br><span class="line">    <span class="comment">// Create new log and a corresponding memtable.</span></span><br><span class="line">    <span class="keyword">uint64_t</span> new_log_number = impl-&gt;versions_-&gt;NewFileNumber();</span><br><span class="line">    WritableFile* lfile;</span><br><span class="line">    s = options.env-&gt;NewWritableFile(LogFileName(dbname, new_log_number),</span><br><span class="line">                                     &amp;lfile);</span><br><span class="line">    <span class="keyword">if</span> (s.ok()) &#123;</span><br><span class="line">      edit.SetLogNumber(new_log_number);</span><br><span class="line">      impl-&gt;logfile_ = lfile;</span><br><span class="line">      impl-&gt;logfile_number_ = new_log_number;</span><br><span class="line">      impl-&gt;log_ = <span class="keyword">new</span> <span class="built_in">log</span>::Writer(lfile);</span><br><span class="line">      impl-&gt;mem_ = <span class="keyword">new</span> MemTable(impl-&gt;internal_comparator_);</span><br><span class="line">      impl-&gt;mem_-&gt;Ref();</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">if</span> (s.ok() &amp;&amp; save_manifest) &#123;</span><br><span class="line">    edit.SetPrevLogNumber(<span class="number">0</span>);  <span class="comment">// No older logs needed after recovery.</span></span><br><span class="line">    edit.SetLogNumber(impl-&gt;logfile_number_);</span><br><span class="line">    s = impl-&gt;versions_-&gt;LogAndApply(&amp;edit, &amp;impl-&gt;mutex_);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">if</span> (s.ok()) &#123;</span><br><span class="line">    <span class="comment">//删除不必要的文件</span></span><br><span class="line">    impl-&gt;RemoveObsoleteFiles();</span><br><span class="line">    impl-&gt;MaybeScheduleCompaction();</span><br><span class="line">  &#125;</span><br><span class="line">  impl-&gt;mutex_.Unlock();</span><br><span class="line">  <span class="keyword">if</span> (s.ok()) &#123;</span><br><span class="line">    assert(impl-&gt;mem_ != <span class="literal">nullptr</span>);</span><br><span class="line">    *dbptr = impl;</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="keyword">delete</span> impl;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> s;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>核心的点在于: impl-&gt;Recover这个函数里面，里面主要包含了version恢复 + wal的恢复; 恢复完毕之后整个db就处于在上一次停止之后的一个比较完整的状态; 基于这个状态的db数据是没有”丢失”的; recover函数的代码量还是很大的，分成两块，分别为version recover + wal的recover;</p>
<h4 id="1-1-Version-Recover的过程"><a href="#1-1-Version-Recover的过程" class="headerlink" title="1.1 Version Recover的过程"></a>1.1 Version Recover的过程</h4><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 读取manifest中的内容</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">while</span> (reader.ReadRecord(&amp;record, &amp;scratch) &amp;&amp; s.ok()) &#123;</span><br><span class="line">  VersionEdit edit;</span><br><span class="line">  s = edit.DecodeFrom(record);</span><br><span class="line">  <span class="keyword">if</span> (s.ok()) &#123;</span><br><span class="line">    <span class="keyword">if</span> (edit.has_comparator_ &amp;&amp;</span><br><span class="line">        edit.comparator_ != icmp_.user_comparator()-&gt;Name()) &#123;</span><br><span class="line">      s = Status::InvalidArgument(</span><br><span class="line">          edit.comparator_ + <span class="string">" does not match existing comparator "</span>,</span><br><span class="line">          icmp_.user_comparator()-&gt;Name());</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (s.ok()) &#123;</span><br><span class="line">    builder.Apply(&amp;edit);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (edit.has_log_number_) &#123;</span><br><span class="line">    log_number = edit.log_number_;</span><br><span class="line">    have_log_number = <span class="literal">true</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (edit.has_prev_log_number_) &#123;</span><br><span class="line">    prev_log_number = edit.prev_log_number_;</span><br><span class="line">    have_prev_log_number = <span class="literal">true</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (edit.has_next_file_number_) &#123;</span><br><span class="line">    next_file = edit.next_file_number_;</span><br><span class="line">    have_next_file = <span class="literal">true</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (edit.has_last_sequence_) &#123;</span><br><span class="line">    last_sequence = edit.last_sequence_;</span><br><span class="line">    have_last_sequence = <span class="literal">true</span>;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>整体逻辑是: </p>
<ul>
<li>读取manifest中的每一个VersionEdit的内存，然后慢慢的恢复到Version中去; 如果按照git的逻辑就是，如果所有的commit都在，那就一定能构建出来完整的数据;</li>
<li>从manifest中读取的每一个VersionEdit，通过builder.Apply(&amp;edit)会被应用到一起，慢慢累积的过程;</li>
</ul>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">Apply</span><span class="params">(VersionEdit* edit)</span> </span>&#123;</span><br><span class="line">  <span class="comment">// Update compaction pointers</span></span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">size_t</span> i = <span class="number">0</span>; i &lt; edit-&gt;compact_pointers_.size(); i++) &#123;</span><br><span class="line">    <span class="keyword">const</span> <span class="keyword">int</span> level = edit-&gt;compact_pointers_[i].first;</span><br><span class="line">    vset_-&gt;compact_pointer_[level] =</span><br><span class="line">        edit-&gt;compact_pointers_[i].second.Encode().ToString();</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Delete files</span></span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">const</span> <span class="keyword">auto</span>&amp; deleted_file_set_kvp : edit-&gt;deleted_files_) &#123;</span><br><span class="line">    <span class="keyword">const</span> <span class="keyword">int</span> level = deleted_file_set_kvp.first;</span><br><span class="line">    <span class="keyword">const</span> <span class="keyword">uint64_t</span> number = deleted_file_set_kvp.second;</span><br><span class="line">    levels_[level].deleted_files.insert(number);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Add new files</span></span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">size_t</span> i = <span class="number">0</span>; i &lt; edit-&gt;new_files_.size(); i++) &#123;</span><br><span class="line">    <span class="keyword">const</span> <span class="keyword">int</span> level = edit-&gt;new_files_[i].first;</span><br><span class="line">    FileMetaData* f = <span class="keyword">new</span> FileMetaData(edit-&gt;new_files_[i].second);</span><br><span class="line">    f-&gt;refs = <span class="number">1</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// We arrange to automatically compact this file after</span></span><br><span class="line">    <span class="comment">// a certain number of seeks.  Let's assume:</span></span><br><span class="line">    <span class="comment">//   (1) One seek costs 10ms</span></span><br><span class="line">    <span class="comment">//   (2) Writing or reading 1MB costs 10ms (100MB/s)</span></span><br><span class="line">    <span class="comment">//   (3) A compaction of 1MB does 25MB of IO:</span></span><br><span class="line">    <span class="comment">//         1MB read from this level</span></span><br><span class="line">    <span class="comment">//         10-12MB read from next level (boundaries may be misaligned)</span></span><br><span class="line">    <span class="comment">//         10-12MB written to next level</span></span><br><span class="line">    <span class="comment">// This implies that 25 seeks cost the same as the compaction</span></span><br><span class="line">    <span class="comment">// of 1MB of data.  I.e., one seek costs approximately the</span></span><br><span class="line">    <span class="comment">// same as the compaction of 40KB of data.  We are a little</span></span><br><span class="line">    <span class="comment">// conservative and allow approximately one seek for every 16KB</span></span><br><span class="line">    <span class="comment">// of data before triggering a compaction.</span></span><br><span class="line">    f-&gt;allowed_seeks = <span class="keyword">static_cast</span>&lt;<span class="keyword">int</span>&gt;((f-&gt;file_size / <span class="number">16384U</span>));</span><br><span class="line">    <span class="keyword">if</span> (f-&gt;allowed_seeks &lt; <span class="number">100</span>) f-&gt;allowed_seeks = <span class="number">100</span>;</span><br><span class="line"></span><br><span class="line">    levels_[level].deleted_files.erase(f-&gt;number);</span><br><span class="line">    levels_[level].added_files-&gt;insert(f);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>整体逻辑：</p>
<ol>
<li>更新VersionSet的compact_pointers_的数据; 这个参数主要是包含了每一层下一次要进行compact的开始的startkey;</li>
<li>VersionEdit要删除的文件进行汇总</li>
<li>VersionEdit新增的文件进行汇总</li>
<li><p>在过程中还会不断的统计这四个参数:</p>
<ul>
<li>log_number_: 用到的wal的id</li>
<li>prev_log_number_: 前一个wal的id，这个id也不知道是怎么被赋值的，但是很重要，因为也保证了数据的不丢;</li>
<li>next_file_number_: 下一个文件的id，这个id用于多种文件类型</li>
<li>last_sequence_: 最大的序列id</li>
</ul>
</li>
</ol>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br></pre></td><td class="code"><pre><span class="line">  <span class="keyword">if</span> (s.ok()) &#123;</span><br><span class="line">    Version* v = <span class="keyword">new</span> Version(<span class="keyword">this</span>);</span><br><span class="line">    builder.SaveTo(v);</span><br><span class="line">    <span class="comment">// Install recovered version</span></span><br><span class="line">    Finalize(v);</span><br><span class="line">    AppendVersion(v);</span><br><span class="line">    manifest_file_number_ = next_file;</span><br><span class="line">    next_file_number_ = next_file + <span class="number">1</span>;</span><br><span class="line">    last_sequence_ = last_sequence;</span><br><span class="line">    log_number_ = log_number;</span><br><span class="line">    prev_log_number_ = prev_log_number;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// See if we can reuse the existing MANIFEST file.</span></span><br><span class="line">    <span class="keyword">if</span> (ReuseManifest(dscname, current)) &#123;</span><br><span class="line">      <span class="comment">// No need to save new manifest</span></span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      *save_manifest = <span class="literal">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">```   </span><br><span class="line"></span><br><span class="line">最后把所用的VersionEdit都恢复回来变成了Version，然后leveldb就你会把当前的version固化，并且放到versionSet中; 到目前为止，版本是恢复回来了，现在就要对真实的文件进行处理了；</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#### <span class="number">1.2</span> WAL文件的恢复</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">```C++</span><br><span class="line">  <span class="keyword">const</span> <span class="keyword">uint64_t</span> min_log = versions_-&gt;LogNumber();</span><br><span class="line">  <span class="keyword">const</span> <span class="keyword">uint64_t</span> prev_log = versions_-&gt;PrevLogNumber();</span><br><span class="line">  <span class="built_in">std</span>::<span class="built_in">vector</span>&lt;<span class="built_in">std</span>::<span class="built_in">string</span>&gt; filenames;</span><br><span class="line">  s = env_-&gt;GetChildren(dbname_, &amp;filenames);</span><br><span class="line">  <span class="keyword">if</span> (!s.ok()) &#123;</span><br><span class="line">    <span class="keyword">return</span> s;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="built_in">std</span>::<span class="built_in">set</span>&lt;<span class="keyword">uint64_t</span>&gt; expected;</span><br><span class="line">  versions_-&gt;AddLiveFiles(&amp;expected);</span><br><span class="line">  <span class="keyword">uint64_t</span> number;</span><br><span class="line">  FileType type;</span><br><span class="line">  <span class="built_in">std</span>::<span class="built_in">vector</span>&lt;<span class="keyword">uint64_t</span>&gt; logs;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">   * 版本中包含的log是已经被写入到sstable中的，但是wal中的log可能还没有写入到sstable中，</span></span><br><span class="line"><span class="comment">   * 所以必须需要将这些没有正常写入的wal恢复回来</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">size_t</span> i = <span class="number">0</span>; i &lt; filenames.size(); i++) &#123;</span><br><span class="line">    <span class="keyword">if</span> (ParseFileName(filenames[i], &amp;number, &amp;type)) &#123;</span><br><span class="line">      expected.erase(number);</span><br><span class="line">      <span class="keyword">if</span> (type == kLogFile &amp;&amp; ((number &gt;= min_log) || (number == prev_log)))</span><br><span class="line">        logs.push_back(number);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">if</span> (!expected.empty()) &#123;</span><br><span class="line">    <span class="keyword">char</span> buf[<span class="number">50</span>];</span><br><span class="line">    <span class="built_in">std</span>::<span class="built_in">snprintf</span>(buf, <span class="keyword">sizeof</span>(buf), <span class="string">"%d missing files; e.g."</span>,</span><br><span class="line">                  <span class="keyword">static_cast</span>&lt;<span class="keyword">int</span>&gt;(expected.size()));</span><br><span class="line">    <span class="keyword">return</span> Status::Corruption(buf, TableFileName(dbname_, *(expected.begin())));</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Recover in the order in which the logs were generated</span></span><br><span class="line">  <span class="built_in">std</span>::sort(logs.begin(), logs.end());</span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">size_t</span> i = <span class="number">0</span>; i &lt; logs.size(); i++) &#123;</span><br><span class="line">    s = RecoverLogFile(logs[i], (i == logs.size() - <span class="number">1</span>), save_manifest, edit,</span><br><span class="line">                       &amp;max_sequence);</span><br><span class="line">    <span class="keyword">if</span> (!s.ok()) &#123;</span><br><span class="line">      <span class="keyword">return</span> s;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// The previous incarnation may not have written any MANIFEST</span></span><br><span class="line">    <span class="comment">// records after allocating this log number.  So we manually</span></span><br><span class="line">    <span class="comment">// update the file number allocation counter in VersionSet.</span></span><br><span class="line">    versions_-&gt;MarkFileNumberUsed(logs[i]);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (versions_-&gt;LastSequence() &lt; max_sequence) &#123;</span><br><span class="line">    versions_-&gt;SetLastSequence(max_sequence);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> Status::OK();</span><br><span class="line">``` </span><br><span class="line"></span><br><span class="line"><span class="number">1.</span> 通过VersionSet可以知道当前应该存在有哪些文件</span><br><span class="line"><span class="number">2.</span> 通过目录可以获得当前db真实存在有哪些文件，</span><br><span class="line"><span class="number">3.</span> 进行比较，多余的进行删除，少的就进行报错，理论上不应有这样的问题;</span><br><span class="line"></span><br><span class="line">这边看到WAL的恢复的逻辑是:</span><br><span class="line"></span><br><span class="line">```C++</span><br><span class="line"> <span class="keyword">if</span> (type == kLogFile &amp;&amp; ((number &gt;= min_log) || (number == prev_log)))</span><br><span class="line">        logs.push_back(number);</span><br></pre></td></tr></table></figure>
<p>如果是kLogFile类型的文件，并且文件id小于等于min_log,或者等于prev_log，小于等于我懂，因为即使版本中包含了log_number，也不能保证wal都被消费掉了，所以需要重新会滚；prev_log目前还不清楚是什么含义(TODO);</p>
<p>wal的文件id会进行排序，然后按照顺序进行恢复; 恢复过程后面细讲;</p>
<h4 id="1-3-善后的工作"><a href="#1-3-善后的工作" class="headerlink" title="1.3 善后的工作"></a>1.3 善后的工作</h4><ol>
<li>会将本次的恢复过程按照一次VersionEdit进行写入到文件;</li>
<li>删除一些多余的文件</li>
</ol>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;终于到了正常讲流程的，对于leveldb来说，让我来看最主要的几个关键点在于：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;打开leveldb的过程；涉及到了数据如何从文件中恢复回来的问题；&lt;/li&gt;
&lt;li&gt;write流程&lt;/li&gt;
&lt;li&gt;open流程&lt;/li&gt;
&lt;li&gt;compacti
    
    </summary>
    
      <category term="源码分析" scheme="http://yoursite.com/categories/%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"/>
    
    
      <category term="leveldb" scheme="http://yoursite.com/tags/leveldb/"/>
    
  </entry>
  
  <entry>
    <title>LevelDB源码(三、leveldb DBImpl成员分析)</title>
    <link href="http://yoursite.com/2020/07/02/LevelDB%E6%BA%90%E7%A0%81-%E4%B8%89%E3%80%81leveldb-DBImpl%E6%88%90%E5%91%98%E5%88%86%E6%9E%90/"/>
    <id>http://yoursite.com/2020/07/02/LevelDB源码-三、leveldb-DBImpl成员分析/</id>
    <published>2020-07-02T14:36:07.000Z</published>
    <updated>2020-07-06T06:44:51.569Z</updated>
    
    <content type="html"><![CDATA[<p>系列第三章，主要分析核心DBImpl的数据成员的含义, 并且会包含讲到Version、VersionSet、VersionEdit这几个版本管理的核心大类；为什么先讲这些呢？因为我在看后面的读写流程的时候，发现如果事先把这些定义都能理解清楚了，对流程上的关键点会更加清晰；尤其在于Leveldb在被打开瞬间，数据如何恢复特别的重要.</p>
<h4 id="1-DBImpl类的数据成员"><a href="#1-DBImpl类的数据成员" class="headerlink" title="1. DBImpl类的数据成员"></a>1. DBImpl类的数据成员</h4><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">class</span> DBImpl: <span class="keyword">public</span> DB &#123;</span><br><span class="line">  <span class="comment">//指定环境的工具类，比如文件操作之类的</span></span><br><span class="line">  Env* <span class="keyword">const</span> env_;</span><br><span class="line">  <span class="keyword">const</span> InternalKeyComparator internal_comparator_;</span><br><span class="line">  <span class="keyword">const</span> InternalFilterPolicy internal_filter_policy_;</span><br><span class="line">  <span class="keyword">const</span> Options options_;  <span class="comment">// options_.comparator == &amp;internal_comparator_</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">//是否是自己管理infolog和blockcache,通常都是leveldb自己去管理，而非调用者来传入</span></span><br><span class="line">  <span class="keyword">const</span> <span class="keyword">bool</span> owns_info_log_;</span><br><span class="line">  <span class="keyword">const</span> <span class="keyword">bool</span> owns_cache_;</span><br><span class="line">  <span class="keyword">const</span> <span class="built_in">std</span>::<span class="built_in">string</span> dbname_;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// table_cache_ provides its own synchronization</span></span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">   * 提供对于leveldb的文件信息的管理，所以它的大小为最大打开文件个数</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  TableCache* <span class="keyword">const</span> table_cache_;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Lock over the persistent DB state.  Non-null iff successfully acquired.</span></span><br><span class="line">  FileLock* db_lock_;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// State below is protected by mutex_</span></span><br><span class="line">  port::Mutex mutex_;</span><br><span class="line">  <span class="built_in">std</span>::atomic&lt;<span class="keyword">bool</span>&gt; shutting_down_;</span><br><span class="line">  port::<span class="function">CondVar background_work_finished_signal_ <span class="title">GUARDED_BY</span><span class="params">(mutex_)</span></span>;</span><br><span class="line"></span><br><span class="line">  MemTable* mem_;</span><br><span class="line">  <span class="function">MemTable* imm_ <span class="title">GUARDED_BY</span><span class="params">(mutex_)</span></span>;  <span class="comment">// Memtable being compacted</span></span><br><span class="line">  <span class="built_in">std</span>::atomic&lt;<span class="keyword">bool</span>&gt; has_imm_;         <span class="comment">// So bg thread can detect non-null imm_</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">//WAL的文件，logFiles用在后面的log_上面</span></span><br><span class="line">  WritableFile* logfile_;</span><br><span class="line">  <span class="keyword">uint64_t</span> <span class="function">logfile_number_ <span class="title">GUARDED_BY</span><span class="params">(mutex_)</span></span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">   * 感觉是WAL的类,用来存储put的数据</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="built_in">log</span>::Writer* log_;</span><br><span class="line">  <span class="keyword">uint32_t</span> <span class="function">seed_ <span class="title">GUARDED_BY</span><span class="params">(mutex_)</span></span>;  <span class="comment">// For sampling.</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">// Queue of writers.</span></span><br><span class="line">  <span class="built_in">std</span>::<span class="built_in">deque</span>&lt;Writer*&gt; <span class="function">writers_ <span class="title">GUARDED_BY</span><span class="params">(mutex_)</span></span>;</span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">   *  leveldb是结合多个写入然后才操作memtable + wal；而这个对象就是WriteBatch</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="function">WriteBatch* tmp_batch_ <span class="title">GUARDED_BY</span><span class="params">(mutex_)</span></span>;</span><br><span class="line"></span><br><span class="line">  <span class="function">SnapshotList snapshots_ <span class="title">GUARDED_BY</span><span class="params">(mutex_)</span></span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Set of table files to protect from deletion because they are</span></span><br><span class="line">  <span class="comment">// part of ongoing compactions.</span></span><br><span class="line">  <span class="built_in">std</span>::<span class="built_in">set</span>&lt;<span class="keyword">uint64_t</span>&gt; <span class="function">pending_outputs_ <span class="title">GUARDED_BY</span><span class="params">(mutex_)</span></span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Has a background compaction been scheduled or is running?</span></span><br><span class="line">  <span class="function"><span class="keyword">bool</span> background_compaction_scheduled_ <span class="title">GUARDED_BY</span><span class="params">(mutex_)</span></span>;</span><br><span class="line"></span><br><span class="line">  <span class="function">ManualCompaction* manual_compaction_ <span class="title">GUARDED_BY</span><span class="params">(mutex_)</span></span>;</span><br><span class="line"></span><br><span class="line">  <span class="function">VersionSet* <span class="keyword">const</span> versions_ <span class="title">GUARDED_BY</span><span class="params">(mutex_)</span></span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Have we encountered a background error in paranoid mode?</span></span><br><span class="line">  <span class="function">Status bg_error_ <span class="title">GUARDED_BY</span><span class="params">(mutex_)</span></span>;</span><br><span class="line"></span><br><span class="line">  CompactionStats stats_[config::kNumLevels] GUARDED_BY(mutex_);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>上面代码只是展示了数据成员，没有写成员函数;想看具体在<code>db_impl.h</code>文件中;下面就具体分析这些数据成员：</p>
<ul>
<li>env_: 内部封装了一些与os相关的操作，主要是读写、生成文件之类的; 默认以default为主</li>
<li>internal_comparator_: 内部字符串的对比方式;默认字节序列比较</li>
<li>internal_filter_policy_: 默认是bloom过滤器，本身是为了减少对磁盘操作而产生的过滤器</li>
<li>options_：本系列的第二篇文章讲了关于db option的细节，大部分使用默认值，如果用户想修改的话，就需要在打开db的时候就赋值</li>
</ul>
<hr>
<ul>
<li>owns_info_log_: 是否使用的是内部自己的打日志的文件，如果是自己的话，需要在最后自己释放掉</li>
<li>owns_cache_：是否自己提供了blockcache的方式，默认是用了LRU的方式来实现这个</li>
<li>dbname_: leveldb的路径</li>
<li>table_cache_: 主要是一些经常打开的sstable的文件缓存，如果经常访问就不需要经常去open;也是使用了LRU的方式进行管理</li>
<li>db_lock_： 文件锁，其实也不是真的文件锁，只不过用一个文件来保存这个状态，方式两次打开相同的db;</li>
</ul>
<hr>
<ul>
<li>mutex_: 用于保护一些关键变量的线程安全</li>
<li>shutting_down_： 是否正在关闭</li>
<li>background_work_finished_signal_: 条件变量，用来通知背后工作线程已经运行关闭，到时候会进行通知;</li>
</ul>
<hr>
<ul>
<li>mem_: memtable; </li>
<li>imm_：不可变的memtable</li>
<li>has_imm_：是否有不可变的memtable</li>
</ul>
<hr>
<ul>
<li>logfile_: wal对应的文件</li>
<li>logfile_number: 表示当前的wal的文件名；在leveldb中文件名通常都是编号；leveldb通过增量的方式来保证唯一性；这样不需要保存文件名;</li>
<li>log_: 对logfile_的封装，可以读写操作</li>
<li>seed_： 看了后期使用的过程，主要是为了后期的随机数使用,可能是为了更加随机一些吧</li>
<li>writers_: deque的队列，是用来存放写操作的双端队列; 通过上面的mutex_来保证线程安全；通过用户调用put之后，会将写操作放到这里面; 后面有线程进行批量的写入;</li>
<li>tmp_batch_: writeBatch类型，用来做批量写入的时候使用，不过为什么需要一个这个成员变量，需要后面看到再来解答; TODO</li>
<li>snapshots_: 维持目前db返回给外界的snapshot的一个list;是一个双向链表</li>
<li>pending_outputs_: 看注解应该是一些被保护防止被删除的文件;  TODO</li>
<li>background_compaction_scheduled_： 是否开启自动compaction的调度worker</li>
<li>manual_compaction_： 记录当前db手动compaction的信息，主要起到管理作用</li>
<li>versions_: 版本管理器; 这是一个常量指针，也就是被赋值之后不能被修改，但是可以修改内容</li>
<li>bg_error_： 与option中的<code>paranoid mode</code>一起使用</li>
<li>stats_: leveldb多层结构中，每层的compaction的状态</li>
</ul>
<p>默认构造函数: </p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">DBImpl::DBImpl(<span class="keyword">const</span> Options&amp; raw_options, <span class="keyword">const</span> <span class="built_in">std</span>::<span class="built_in">string</span>&amp; dbname)</span><br><span class="line">    : env_(raw_options.env),</span><br><span class="line">      internal_comparator_(raw_options.comparator),</span><br><span class="line">      internal_filter_policy_(raw_options.filter_policy),</span><br><span class="line">      options_(SanitizeOptions(dbname, &amp;internal_comparator_,</span><br><span class="line">                               &amp;internal_filter_policy_, raw_options)),</span><br><span class="line">      owns_info_log_(options_.info_log != raw_options.info_log),</span><br><span class="line">      owns_cache_(options_.block_cache != raw_options.block_cache),</span><br><span class="line">      dbname_(dbname),</span><br><span class="line">      table_cache_(<span class="keyword">new</span> TableCache(dbname_, options_, TableCacheSize(options_))),</span><br><span class="line">      db_lock_(<span class="literal">nullptr</span>),</span><br><span class="line">      shutting_down_(<span class="literal">false</span>),</span><br><span class="line">      background_work_finished_signal_(&amp;mutex_),</span><br><span class="line">      mem_(<span class="literal">nullptr</span>),</span><br><span class="line">      imm_(<span class="literal">nullptr</span>),</span><br><span class="line">      has_imm_(<span class="literal">false</span>),</span><br><span class="line">      logfile_(<span class="literal">nullptr</span>),</span><br><span class="line">      logfile_number_(<span class="number">0</span>),</span><br><span class="line">      log_(<span class="literal">nullptr</span>),</span><br><span class="line">      seed_(<span class="number">0</span>),</span><br><span class="line">      tmp_batch_(<span class="keyword">new</span> WriteBatch),</span><br><span class="line">      background_compaction_scheduled_(<span class="literal">false</span>),</span><br><span class="line">      manual_compaction_(<span class="literal">nullptr</span>),</span><br><span class="line">      versions_(<span class="keyword">new</span> VersionSet(dbname_, &amp;options_, table_cache_,</span><br><span class="line">                               &amp;internal_comparator_)) &#123;&#125;</span><br></pre></td></tr></table></figure>
<p>初始化之后都是默认值，但是在<code>DB:open</code>函数调用之后都会从文件中恢复出之前持久化的数值;</p>
<h4 id="2-VersionSet，Leveldb的版本管理"><a href="#2-VersionSet，Leveldb的版本管理" class="headerlink" title="2. VersionSet，Leveldb的版本管理"></a>2. VersionSet，Leveldb的版本管理</h4><p>所谓版本管理，主要指的是Leveldb去管理sstable、wal、manifest等一些本地的文件；而这些文件会随着compaction的操作而变化，所以需要有版本管理器来管理这些;</p>
<p>在网上看到一<a href="https://sf-zhou.github.io/leveldb/leveldb_07_version.html" target="_blank" rel="noopener">文章</a>,里面有一个比喻会比较形象来描述这些概念:</p>
<ul>
<li>VersionEdit: 类似于git的一个commit，记录了本次的变化</li>
<li>Version: 表示git当前的版本；就是git log中展示的那个唯一id; 通常上一个version + VersionEdit = 当前的version</li>
<li>VersionSet: 初始version，以及之后的所有的VersionEdit，这个方式可以推演出所有的之后版本;</li>
</ul>
<h5 id="FileMetaData对象"><a href="#FileMetaData对象" class="headerlink" title="FileMetaData对象"></a>FileMetaData对象</h5><p>FileMetaData是用来管理sstatble的状态的;<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> FileMetaData &#123;</span><br><span class="line">  FileMetaData() : refs(<span class="number">0</span>), allowed_seeks(<span class="number">1</span> &lt;&lt; <span class="number">30</span>), file_size(<span class="number">0</span>) &#123;&#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">   * refs: 当前sstable被引用的次数，如果次数=0的时候，就表示可以删除</span></span><br><span class="line"><span class="comment">   * allowed_seek: 查好次数,估计会通过这个来进行判断是否要compaction</span></span><br><span class="line"><span class="comment">   * number: 文件编号，通过编号找到文件</span></span><br><span class="line"><span class="comment">   * filesize: 文件size</span></span><br><span class="line"><span class="comment">   * smallest: 最小key的</span></span><br><span class="line"><span class="comment">   * largest: 最大key</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="keyword">int</span> refs;</span><br><span class="line">  <span class="keyword">int</span> allowed_seeks;  <span class="comment">// Seeks allowed until compaction</span></span><br><span class="line">  <span class="keyword">uint64_t</span> number;</span><br><span class="line">  <span class="keyword">uint64_t</span> file_size;    <span class="comment">// File size in bytes</span></span><br><span class="line">  InternalKey smallest;  <span class="comment">// Smallest internal key served by table</span></span><br><span class="line">  InternalKey largest;   <span class="comment">// Largest internal key served by table</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure></p>
<h5 id="VersionEdit"><a href="#VersionEdit" class="headerlink" title="VersionEdit"></a>VersionEdit</h5><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">std</span>::<span class="built_in">string</span> comparator_;</span><br><span class="line"><span class="keyword">uint64_t</span> log_number_;</span><br><span class="line"><span class="keyword">uint64_t</span> prev_log_number_;</span><br><span class="line"><span class="keyword">uint64_t</span> next_file_number_;</span><br><span class="line">SequenceNumber last_sequence_;</span><br><span class="line"><span class="keyword">bool</span> has_comparator_;</span><br><span class="line"><span class="keyword">bool</span> has_log_number_;</span><br><span class="line"><span class="keyword">bool</span> has_prev_log_number_;</span><br><span class="line"><span class="keyword">bool</span> has_next_file_number_;</span><br><span class="line"><span class="keyword">bool</span> has_last_sequence_;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * key: level</span></span><br><span class="line"><span class="comment"> * value: 内部key</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="built_in">std</span>::<span class="built_in">vector</span>&lt;<span class="built_in">std</span>::pair&lt;<span class="keyword">int</span>, InternalKey&gt;&gt; compact_pointers_;</span><br><span class="line"><span class="comment">//需要被删除的文件</span></span><br><span class="line">DeletedFileSet deleted_files_;</span><br><span class="line"><span class="comment">// 新增的文件</span></span><br><span class="line"><span class="built_in">std</span>::<span class="built_in">vector</span>&lt;<span class="built_in">std</span>::pair&lt;<span class="keyword">int</span>, FileMetaData&gt;&gt; new_files_;</span><br></pre></td></tr></table></figure>
<ul>
<li>comparator_: 压缩方式</li>
<li>log_number_: 这次的变更对应的wal的文件ID</li>
<li>prev_log_number_： 上一个wal的文件ID</li>
<li>next_file_number_: 下一个sstable文件的id</li>
<li>last_sequence_： 最大的版本id是什么</li>
<li>compact_pointers_： 每一层level对应的compaction指针，目前还不清楚有什么用</li>
<li>deleted_files_: 本次更新需要被删除的文件</li>
<li>new_files_: 本次更新新增的文件</li>
</ul>
<p>对VersionEdit的理解，可以想个例子: memtable在被写入到sstable的时候，就会产生一个问题；这个时候这次的更新可以比较简单的认为是新增的一个sstable，这个时候的VersionEdit估计就是;</p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line"><span class="attr">"comparator_"</span>: <span class="string">""</span>,</span><br><span class="line"><span class="attr">"log_number_"</span>:<span class="number">2</span>,</span><br><span class="line"><span class="attr">"prev_log_number_"</span>:<span class="number">1</span>,</span><br><span class="line"><span class="attr">"next_file_number_"</span>: <span class="number">3</span>,</span><br><span class="line"><span class="attr">"last_sequence_"</span>: <span class="number">1000</span>,</span><br><span class="line"><span class="attr">"new_files_"</span>: [<span class="string">"xxx"</span>]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>为什么要保存wal的id呢，我觉得主要是在启动恢复的时候需要去知道当前哪些wal是需要被恢复的，至于为什么是要保存两个id呢？我看了后面再来记录TODO</p>
<h5 id="Version"><a href="#Version" class="headerlink" title="Version"></a>Version</h5><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> Version &#123;</span><br><span class="line">  VersionSet* vset_;  <span class="comment">// VersionSet to which this Version belongs</span></span><br><span class="line">  Version* next_;     <span class="comment">// Next version in linked list</span></span><br><span class="line">  Version* prev_;     <span class="comment">// Previous version in linked list</span></span><br><span class="line">  <span class="keyword">int</span> refs_;          <span class="comment">// Number of live refs to this version</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">// List of files per level</span></span><br><span class="line">  <span class="built_in">std</span>::<span class="built_in">vector</span>&lt;FileMetaData*&gt; files_[config::kNumLevels];</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Next file to compact based on seek stats.</span></span><br><span class="line">  FileMetaData* file_to_compact_;</span><br><span class="line">  <span class="keyword">int</span> file_to_compact_level_;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Level that should be compacted next and its compaction score.</span></span><br><span class="line">  <span class="comment">// Score &lt; 1 means compaction is not strictly needed.  These fields</span></span><br><span class="line">  <span class="comment">// are initialized by Finalize().</span></span><br><span class="line">  <span class="keyword">double</span> compaction_score_;</span><br><span class="line">  <span class="keyword">int</span> compaction_level_;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>vset_: 当前version属于那个VersionSet</li>
<li>next_, prev_: 双向链表，指向上一个或者下一个的version</li>
<li>refs_：version是否被引用</li>
<li>files_： 当前这个version，每一个层关联的文件，估计排序的</li>
<li>file_to_compact_： 当前有哪些可能需要被compaction</li>
<li>file_to_compact_level_: 对应的层数</li>
<li>compaction_score_：TODO</li>
<li>compaction_level_：TODO</li>
</ul>
<p>从数据结构来说，Version包含了当前这个版本整体的文件结构，比如每次包含了哪些文件，哪些文件就可能需要进行compaction之类的; 上下版本的list;</p>
<h5 id="VersionSet"><a href="#VersionSet" class="headerlink" title="VersionSet"></a>VersionSet</h5><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">class</span> VersionSet &#123;</span><br><span class="line">  Env* <span class="keyword">const</span> env_;</span><br><span class="line">  <span class="keyword">const</span> <span class="built_in">std</span>::<span class="built_in">string</span> dbname_;</span><br><span class="line">  <span class="keyword">const</span> Options* <span class="keyword">const</span> options_;</span><br><span class="line">  TableCache* <span class="keyword">const</span> table_cache_;</span><br><span class="line">  <span class="keyword">const</span> InternalKeyComparator icmp_;</span><br><span class="line">  <span class="keyword">uint64_t</span> next_file_number_;</span><br><span class="line">  <span class="keyword">uint64_t</span> manifest_file_number_;</span><br><span class="line">  <span class="keyword">uint64_t</span> last_sequence_;</span><br><span class="line">  <span class="keyword">uint64_t</span> log_number_;</span><br><span class="line">  <span class="keyword">uint64_t</span> prev_log_number_;  <span class="comment">// 0 or backing store for memtable being compacted</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">// Opened lazily</span></span><br><span class="line">  WritableFile* descriptor_file_;</span><br><span class="line">  <span class="built_in">log</span>::Writer* descriptor_log_;</span><br><span class="line">  Version dummy_versions_;  <span class="comment">// Head of circular doubly-linked list of versions.</span></span><br><span class="line">  Version* current_;        <span class="comment">// == dummy_versions_.prev_</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">// Per-level key at which the next compaction at that level should start.</span></span><br><span class="line">  <span class="comment">// Either an empty string, or a valid InternalKey.</span></span><br><span class="line">  <span class="built_in">std</span>::<span class="built_in">string</span> compact_pointer_[config::kNumLevels]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>env_: 同上</li>
<li>dbname_: leveldb路径</li>
<li>options_： 同上dbimpl_</li>
<li>icmp_: 同上</li>
<li>next_file_number_: 下一个文件id; 这个文件可能指sstable，目前还不确定</li>
<li>manifest_file_number_: manifest文件的ID</li>
<li>last_sequence_：最大序列号</li>
<li>log_number_： wal文件id</li>
<li>prev_log_number_： 同上</li>
<li>dummy_versions_: version双向链表的头</li>
<li>current_: dummy_versions_.prev_，表示当前version</li>
<li>compact_pointer_：TODO 未知</li>
</ul>
<p>构造函数:</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">VersionSet::VersionSet(<span class="keyword">const</span> <span class="built_in">std</span>::<span class="built_in">string</span>&amp; dbname, <span class="keyword">const</span> Options* options,</span><br><span class="line">                       TableCache* table_cache,</span><br><span class="line">                       <span class="keyword">const</span> InternalKeyComparator* cmp)</span><br><span class="line">    : env_(options-&gt;env),</span><br><span class="line">      dbname_(dbname),</span><br><span class="line">      options_(options),</span><br><span class="line">      table_cache_(table_cache),</span><br><span class="line">      icmp_(*cmp),</span><br><span class="line">      next_file_number_(<span class="number">2</span>),</span><br><span class="line">      manifest_file_number_(<span class="number">0</span>),  <span class="comment">// Filled by Recover()</span></span><br><span class="line">      last_sequence_(<span class="number">0</span>),</span><br><span class="line">      log_number_(<span class="number">0</span>),</span><br><span class="line">      prev_log_number_(<span class="number">0</span>),</span><br><span class="line">      descriptor_file_(<span class="literal">nullptr</span>),</span><br><span class="line">      descriptor_log_(<span class="literal">nullptr</span>),</span><br><span class="line">      dummy_versions_(<span class="keyword">this</span>),</span><br><span class="line">      current_(<span class="literal">nullptr</span>) &#123;</span><br><span class="line">  <span class="comment">//提供的时候VersionSet就只有一个;</span></span><br><span class="line">  AppendVersion(<span class="keyword">new</span> Version(<span class="keyword">this</span>));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>next_file_number_: 为什么初始化是2？？TODO</li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;系列第三章，主要分析核心DBImpl的数据成员的含义, 并且会包含讲到Version、VersionSet、VersionEdit这几个版本管理的核心大类；为什么先讲这些呢？因为我在看后面的读写流程的时候，发现如果事先把这些定义都能理解清楚了，对流程上的关键点会更加清晰；尤
    
    </summary>
    
      <category term="源码分析" scheme="http://yoursite.com/categories/%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"/>
    
    
      <category term="leveldb" scheme="http://yoursite.com/tags/leveldb/"/>
    
  </entry>
  
  <entry>
    <title>LevelDB源码(二、leveldb option分析)</title>
    <link href="http://yoursite.com/2020/06/28/LevelDB%E6%BA%90%E7%A0%81-%E4%BA%8C%E3%80%81leveldb-option%E5%88%86%E6%9E%90/"/>
    <id>http://yoursite.com/2020/06/28/LevelDB源码-二、leveldb-option分析/</id>
    <published>2020-06-28T15:35:23.000Z</published>
    <updated>2020-06-28T16:59:10.316Z</updated>
    
    <content type="html"><![CDATA[<p>本系列的第二篇文章主要是针对leveldb的option的参数进行介绍，option的参数其实不多，但是相对很重要，因为可以让用户进行自定义的一些操作; 了解清楚这些参数的含义就可以更加好的使用leveldb;</p>
<h3 id="1-option"><a href="#1-option" class="headerlink" title="1. option"></a>1. option</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> LEVELDB_EXPORT Options &#123;</span><br><span class="line">  <span class="comment">// Create an Options object with default values for all fields.</span></span><br><span class="line">  Options();</span><br><span class="line"></span><br><span class="line">  <span class="comment">//自定义比较器，默认使用字节序的方式进行排序比较</span></span><br><span class="line">  <span class="keyword">const</span> Comparator* comparator;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 假如leveldb对应的目录不存在就创建 </span></span><br><span class="line">  <span class="keyword">bool</span> create_if_missing = <span class="literal">false</span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 假如对应的目录存在的时候就报错</span></span><br><span class="line">  <span class="keyword">bool</span> error_if_exists = <span class="literal">false</span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// If true, the implementation will do aggressive checking of the</span></span><br><span class="line">  <span class="comment">// data it is processing and will stop early if it detects any</span></span><br><span class="line">  <span class="comment">// errors.  This may have unforeseen ramifications: for example, a</span></span><br><span class="line">  <span class="comment">// corruption of one DB entry may cause a large number of entries to</span></span><br><span class="line">  <span class="comment">// become unreadable or for the entire DB to become unopenable.</span></span><br><span class="line">  </span><br><span class="line">  <span class="comment">//在打开leveldb的时候是否检测db，如果有数据损坏的话就直接报错；但是通常默认false；因为大部分情况下即使数据损坏也可以用;</span></span><br><span class="line">  <span class="keyword">bool</span> paranoid_checks = <span class="literal">false</span>;</span><br><span class="line"></span><br><span class="line"> <span class="comment">// 默认Env::default(), Env封装的是操作系统相关的操作;</span></span><br><span class="line">  Env* env;</span><br><span class="line"></span><br><span class="line">  <span class="comment">//leveldb自己的日志文件对象，用来记录leveldb本身在处理过程中的信息</span></span><br><span class="line">  Logger* info_log = <span class="literal">nullptr</span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">   * memetable的大小;默认4MB</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="keyword">size_t</span> write_buffer_size = <span class="number">4</span> * <span class="number">1024</span> * <span class="number">1024</span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">   * db能最大打开文件的个数;</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="keyword">int</span> max_open_files = <span class="number">1000</span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Control over blocks (user data is stored in a set of blocks, and</span></span><br><span class="line">  <span class="comment">// a block is the unit of reading from disk).</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">// If non-null, use the specified cache for blocks.</span></span><br><span class="line">  <span class="comment">// If null, leveldb will automatically create and use an 8MB internal cache.</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">   * block缓存，如果为null，使用的是leveldb自己的lRU的缓存，默认8MB</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  Cache* block_cache = <span class="literal">nullptr</span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">//默认block的大小为4KB,真实数据为4KB，非压缩数据</span></span><br><span class="line">  <span class="keyword">size_t</span> block_size = <span class="number">4</span> * <span class="number">1024</span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">   * 类似与时间戳的压缩算法一下，通过保存一个完整的时间戳，后面的时间戳用偏移量来存储，这样的好处就可以压缩空间</span></span><br><span class="line"><span class="comment">   * 问题在于如果数据损毁的话会损失很多数据，所以会每n隔时间戳重新记录一个完整时间戳，这样即使数据顺坏也不会丢失</span></span><br><span class="line"><span class="comment">   * 很多数据；，这个参数是key前缀压缩的方式;</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="keyword">int</span> block_restart_interval = <span class="number">16</span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">//sstable的大小为2M,除了0层是4M，其他的level都是2M的大小</span></span><br><span class="line">  <span class="keyword">size_t</span> max_file_size = <span class="number">2</span> * <span class="number">1024</span> * <span class="number">1024</span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Compress blocks using the specified compression algorithm.  This</span></span><br><span class="line">  <span class="comment">// parameter can be changed dynamically.</span></span><br><span class="line">  <span class="comment">//</span></span><br><span class="line">  <span class="comment">// Default: kSnappyCompression, which gives lightweight but fast</span></span><br><span class="line">  <span class="comment">// compression.</span></span><br><span class="line">  <span class="comment">//</span></span><br><span class="line">  <span class="comment">// Typical speeds of kSnappyCompression on an Intel(R) Core(TM)2 2.4GHz:</span></span><br><span class="line">  <span class="comment">//    ~200-500MB/s compression</span></span><br><span class="line">  <span class="comment">//    ~400-800MB/s decompression</span></span><br><span class="line">  <span class="comment">// Note that these speeds are significantly faster than most</span></span><br><span class="line">  <span class="comment">// persistent storage speeds, and therefore it is typically never</span></span><br><span class="line">  <span class="comment">// worth switching to kNoCompression.  Even if the input data is</span></span><br><span class="line">  <span class="comment">// incompressible, the kSnappyCompression implementation will</span></span><br><span class="line">  <span class="comment">// efficiently detect that and will switch to uncompressed mode.</span></span><br><span class="line">  CompressionType compression = kSnappyCompression;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">   * 通过判断来发现manifest是否可以重用之前的；还不确定？？</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="keyword">bool</span> reuse_logs = <span class="literal">false</span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">   * 设置一个过滤器能用来减少磁盘的访问次数，默认用bloomfilter</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="keyword">const</span> FilterPolicy* filter_policy = <span class="literal">nullptr</span>;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<h3 id="2-ReadOptions"><a href="#2-ReadOptions" class="headerlink" title="2. ReadOptions"></a>2. ReadOptions</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Options that control read operations</span></span><br><span class="line"><span class="keyword">struct</span> LEVELDB_EXPORT ReadOptions &#123;</span><br><span class="line">  ReadOptions() = <span class="keyword">default</span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// If true, all data read from underlying storage will be</span></span><br><span class="line">  <span class="comment">// verified against corresponding checksums.</span></span><br><span class="line">  <span class="comment">//是否对结果进行checksum检查</span></span><br><span class="line">  <span class="keyword">bool</span> verify_checksums = <span class="literal">false</span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Should the data read for this iteration be cached in memory?</span></span><br><span class="line">  <span class="comment">// Callers may wish to set this field to false for bulk scans.</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">//是否将读出来数据缓存在内存里，如果你读很大的数据的时候，希望它不污染cache的话，可以设置false</span></span><br><span class="line">  <span class="keyword">bool</span> fill_cache = <span class="literal">true</span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// If "snapshot" is non-null, read as of the supplied snapshot</span></span><br><span class="line">  <span class="comment">// (which must belong to the DB that is being read and which must</span></span><br><span class="line">  <span class="comment">// not have been released).  If "snapshot" is null, use an implicit</span></span><br><span class="line">  <span class="comment">// snapshot of the state at the beginning of this read operation.</span></span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">   * 对于db的getSnapshot的函数返回的对象，可以读指定snapshot的数据，如果为null，就读当前读操作最新的snapshot的数据</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="keyword">const</span> Snapshot* snapshot = <span class="literal">nullptr</span>;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<h3 id="3-WriteOptions"><a href="#3-WriteOptions" class="headerlink" title="3. WriteOptions"></a>3. WriteOptions</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment">// Options that control write operations</span></span><br><span class="line"><span class="keyword">struct</span> LEVELDB_EXPORT WriteOptions &#123;</span><br><span class="line">  WriteOptions() = <span class="keyword">default</span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// If true, the write will be flushed from the operating system</span></span><br><span class="line">  <span class="comment">// buffer cache (by calling WritableFile::Sync()) before the write</span></span><br><span class="line">  <span class="comment">// is considered complete.  If this flag is true, writes will be</span></span><br><span class="line">  <span class="comment">// slower.</span></span><br><span class="line">  <span class="comment">//</span></span><br><span class="line">  <span class="comment">// If this flag is false, and the machine crashes, some recent</span></span><br><span class="line">  <span class="comment">// writes may be lost.  Note that if it is just the process that</span></span><br><span class="line">  <span class="comment">// crashes (i.e., the machine does not reboot), no writes will be</span></span><br><span class="line">  <span class="comment">// lost even if sync==false.</span></span><br><span class="line">  <span class="comment">//</span></span><br><span class="line">  <span class="comment">// In other words, a DB write with sync==false has similar</span></span><br><span class="line">  <span class="comment">// crash semantics as the "write()" system call.  A DB write</span></span><br><span class="line">  <span class="comment">// with sync==true has similar crash semantics to a "write()"</span></span><br><span class="line">  <span class="comment">// system call followed by "fsync()".</span></span><br><span class="line">  <span class="comment">//性能考虑，不会设置true</span></span><br><span class="line">  <span class="keyword">bool</span> sync = <span class="literal">false</span>;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本系列的第二篇文章主要是针对leveldb的option的参数进行介绍，option的参数其实不多，但是相对很重要，因为可以让用户进行自定义的一些操作; 了解清楚这些参数的含义就可以更加好的使用leveldb;&lt;/p&gt;
&lt;h3 id=&quot;1-option&quot;&gt;&lt;a href=&quot;
    
    </summary>
    
      <category term="源码分析" scheme="http://yoursite.com/categories/%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"/>
    
    
      <category term="leveldb" scheme="http://yoursite.com/tags/leveldb/"/>
    
  </entry>
  
  <entry>
    <title>LevelDB源码(一、leveldb接口分析)</title>
    <link href="http://yoursite.com/2020/06/27/leveldb%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-db%E6%8E%A5%E5%8F%A3%E5%88%86%E6%9E%90/"/>
    <id>http://yoursite.com/2020/06/27/leveldb源码分析-db接口分析/</id>
    <published>2020-06-27T15:28:31.000Z</published>
    <updated>2020-06-28T15:38:41.706Z</updated>
    
    <content type="html"><![CDATA[<p>本系列文章主要是针对leveldb的源码分析; 个人也是重温这份源码，希望能在重新看的过程中学习到更多的知识;</p>
<h3 id="1-基本接口"><a href="#1-基本接口" class="headerlink" title="1. 基本接口"></a>1. 基本接口</h3><p><a href="https://github.com/google/leveldb/blob/master/include/leveldb/db.h" target="_blank" rel="noopener">db.h</a>这个头文件几乎包含了所有leveldb提供的所有功能；这套接口是标准的存储引擎的接口，接口非常简洁，主要提供了修改、删除、读取的三大基本功能；其他的接口主要是一些附带的功能;</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line">  </span><br><span class="line">/**</span><br><span class="line"> * 打开leveldb,</span><br><span class="line"> * @param options: 打开leveldb的一些参数</span><br><span class="line"> * @param name: 路径</span><br><span class="line"> * @param dbptr: 返回值,如果成功打开就会在这个参数中返回;</span><br><span class="line"> * @return</span><br><span class="line"> */</span><br><span class="line">static Status Open(const Options&amp; options, const std::string&amp; name,</span><br><span class="line">                   DB** dbptr);</span><br><span class="line"></span><br><span class="line">DB() = default;</span><br><span class="line"></span><br><span class="line">//db不能被copy或者赋值</span><br><span class="line">DB(const DB&amp;) = delete;</span><br><span class="line">DB&amp; operator=(const DB&amp;) = delete;</span><br><span class="line"></span><br><span class="line">virtual ~DB();</span><br><span class="line"></span><br><span class="line">/**</span><br><span class="line"> * 将key和value存储到db里面；</span><br><span class="line"> * @param options ： 写参数设置，默认可以空对象</span><br><span class="line"> * @param key </span><br><span class="line"> * @param value </span><br><span class="line"> * @return </span><br><span class="line"> */</span><br><span class="line">virtual Status Put(const WriteOptions&amp; options, const Slice&amp; key,</span><br><span class="line">                   const Slice&amp; value) = 0;</span><br><span class="line"> </span><br><span class="line">//删除key</span><br><span class="line">virtual Status Delete(const WriteOptions&amp; options, const Slice&amp; key) = 0;</span><br><span class="line"> </span><br><span class="line"> /**</span><br><span class="line"> * 批量写的接口; </span><br><span class="line"> * @param options: 同Put接口 </span><br><span class="line"> * @param updates : 批量参数，里面可以包含有写、delete的操作; </span><br><span class="line"> * @return </span><br><span class="line"> */</span><br><span class="line">virtual Status Write(const WriteOptions&amp; options, WriteBatch* updates) = 0;</span><br><span class="line"></span><br><span class="line">//查询接口，指定key,返回结果在value中；状态看Status，如果为ok的话，value就是取到的值;</span><br><span class="line">virtual Status Get(const ReadOptions&amp; options, const Slice&amp; key,</span><br><span class="line">                   std::string* value) = 0;</span><br><span class="line"></span><br><span class="line">/**</span><br><span class="line"> * 返回一个iterator，这个需要调用者自己去清理掉的,</span><br><span class="line"> * 返回的iterator通常是无效的，需要在调用seek之后才有效</span><br><span class="line"> * @param options</span><br><span class="line"> * @return</span><br><span class="line"> */</span><br><span class="line">virtual Iterator* NewIterator(const ReadOptions&amp; options) = 0;</span><br></pre></td></tr></table></figure>
<p>上面这些接口机会是最为常用的接口,提供了打开db、读key、存储key的功能；存储引擎的功能就在于：</p>
<ul>
<li>存储数据</li>
<li>读取数据</li>
</ul>
<p>关于<code>NewIterator</code>接口需要注意的在于返回是一个指针类型的<code>Iterator*</code>,这个指针内存释放需要调用者来执行的，所以如果每次调用之后不调用delete的话，会出现内存泄露; 这是我第一次注意到这个问题，我发现自己在其他的代码中几乎都没有显示的delete的; 用shared_ptr来封装掉这个过程,这样就不需要手动去delete这个指针;</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">std::shared_ptr&lt;Iterator&gt; tmp = new std::shared_ptr&lt;Iterator&gt;(db-&gt;NewIterator(options), [](void* raw)&#123;</span><br><span class="line">  if (raw != nullptr) &#123;</span><br><span class="line">    delete static_cast&lt;Iterator*&gt;(raw);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;);</span><br><span class="line">tmp-&gt;SeekToFirst();</span><br></pre></td></tr></table></figure>
<h3 id="2-附加接口"><a href="#2-附加接口" class="headerlink" title="2. 附加接口"></a>2. 附加接口</h3><p>附加接口主要是一些其他功能的介绍；比如快照、如何获得leveldb的监控信息等等;</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br></pre></td><td class="code"><pre><span class="line">/**</span><br><span class="line"> * 获得快照; 需要调用者负责清理;</span><br><span class="line"> * @return</span><br><span class="line"> */</span><br><span class="line">virtual const Snapshot* GetSnapshot() = 0;</span><br><span class="line"></span><br><span class="line">// Release a previously acquired snapshot.  The caller must not</span><br><span class="line">// use &quot;snapshot&quot; after this call.</span><br><span class="line">virtual void ReleaseSnapshot(const Snapshot* snapshot) = 0;</span><br><span class="line"></span><br><span class="line">// DB implementations can export properties about their state</span><br><span class="line">// via this method.  If &quot;property&quot; is a valid property understood by this</span><br><span class="line">// DB implementation, fills &quot;*value&quot; with its current value and returns</span><br><span class="line">// true.  Otherwise returns false.</span><br><span class="line">//</span><br><span class="line">//</span><br><span class="line">// Valid property names include:</span><br><span class="line">//</span><br><span class="line">//  &quot;leveldb.num-files-at-level&lt;N&gt;&quot; - return the number of files at level &lt;N&gt;,</span><br><span class="line">//     where &lt;N&gt; is an ASCII representation of a level number (e.g. &quot;0&quot;).</span><br><span class="line">//  &quot;leveldb.stats&quot; - returns a multi-line string that describes statistics</span><br><span class="line">//     about the internal operation of the DB.</span><br><span class="line">//  &quot;leveldb.sstables&quot; - returns a multi-line string that describes all</span><br><span class="line">//     of the sstables that make up the db contents.</span><br><span class="line">//  &quot;leveldb.approximate-memory-usage&quot; - returns the approximate number of</span><br><span class="line">//     bytes of memory in use by the DB.</span><br><span class="line"></span><br><span class="line">/**</span><br><span class="line"> * leveldb会有自己的统计信息，这个函数可以获得这些信息;</span><br><span class="line"> * @param property</span><br><span class="line"> * @param value</span><br><span class="line"> * @return</span><br><span class="line"> */</span><br><span class="line">virtual bool GetProperty(const Slice&amp; property, std::string* value) = 0;</span><br><span class="line"></span><br><span class="line">// For each i in [0,n-1], store in &quot;sizes[i]&quot;, the approximate</span><br><span class="line">// file system space used by keys in &quot;[range[i].start .. range[i].limit)&quot;.</span><br><span class="line">//</span><br><span class="line">// Note that the returned sizes measure file system space usage, so</span><br><span class="line">// if the user data compresses by a factor of ten, the returned</span><br><span class="line">// sizes will be one-tenth the size of the corresponding user data size.</span><br><span class="line">//</span><br><span class="line">// The results may not include the sizes of recently written data.</span><br><span class="line"></span><br><span class="line">/**</span><br><span class="line"> * 给key的范围、给level的层数，获得这些key大概的磁盘占用空间</span><br><span class="line"> * @param range</span><br><span class="line"> * @param n</span><br><span class="line"> * @param sizes</span><br><span class="line"> */</span><br><span class="line">virtual void GetApproximateSizes(const Range* range, int n,</span><br><span class="line">                                 uint64_t* sizes) = 0;</span><br><span class="line"></span><br><span class="line">// Compact the underlying storage for the key range [*begin,*end].</span><br><span class="line">// In particular, deleted and overwritten versions are discarded,</span><br><span class="line">// and the data is rearranged to reduce the cost of operations</span><br><span class="line">// needed to access the data.  This operation should typically only</span><br><span class="line">// be invoked by users who understand the underlying implementation.</span><br><span class="line">//</span><br><span class="line">// begin==nullptr is treated as a key before all keys in the database.</span><br><span class="line">// end==nullptr is treated as a key after all keys in the database.</span><br><span class="line">// Therefore the following call will compact the entire database:</span><br><span class="line">//    db-&gt;CompactRange(nullptr, nullptr);</span><br><span class="line"></span><br><span class="line">/**</span><br><span class="line"> * 手动触发指定key范围的compaction</span><br><span class="line"> * @param begin</span><br><span class="line"> * @param end</span><br><span class="line"> */</span><br><span class="line">virtual void CompactRange(const Slice* begin, const Slice* end) = 0;</span><br></pre></td></tr></table></figure>
<p><code>ReleaseSnapshot</code>这个也可以通过<code>shared_ptr</code>来进行封装，这样就省的自己操作了; <code>GetProperty</code>这个函数对后期真正线上使用的时候会特别有用，因为可以让leveldb吐出来很多leveldb自身的信息，方便查问题并且调整leveldb; 对于db来说，能清楚的知道db的状态是非常重要的;</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本系列文章主要是针对leveldb的源码分析; 个人也是重温这份源码，希望能在重新看的过程中学习到更多的知识;&lt;/p&gt;
&lt;h3 id=&quot;1-基本接口&quot;&gt;&lt;a href=&quot;#1-基本接口&quot; class=&quot;headerlink&quot; title=&quot;1. 基本接口&quot;&gt;&lt;/a&gt;1. 基
    
    </summary>
    
      <category term="源码分析" scheme="http://yoursite.com/categories/%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"/>
    
    
      <category term="leveldb" scheme="http://yoursite.com/tags/leveldb/"/>
    
  </entry>
  
  <entry>
    <title>想好要去试试看了</title>
    <link href="http://yoursite.com/2020/06/12/%E6%83%B3%E5%A5%BD%E8%A6%81%E5%8E%BB%E8%AF%95%E8%AF%95%E7%9C%8B%E4%BA%86/"/>
    <id>http://yoursite.com/2020/06/12/想好要去试试看了/</id>
    <published>2020-06-12T15:48:26.000Z</published>
    <updated>2020-06-12T17:06:30.272Z</updated>
    
    <content type="html"><![CDATA[<h3 id="1-这段时间的思考"><a href="#1-这段时间的思考" class="headerlink" title="1. 这段时间的思考"></a>1. 这段时间的思考</h3><p>上一个文章讲了我得到325这个事情；这个事情给我的打击和压力很大很大，我几乎有半个月的时间意志一直很低迷; 不过慢慢的我也看开了，而且开始专注于做新的事情，并且新老板还比较合得来，所以慢慢的好起来来的.</p>
<p>但是从那之后我还是从各方面打听了不少消息过来的；也找了一些朋友交心的聊了一下；感觉自己的处境的确还是比较尴尬的，而且最为主要的是我发现大老板这边我可能不大被看好，我做的事情其实不咋关心，他更加关心的是在另外场景下面的东西落地；但是按照我的想法，这个东西在一个环境没能很好的跑起来，马上就到内部使用，估计到时候会变得骑虎难下哦。</p>
<p>当然其实大老板怎么想和我关心不大，但是相对而言的是我做的事情对他而言无价值的话，就会导致后面325又落我头上，这不是坑爹吗. 而且我在和同事聊天的过程中发现，325是谁可周旋的余地太大了，和老板关系好一些，估计325就能变成3.5甚至于375; 所以，像我这种新人估计有点艰难..</p>
<p>第二点思考在于目前我的组织比较奇葩；我和我团队分割两地，团队几乎全在北京，而我一人在杭州；按照常规分析来说，可能不是一个很好的现象; 而且组织架构也很奇怪，估计后面绩效的还是有这边的大老板来确定，哎想想就有点怕;</p>
<p>第三点思考在于做的事情; 可能心中还是有一个追求技术的心，并且我感觉在这边做的事情，更多的是产品形态上东西，而且监控门槛太低了，能做的东西大家都在做，不能做的大家都不做；所以在差别上就是谁能更加全一些；所以在这里能得到的成长可能没有想象中的那么大；而且我感觉不开心，因为没成长没组织，平时就一个人做事情，这样对自己的心理压力还是很大的；可能现在还好，时间长了可能就不咋好了;</p>
<p>当然这段时间还在思考自己到底要什么东西? 在和包总聊的时候，包总聊到不可替代性这个东西；技术是一个非常容易被替代的东西，尤其当你做的技术还是很上层的东西，3年的熟练工和5～10年的你技术没有区别；那么对于我来说，是否只能往管理岗位走呢？我觉得难，因为这个转化非常难，而且也没有地方让你能做这种磨练和转化; 包总这种算是目标明确，现在也是完全得到了他们想要的，但是我呢？我的优势是什么呢？</p>
<table>
<thead>
<tr>
<th>优势</th>
<th>劣势</th>
</tr>
</thead>
<tbody>
<tr>
<td>技术水平还可以</td>
<td>毫无带团队的经验</td>
</tr>
<tr>
<td>对技术还是有追求</td>
<td>貌似没那么浓厚的技术倾向</td>
</tr>
<tr>
<td>目前31岁还年轻</td>
<td>剩下4年</td>
</tr>
<tr>
<td></td>
<td>想不到未来能做什么</td>
</tr>
</tbody>
</table>
<p>那么对于这些优势，我能在35之前的目标是什么呢？并且不会被淘汰呢; </p>
<ul>
<li><p>技术门槛性; 往某一个方面继续努力深挖;</p>
<ul>
<li>技术门槛</li>
<li>清晰产品形态</li>
</ul>
</li>
<li><p>往TL方向努力; 技术是一方面，但是管理这个东西还是后面主力的东西；这有点类似于在理财方面，随着经济周期的变化，你必须慢慢从一个资产过度到另外的资产，这样才能保证你持续的赚钱；而在职业生涯中也是这样的，慢慢从纯技术到技术+管理最后到整体的架构师之类的; </p>
</li>
</ul>
<p>对于这块，我目前在我司是看不到希望的；技术上明显还处于比较薄的地段；管理上，我根本就没什么管理的，就一个人在杭州呆着，我估计升上去的机会要好多年才能到我身上; 哎艰难..</p>
<h3 id="2-心中有了一个想法"><a href="#2-心中有了一个想法" class="headerlink" title="2. 心中有了一个想法"></a>2. 心中有了一个想法</h3><p>想尝试去其他的公司看看，能不能获得自己想要的东西;  如果有好的机会那就选择走，如果没有特别优秀的机会，那看在公司中还能不能熬一熬; 但是多个选择总比一个选择要好很多很多;</p>
<h3 id="3-需要做的准备"><a href="#3-需要做的准备" class="headerlink" title="3. 需要做的准备"></a>3. 需要做的准备</h3><p>目前我需要做的准备是:</p>
<h4 id="1-基础"><a href="#1-基础" class="headerlink" title="1. 基础"></a>1. 基础</h4><ul>
<li>操作系统: <ul>
<li><ol>
<li>看操作系统导论 </li>
</ol>
</li>
<li><ol start="2">
<li>找一个与linux结合比较近的操作系统课程来补习一下<a href="https://time.geekbang.org/column/article/105980" target="_blank" rel="noopener">趣谈Linux操作系统</a></li>
</ol>
</li>
</ul>
</li>
<li>网络: 直接看一下<a href="https://time.geekbang.org/column/article/8386" target="_blank" rel="noopener">趣谈网络协议</a></li>
<li>算法题: 关于这个，现在知乎上刷一些帖子，看是否有比较合适的方式来刷题，然后就进行比较系统的刷和总结吧;</li>
</ul>
<h4 id="2-语言层面（主要还是C-这个方面）"><a href="#2-语言层面（主要还是C-这个方面）" class="headerlink" title="2. 语言层面（主要还是C++这个方面）"></a>2. 语言层面（主要还是C++这个方面）</h4><ul>
<li><a href="https://time.geekbang.org/column/article/184018" target="_blank" rel="noopener">现代C++实战30讲</a>: 几乎把C++的最近的几个特点都比较好的讲了一下；但是缺少了并发的相关东西;</li>
<li><a href="https://time.geekbang.org/column/article/245259" target="_blank" rel="noopener">罗剑锋的C++实战笔记</a>： 目前重合度与上面重合度还是有点高，所以关于这块倒是选择性阅读;</li>
</ul>
<h4 id="3-一些有趣东西的深入"><a href="#3-一些有趣东西的深入" class="headerlink" title="3. 一些有趣东西的深入"></a>3. 一些有趣东西的深入</h4><ul>
<li><p>C++异步的网络框架: 之前我们用的是个facebook的folly + proxygen这个东西来模拟类似于netty；这边需要主要了解的是：</p>
<ul>
<li>future + promise是什么</li>
<li>带来了怎么样的变化</li>
<li>在boost.asio、folly、seastar中都是如何实现，之间有什么区别;</li>
</ul>
</li>
<li><p>协程这个东西的了解; 这块就是要自己深入一下，最好这次就啃下来这块东西，不会再被约束；而且结合目前C++20的stackless的实现来看看;</p>
</li>
<li><p>tcmalloc/jemalloc/malloc这块，对于这块主要连个操作系统的内存机制一起合着看会比较好掌握;</p>
</li>
</ul>
<h4 id="4-基础问题需要掌握的好的几个点"><a href="#4-基础问题需要掌握的好的几个点" class="headerlink" title="4. 基础问题需要掌握的好的几个点"></a>4. 基础问题需要掌握的好的几个点</h4><ul>
<li>进程、线程的概念和目前的调度机制</li>
<li>内存的分配机制</li>
<li>网络的技术问题</li>
<li>io协议栈之类的吧</li>
</ul>
<h4 id="5-领域"><a href="#5-领域" class="headerlink" title="5. 领域"></a>5. 领域</h4><ul>
<li>sentry的整体架构、原理、优势和缺点</li>
<li><p>influxdb的源码阅读</p>
<ul>
<li>文件存储</li>
<li>元信息的管理</li>
<li>时间线的管理</li>
<li>如果我来设计分布式方案要如何解决;</li>
</ul>
</li>
<li><p>整理监控领域的几个产品; </p>
<ul>
<li>sentry</li>
<li>influxdb</li>
<li>prometheus：产品形态、自身的分布式方案、thanos的分布式方案架构</li>
<li>open-falcon</li>
<li>opentsdb/kairsdb等</li>
<li><p>我司内部的监控产品</p>
<p>这边主要是比较有缺点，并且进行划分来看出各自的优缺点</p>
</li>
</ul>
</li>
<li><p>监控产品的全景形态</p>
<p>  从采集到存储到计算到展示和报警；每一块如何做到最优，最后服务好用户本身;</p>
</li>
<li><p>时序存储需要掌握的知识点</p>
<ul>
<li>分布式一致性协议; raft, 目前会按照<a href="https://time.geekbang.org/column/article/218938" target="_blank" rel="noopener">分布式协议与算法实战</a>来进行一步步的学习，主要是对源码和论文进行比较好的阅读;</li>
<li>mysql的一些列的概念;<a href="https://time.geekbang.org/column/article/75659" target="_blank" rel="noopener">MySQL实战45讲</a>, 大神课程，一定能收获很多;</li>
<li><p>leveldb：目前的源码能再次阅读，脉络要清晰; </p>
<ul>
<li>rocksdb的改造有哪些；</li>
<li>x-engine进行了哪些改造，为什么？</li>
<li>lsm的结构会遇到什么样子的问题，如何能优化和解决这些问题</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="6-其他"><a href="#6-其他" class="headerlink" title="6. 其他"></a>6. 其他</h4><ul>
<li>案件用例; 需要自己整理，并且对常规的方式进行了解; <a href="https://time.geekbang.org/column/article/230187" target="_blank" rel="noopener">系统性能调优必知必会</a></li>
<li>经验管理: 这块只能现学现卖吧；自己整理即可</li>
<li>对于过去这段时间的工作经验的解释: 这个需要找到能圆的过去的理由，不然难弄的;</li>
</ul>
<h3 id="4-给自己的时间"><a href="#4-给自己的时间" class="headerlink" title="4. 给自己的时间"></a>4. 给自己的时间</h3><p>目前准备给自己大概是1～1.5个月的时间; 因为内容还是比较多的，需要充分的准备时间；而且目前我手头项目有点忙，可能大部分时间都是课外时间；希望自己能慢慢坚持下来，最后能从多个选择中选择一些比较好的机会; 太难了..</p>
]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;1-这段时间的思考&quot;&gt;&lt;a href=&quot;#1-这段时间的思考&quot; class=&quot;headerlink&quot; title=&quot;1. 这段时间的思考&quot;&gt;&lt;/a&gt;1. 这段时间的思考&lt;/h3&gt;&lt;p&gt;上一个文章讲了我得到325这个事情；这个事情给我的打击和压力很大很大，我几乎有半
    
    </summary>
    
      <category term="思考" scheme="http://yoursite.com/categories/%E6%80%9D%E8%80%83/"/>
    
    
  </entry>
  
  <entry>
    <title>第一次3.25</title>
    <link href="http://yoursite.com/2020/04/23/%E7%AC%AC%E4%B8%80%E6%AC%A13-25/"/>
    <id>http://yoursite.com/2020/04/23/第一次3-25/</id>
    <published>2020-04-23T14:27:05.000Z</published>
    <updated>2020-04-23T14:59:57.538Z</updated>
    
    <content type="html"><![CDATA[<p>今天早上，新老板找我过一下绩效什么的; 我想总算是到了聊绩效的，我等年终奖等了好久呢；可是等来的是一个3.25；搞得我心情一天都很失落;</p>
<p>去年9月来了阿里，超过半年了; 我虽然觉得我做的东西并不多的，但是3.25总觉得有点过不去吧; 和新老板聊了一下，大概原因估计在与：和我层级不匹配之类的；还有没有主动的提意见并且没有作为技术专家的气势; 当然我觉得，主动、能提出意见、还有气势的什么的，都是不咋靠谱的；我毕竟只是一个新来的，在不熟悉系统、不熟悉人员的个性、不熟悉我们遇到了什么问题的情况下，你能我怎么样才能说到你想要的呢；</p>
<p>我自己其实承认这半年没有很主动的去承担这团队内的核心C位，但是我来这个团队的时候，团队是很稳定的，并且每一个位置都有人做了很久，我能做的只是帮他们负担一些需求；现在看来这样的方式其实并不是很好，因为这样我虽然做了很多的工作，但是得不到老板们的认可；真尼玛坑爹; 最近还为了别人的一个项目忙死忙活的，我实在是有点气愤；</p>
<p>当然我隐性的猜测到有一点是：前老板的这份评价有点针对我，而保护了其他人；其他人毕竟都是自己带出来的，而且跟了很多年；而且现在他要走了，估计后面也没有相处的机会，那就让我这个新人来背一个3.25的位置; 哎…当然这是我臆测；但是我估计从人性角度上来说，这个事情是肯定会在主观上去影响的，即使他觉得他没有; </p>
<p>哎..这3.25的锅一背上, 少说亏个10w块还是有的，真尼玛的不舍得; 哎…涨薪水 + 年终奖都泡汤了, 本来还想用这笔钱来抄个底之类的，现在什么都没有了…有点心烦意乱.</p>
<h3 id="教训是什么"><a href="#教训是什么" class="headerlink" title="教训是什么"></a>教训是什么</h3><p>与老板的聊天过程中，我自己多多少少能感悟到一些东西，这些东西是老板看重的，也是我需要做的一些:</p>
<ul>
<li><p>绩效考核的是在你这个层级，你在半年中，核心价值是什么; 核心价值是指你在某一块内容中承担了什么样的责任，并且你的核心价值解决的是什么样子的问题;这边需要明确的是，你的核心是解决什么问题，用了什么手段，达到了什么样子的效果；</p>
<ul>
<li>解决什么问题</li>
<li>使用什么手段</li>
<li><p>达到怎么样的效果</p>
<p>在设定自己的kpi的时候就需要思考好这个思路，并且按照这个思路去思考自己解决这个难题的方式是否是正确的，是否能达到自己的层级; </p>
</li>
</ul>
</li>
<li><p>老板其实不关心你做了多少事情；这边的事情指的是和你核心事情无关的其他的事情；这半年，我做了很多事情，比如输出、报警、sso登录其他的乱七八糟的事情，我都是做过，但是，老板基本不认可你这事情；他更加关心你的核心事情完成的怎么样? 所以后面要时刻要与老板聊这块的东西,要保证自己能有足够的时间来做自己的本职的事情;</p>
</li>
<li>多给老板做选择题，而非问答题; 因为这样会让老板觉得你比较有能力;</li>
<li>多提出意见和解决方案; 其实这块我觉得可以试试;</li>
<li>和老板多聊聊进度什么的, 让老板能时时刻刻知道目前的状态进度和你的想法;</li>
<li>最后最后，一定要记住自己的核心职责是什么？</li>
</ul>
<h3 id="机会"><a href="#机会" class="headerlink" title="机会"></a>机会</h3><p>说机会也是有的; 目前其实我们部门也不是没有危机，很多产品都在竞争，要做到在这个地方能脱引而出，还是需要做点手段的; 首先：</p>
<ul>
<li>你要解决的问题是什么？</li>
<li>你面向的场景是什么？</li>
<li>你要如何解决这个问题？</li>
<li>解决了这个问题之后会达到什么样子的成果?</li>
</ul>
<p>敏捷paas版本，我个人感觉还是机会，虽然不一定能赚钱什么的，但是推出之后可用的范围可以很大…</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;今天早上，新老板找我过一下绩效什么的; 我想总算是到了聊绩效的，我等年终奖等了好久呢；可是等来的是一个3.25；搞得我心情一天都很失落;&lt;/p&gt;
&lt;p&gt;去年9月来了阿里，超过半年了; 我虽然觉得我做的东西并不多的，但是3.25总觉得有点过不去吧; 和新老板聊了一下，大概原因
    
    </summary>
    
      <category term="心情" scheme="http://yoursite.com/categories/%E5%BF%83%E6%83%85/"/>
    
    
  </entry>
  
  <entry>
    <title>何为债券</title>
    <link href="http://yoursite.com/2020/03/03/%E4%BD%95%E4%B8%BA%E5%9B%BD%E5%80%BA/"/>
    <id>http://yoursite.com/2020/03/03/何为国债/</id>
    <published>2020-03-03T10:51:53.000Z</published>
    <updated>2020-03-03T12:36:32.839Z</updated>
    
    <content type="html"><![CDATA[<h3 id="1-债券"><a href="#1-债券" class="headerlink" title="1. 债券"></a>1. 债券</h3><ul>
<li>wiki-定义</li>
</ul>
<blockquote>
<p>债券(Notes)是政府、金融机构、工商企业等机构直接向社会借债筹措资金时，向投资者发行，承诺按一定利率支付利息并按约定条件偿还本金的债权债务凭证。债券的本质是债的证明书，具有法律效力。债券购买者与发行者之间是一种债权债务关系，债券发行人即债务人(Debtors)，投资者（或债券持有人）即债权人(Creditors)。最常见的债券为定息债券、浮息债券以及零息债券。</p>
</blockquote>
<ul>
<li>与银行贷款的不同</li>
</ul>
<blockquote>
<p>与银行信贷不同的是，债券是一种直接债务关系。银行信贷通过存款人——银行，银行——贷款人形成间接的债务关系。</p>
</blockquote>
<h4 id="债券的特性"><a href="#债券的特性" class="headerlink" title="债券的特性"></a>债券的特性</h4><ol>
<li>债券属于有价证券</li>
<li>债券是一种虚拟资本</li>
<li>债券是债权的表现</li>
</ol>
<h4 id="债券的基本要素"><a href="#债券的基本要素" class="headerlink" title="债券的基本要素"></a>债券的基本要素</h4><ul>
<li>债券价格：也就是债券的面值; 面值是固定的，但是购买这些债券的花费的价值是不固定的，有时候高有时候低;</li>
<li>债券利息: 债券利率是<strong>债券利息</strong>与<strong>债券面值</strong>的比率。债券利率分为固定利率和浮动利率两种。债券利率一般为年利率，面值与利率相乘可得出年利息。债券利率直接关系到债券的收益。影响债券利率的因素主要有银行利率水平、发行者的资信状况、债券的偿还期限和资金市场的供求情况等</li>
<li><p>债券还本期限与方式</p>
<ul>
<li>债券还本期限是指从债券发行到归还本金之间的时间</li>
<li>债券还本方式是指一次还本还是分期还本等，还本方式也应在债券票面上注明。</li>
</ul>
</li>
</ul>
<h4 id="债券的特征"><a href="#债券的特征" class="headerlink" title="债券的特征"></a>债券的特征</h4><ul>
<li>期限性</li>
<li>流动性: 仅仅次于储蓄存款；流动性非常好</li>
<li>收益性: 票息（债券利息） + 债券买卖价格差 = 债券收益率</li>
<li><p>安全性</p>
<p>  <strong>市场风险是指债券的市场价格随资本市场的利率上涨而下跌，因为债券的价格是与市场利率呈反方向变动的。当利率下跌时，债券的市场价格便上涨；而当利率上升时，债券的市场价格就下跌。而债券距离到期日越远，其价格受利率变动的影响越大。</strong></p>
</li>
<li><p>自主性</p>
</li>
</ul>
<h4 id="债券类型"><a href="#债券类型" class="headerlink" title="债券类型"></a>债券类型</h4><ul>
<li><p>按照发行主体分类</p>
<ul>
<li>政府</li>
<li>金融债券</li>
<li>企业债券</li>
</ul>
</li>
<li><p>按付息方式划分</p>
<ul>
<li><strong>贴现债券</strong>: 购买债券的时候，按照折扣来进行买；这样折扣就是利息;</li>
<li><strong>零息债券</strong>: 零息债券指债券到期时和本金一起一次性付息、利随本清，也可称为到期付息债券。付息特点一是利息一次性支付。二是债券到期时支付。</li>
<li><strong>附息债券</strong>: 附息债券指债券券面上附有息票的债券，是按照债券票面载明的利率及支付方式支付利息的债券。息票上标有利息额、支付利息的期限和债券号码等内容。持有人可从债券上剪下息票，并据此领取利息。附息国债的利息支付方式一般是在偿还期内按期付息，如每半年或一年付息一次。</li>
<li><strong>固定利率债券</strong>: 是在偿还期内利率固定的债券</li>
<li><strong>浮动利率债券</strong>: 浮动利率债券是指利率可以变动的债券。这种债券的利率确定与市场利率挂钩，一般高于市场利率的一定百分点。</li>
</ul>
</li>
<li><p>按照偿还期限划分</p>
<ul>
<li>长期：&gt; 10年; 我国是5年为分割点</li>
<li>中期:1 ~ 10年</li>
<li>短期: &lt; 1年</li>
</ul>
</li>
<li><p>按照是否可转换来区分</p>
<ul>
<li>可转债债券</li>
<li><p>不可转换债券</p>
<p>可转换债券是能按一定条件转换为其他金融工具的债券，而不可转换债券就是不能转化为其他金融工具的债券。可转换债券一般都是指的可转换公司债券，这种债券的持有者可按一定的条件根据自己的意愿将持有的债券转换成股票。</p>
</li>
</ul>
</li>
</ul>
<h3 id="2-债券市场"><a href="#2-债券市场" class="headerlink" title="2. 债券市场"></a>2. 债券市场</h3><p>债券市场, 分为一级市场和二级市场; 其实一开始我很不能理解，为什么会存在债券这种东西? 它存在的形式有的时候和股票那么像，可能买来买去，而且竟然价格还会那么不一致；这主要原因在于: </p>
<blockquote>
<p>债券市场，一个将债券变成可以交易的东西，而不再是只有两个人的关系; 现在的金融市场的基础是信用; 而债券本身就是信用证明，证明了其实期限一到就可以获得一笔钱; 这样以来，其实被借人可以将债券证明卖掉，来提前获得钱;</p>
<p>就这样,债券市场就产生了；那为什么会有价格高低呢? 原因在于每个时间点的利率是不一样的，与国家的基本利率有关系; 比如去年借钱利率是5%，但是今年就只有1%，那么如果5%的债券出来卖的时候价格肯定是高的，因为买走这个债券是有稳定的可预见的收益;</p>
</blockquote>
<h3 id="3-例子"><a href="#3-例子" class="headerlink" title="3. 例子"></a>3. 例子</h3><ol>
<li>2010年，利率为5%, A为B借了100元; 那么就产生了借条: 100元，年利率为5%</li>
<li>2013年, B已经拿了两年的利息, 也就是10元；但是由于他比较缺钱，他需要把这个借条卖掉; 这年的利率是1%；</li>
<li>因为2013年的利率很低，所以B卖出这个债券的价格就比债券本身的面值(100)要高; 比如卖出的价格是105元; </li>
<li>那么B总共赚的钱是 10 + 5 = 15; 那么他的年华收益率100 <em> (1 + x) </em> (1 + x) = 115; 年化利率大概是7%； 这个利率比银行高好多啊; </li>
</ol>
]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;1-债券&quot;&gt;&lt;a href=&quot;#1-债券&quot; class=&quot;headerlink&quot; title=&quot;1. 债券&quot;&gt;&lt;/a&gt;1. 债券&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;wiki-定义&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;债券(Notes)是政府、金融机构、工
    
    </summary>
    
      <category term="财经" scheme="http://yoursite.com/categories/%E8%B4%A2%E7%BB%8F/"/>
    
    
  </entry>
  
  <entry>
    <title>2019年-年终总结</title>
    <link href="http://yoursite.com/2020/01/20/2019%E5%B9%B4-%E5%B9%B4%E7%BB%88%E6%80%BB%E7%BB%93/"/>
    <id>http://yoursite.com/2020/01/20/2019年-年终总结/</id>
    <published>2020-01-20T08:54:29.000Z</published>
    <updated>2020-01-28T04:36:18.932Z</updated>
    
    <content type="html"><![CDATA[<p>2019年过完了; 今天离农历过年还有几天，属于很明显的垃圾时间,大家都比较轻松，并且事情也都能拖到年后来做，所以就找了今天下午出来酱油写一下去年的年终总结；其实每年的年终总结都挺水的，所以今年就稍微不同一下，总结一下去年的好的，今年想要做的；简单一些，不罗列太多无用的东西;</p>
<h3 id="1-去年总结"><a href="#1-去年总结" class="headerlink" title="1. 去年总结"></a>1. 去年总结</h3><p>去年做了几个选择，想了很久但是一直没有行动，去年一年就做了不少的改变，我觉得还挺好的，佩服自己的抉择;有的改变是主动的、有的是被动的，但是从目前来看都挺好的，就类似于伯爵说的，老天永远在往好的方向在推动我; 在这边谢谢老天爷;</p>
<h4 id="1-1-换了工作"><a href="#1-1-换了工作" class="headerlink" title="1.1 换了工作"></a>1.1 换了工作</h4><p>从1年多前就开始尝试出去面试，目标是阿里；总的来说，其实面的并不是很好；除了自己水平原因之外，很重要的一点在于我想做的一直是存储，导致面试阿里存储的时候我的水平一直没到位；后期，自己一直也在思考是否合适，并且也有补习相关的知识，慢慢的就转变了方向；开始面试自己比较擅长的监控领域，这个决策还是很ok的，一下子面试就进步很快; 可能是运气真的很好，来的这个部门刚刚有人走; 当时阿里的招聘的策略是走一个才能进一个，而且必须是7的层级; </p>
<p>面试过程比较顺利，并且进度也很快; 当然真的拿到offer的过程是挺漫长的；中间还去了一家神奇的公司，让我对小公司一下子就没有了好感；索性的是它在去年11月份就倒闭了，说真的心里挺开心的；因为这家公司真的很糟糕;</p>
<p>终于成功的来到了阿里，还是比较兴奋的; 因为一直想来这种世界级公司，看看什么不一样；而且毕业的时候也没成功进来; 来了阿里，其实整体的文化氛围还是很ok的，和之前的公司的感觉很像；大概率因为我们之前那个公司大部分是从阿里过去的，所以文化也超级像；所以适应这种环境还是很快的；</p>
<p>当然最艰难的主要是和同事相处；相处的还挺漫长，我也不知道如何和他们相处；不过虽然他们不怎么说话，但是整体很nice，我有什么问题他们都会积极的; 另外的问题就是适应他们的产品，而且需要寻找自己的定位；我不知道如何去介入到他们做的事情，做多了怕让他们觉得我抢工作，做少了又怕3.25；有点尴尬;</p>
<p>不管怎么说，工作换了，也算是走出了自己的舒服区；去尝试各种不一样的团队和不一样公司，让自己有着更加好的成长;</p>
<h4 id="1-2-开始持久的健身"><a href="#1-2-开始持久的健身" class="headerlink" title="1.2 开始持久的健身"></a>1.2 开始持久的健身</h4><p>去年过年回来之后，我花了将近2w元去办了一个健身卡和报了私交; 开始了自己的健身之路；成果挺好的；大概花了3个月就从160到了140，不过减肥之路还是很辛苦和花钱；不过我觉得值得，因为这是为自己投资；后面又胖回来了一点，但是整体通过持续的锻炼还ok；</p>
<p>今年依然还是买了1w块课程，准备比较系统的学习一下无氧的肌肉运动；但是目前感觉是自己貌似没有学到太多，只是每次让教练监督我练习；明年的话我也多请教一下教练好好的掌握技巧，能在后面自己就能完成练习;</p>
<p>自己健身主要是为了身材、健康和给自己一个目标；所以今年算是坚持下来了，后面要持续支持，让自己的身体更加健康;</p>
<h4 id="1-3-开始学习财务知识"><a href="#1-3-开始学习财务知识" class="headerlink" title="1.3 开始学习财务知识"></a>1.3 开始学习财务知识</h4><p>一直想，一直想学，但是总是没有行动；因为入门的那一脚有点难，一直借口着不去尝试；不过去年真的在离职的前几个月，也不知道为什么就开始认识了公司的一个朋友；其实他和我在公司的时间差不多，之前是认识的，但是不那么熟悉；但是因为kafka迁移让我们关系越来越熟悉，到后面饭后一起走路，到后面他给我们讲于我们不同的观点；慢慢的我就发现着就是我想要学习的东西；而现在这个时间点，这个人出现了，并且他真的很愿意和我们分享这些知识，于是我就下决心好好的把这块补上;</p>
<p>他家相对比较富裕，但是他有着更加遥远的梦想；他的观点是想要让自己做到财富自由；这边的财富自由值得是支付和被动收入相同，也就是即使不上班你也不会饿死；目前我的状态是工作是我唯一的收入，而我的支付有很多很多，房贷就是最大的支出；假设我不工作我感觉用不了多久我就活不下去了. 所以我的人生是被动的。而在遇到他之前，我的想法很简单的，就是如何去提高自己的工资，如何让工作给我赚更多的钱；这条一路走到黑。</p>
<p>关于这点，我突然想到了一个观点；每个人的格局或者视野什么的本来就是需要是被开阔的，不会有一个人天生就格局很大；普通人通常会是这样的一个过程，给了一条路，就觉得这条路就是适合自己，然后不断的往里面走，直到走到黑为止；但是其实可能这条本来就是错的，也不是唯一的，只不过是一开始冒失的一个选择而已；中国人真的很悲剧，在不了解的情况下，做出了人生后半辈子的选择，导致很多人在干的过程中很辛苦很累.而后半辈子因为生活压力的情况下，也不敢再去做尝试，只能默默的承受的这条路;</p>
<p>所以如果你觉得这条路走的很难受，或者你觉得前途很不行；那么是否可以考虑一下，是不是这条本来就不是自己选择的，而且也不知道有什么错误； 换条路是否可能；尤其是年轻人一定要多尝试；尝试可以让你不断去试错，直到找到自己觉得舒服的道路；事半功倍可能;</p>
<p>而对于已经承受着人生压力我来说，轻易的换肯定会导致生活的严重抖动；在计算机中就是要如何平滑重启；既然你已经在这条路上走了，那就先走着，但是你需要去接触除了这条路以外的事物，比如经济学，比如社会学，比如其他的任何东西；虽然你没有试错的机会，但是你可以通过主动学习去开阔自己的视野，这是一种准备，为未来的准备；现在可能会辛苦，但是当你在未来某一个时刻，你在做出选择的时候可能是多条路的选择，而不是一路走黑的选择； </p>
<p>昨天和一个小朋友聊；他说他可能还是有点喜欢计算机的，我说这个没问题，但是这不是你不去做尝试的借口；作为工作计算机可以帮你赚钱养家，但是它并非是你唯一的一条路，你的人生可以有多个路，这个路并非说现在就你让你来换，而是一种准备，在未来的某一个时刻，你发现计算机这条路已经不适合的你的时候，你有其他的路可以走；而且也会让你能更加早的去判断是否这条路合理; 如果合理那就更加应该努力学习而不是茫然;</p>
<p>说了那么多精神方面的，其实想说的总结：</p>
<ul>
<li>保持主动学习，这个学习不一定是看书，也可以尝试其他的东西;</li>
<li>学习可能现在没用，但是后面会有用;</li>
<li>等你的格局或者知识慢慢有变化之后，你就越是能判断当前这路的未来; 如果值得那就不会再迷失自己;</li>
<li>多接触非这条路上的人;</li>
</ul>
<p>关于自己，去年的观点有了比较多的转变; 我看了富爸爸系列的几本书，还看了基金相关的，虽然现在还挺糊涂的，但是慢慢的我觉得会好起来; 去年的投资也还ok，只不过大部分还是无脑操作；后面慢慢的需要去了解这一切的东西;</p>
<h4 id="1-4-存款"><a href="#1-4-存款" class="headerlink" title="1.4 存款"></a>1.4 存款</h4><p>去年基本完成了存款目标；也幸好是我那个朋友说，先让我存6个月的支出，然后放起来，其他的再来投资; 慢慢也有点积蓄能抗风险，希望未来能越来越好;</p>
<h3 id="2-2020年的规划"><a href="#2-2020年的规划" class="headerlink" title="2. 2020年的规划"></a>2. 2020年的规划</h3><p>今年的规划我只是想写个大方向，不想太过细节; 2019年虽然上面几个小目标都完成了，但是依然是一个打酱油的一年，2月份～9月在上一家公司安心的打着酱油, 9月～1月在新公司打酱油；</p>
<p>为什么能在新公司打酱油呢；主要还是因为这个领域能做的东西其实并不是很多，而且团队比较大，所以能分到自己手上的东西就很少。每天改console是我最主要的东西；说真的这个工作真没意思，没有任何挑战；本来到了年底想和老板好好聊聊，看看能不能从他未来的规划中找出一块有价值的事情；但是最后整个团队散了，老板和师兄都转岗了，我们部分团队和另外的团队合并了，另外一些全心做产品；我感觉这是一次机会，因为后面的远景很大的，世界级别的，而且是我喜欢做的技术相关的，有技术挑战性。来了这边我才觉得技术成长对我来说是什么？是一种快乐，是一种每天都愿意奋斗的动力. 所以2020-2021我的目前就是搞定这个世界级别的技术问题，然后能获得自己想要的成果;</p>
<h4 id="2-1-工作"><a href="#2-1-工作" class="headerlink" title="2.1 工作"></a>2.1 工作</h4><p>虽然不清楚后面要做什么，但是目前新老板画的饼我非常喜欢，真的是吃准了技术人员的大饼. 钱很重要，但是技术人员喜欢的挑战，目前我后面主要做我领域的基础技术平台开发, 后面要接入每秒上千万的tps. 我之前公司最最最顶峰的时候才100w，所以这太吸引我了. </p>
<p>我自己的打算是这样的：</p>
<ul>
<li>先承接住目前sunfire的稳定性; 目前主要是对整体的解决问题的能力、对一些细节的掌握，可能是我比较弱的点; 不过目前机会还是蛮好的，我的层级和目前机会的空缺，估计应该可以顺利的接过来; 主要我能主动点;</li>
<li>云监控那边我目前还不怎么清楚;但是我后面想主要放精力的两个方面是：1. 监控数据实时计算 2. 比较友好的预聚合方案 3. 存储引擎；关于展示和采集、报警我其实兴趣不大; 后面就往这块走;</li>
<li>研究一下开源的时序数据库和nosql的存储引擎，怎么样来调和两者;</li>
</ul>
<p>这次调整机会还是很大的，所以能不能抓住要看自己了；我觉得这已经是在我擅长的赛道上进行比赛了，所以老天已经对我很好了，要自己争气啊; 加油加油..</p>
<h4 id="2-2-财务理财"><a href="#2-2-财务理财" class="headerlink" title="2.2 财务理财"></a>2.2 财务理财</h4><p>2020年的目标是真正入门到这个行业,个人觉得可能需要从理论、观点和实战方面全方面进行; 虽然2019年已经开始进行了投资的行为，但是大部分还是通过感觉来进行的；所以2020年就像逐步构建自己的经济学的知识体系，通过实践来不断的完善自己的知识体系; 就目前想得到的目标有几个：</p>
<ul>
<li>能轻松分析国外和国内的公司财报</li>
<li>自己来操作基金组合定投</li>
<li>从跟着别人做资产配置变成自己做资产配置</li>
<li>做公司估值分析</li>
</ul>
<p>这几个方面可能需要看很多书，需要自律; 但是这是没有办法的，学习本来就是逆人性的过程，不能只是焦虑，需要的是去了解这些知识，为后面的未知做好准备; </p>
<p>目前这两条路是我预防我中年危机的手段; 上次在玩现金流游戏的时候让我知道了几个重要点:</p>
<ol>
<li>工资收入高，可以带来很多现金流; 工作上面的努力可以让你很快的积累现金流;</li>
<li>工资高如果支付高，那么想达到财富自由是不可能的; 所以尽可能避免无效开支，不能说因为收入很高，就花费很多; </li>
<li>被动收入真的很重要; 企业和房产的被动收入相差比较大; 需要在生活过程中不断的去寻找高回报的现金流资产. 这个过程可能很艰难，但是这可能是未来一条正确的道路，不然等真的到了35岁的时候，就真的一点办法都没了，我实在太害怕回到农村，我想给孩子一个好的环境，一个能让她尝试各种东西的环境；这样的环境能让她能让我能让我老婆做出心所向往的选择，而不是被迫无奈的选择.</li>
</ol>
<p>加油，2020年的自己…一定要自律自律自律，的确反人性，但是这才是真的吃苦;</p>
<h4 id="2-3-健身"><a href="#2-3-健身" class="headerlink" title="2.3 健身"></a>2.3 健身</h4><p>钱已经花了，后面就按照教练的课程好好练就好了; 但是2020年有几个想要完成的目标：</p>
<ul>
<li>体重达到120～130斤差不多;</li>
<li>学习一整套比较完整的动作，之后就按照这个套路训练就可以;</li>
</ul>
<h3 id="3-写给下一次看的自己"><a href="#3-写给下一次看的自己" class="headerlink" title="3. 写给下一次看的自己"></a>3. 写给下一次看的自己</h3><p>目标每年都定，不知道每年是否有回顾过自己的目标完成的程度; 希望每个一段时间都来回顾自己的计划，然后总结一下自己是否偏离目标，如果偏离合理，那么目标是否要调整; 2019年是一个不错的开始也有一个不错的结尾，后面就靠自己努力进步; 加油加油…</p>
<p>感情这个东西，对我来说真的很难驾驭，本身的性格缺陷，让我有的时候程度很难把握..哎.. 2020年我希望自己能大方一些，不要太在意很多小东西；并且主动去交流，我想这样一定会有点改善;</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;2019年过完了; 今天离农历过年还有几天，属于很明显的垃圾时间,大家都比较轻松，并且事情也都能拖到年后来做，所以就找了今天下午出来酱油写一下去年的年终总结；其实每年的年终总结都挺水的，所以今年就稍微不同一下，总结一下去年的好的，今年想要做的；简单一些，不罗列太多无用的东西
    
    </summary>
    
      <category term="总结" scheme="http://yoursite.com/categories/%E6%80%BB%E7%BB%93/"/>
    
    
  </entry>
  
  <entry>
    <title>关于Linux内存的一些知识</title>
    <link href="http://yoursite.com/2019/04/04/%E5%85%B3%E4%BA%8ELinux%E5%86%85%E5%AD%98%E7%9A%84%E4%B8%80%E4%BA%9B%E7%9F%A5%E8%AF%86/"/>
    <id>http://yoursite.com/2019/04/04/关于Linux内存的一些知识/</id>
    <published>2019-04-04T03:50:57.000Z</published>
    <updated>2019-04-18T06:24:26.000Z</updated>
    
    <content type="html"><![CDATA[<ol>
<li><p>页表</p>
<p> 每个进程都会有自己的页表，页表的主要的作用就是将虚拟地址转化为真实的物理地址；通过页表的架构是这样的：</p>
<p> <img src="media/9C2C6E33-E0C4-4EEC-9F24-37C2C6E6917E.png" alt="9C2C6E33-E0C4-4EEC-9F24-37C2C6E6917E"></p>
</li>
</ol>
<p>有三个部分组成</p>
<pre><code>* 页表目录
* 页表
* 偏移量
</code></pre><p>多级的好处是节省内存占用率，如果只有一级的话，那么即使不用全部的线程地址，也会占用很多无效内存; 所以多级可以有效的介绍这部分的开销;</p>
<p>那不同进程是如何找到自己的页表的物理地址呢？那么就要靠<code>cr3(控制寄存器)</code>，每次进程切换会把这个寄存器恢复，那么每次查找页表的时候就可以轻而易举的找到页表；</p>
<ol start="2">
<li><p>页表和页的权限控制</p>
<p> 根据User/Supervisor这个flag来设置权限;这个flag是存在页表项的;</p>
<ul>
<li>0: 必须是内核态才能访问</li>
<li><p>1: 总能访问</p>
<p>通过这个就可以保护内存的访问，有的只有内核态的进程才能访问;</p>
</li>
</ul>
</li>
<li><p>PAE（物理地址扩展）</p>
<p> 明明地址空间只有32bit，如何能使用超过4GB的物理内存空间呢；就出现了PAE了; 其本质在于在cr3这个寄存器上做了手段；cr3本身指向页表的物理地址，所以cr3可以变化，可以指向多个页表的物理地址就可以访问多个物理地址了；<br> 寻址空间依然是4GB，只不过通过切换来使用更多的内存；但是由于用户态的进程不能修改页表，所以它无法使用超过4GB的物理内存；</p>
</li>
<li><p>高速缓存和TLB</p>
<p> 高速缓存主要解决的是cpu与ram速度的巨大差异，用来缓解这个过程；在cpu和ram之间加入高速缓存，cpu直接访问cache而不是RAM；使用的原理当时就是局部性原理；</p>
<pre><code>* 时间局部性: 在一定返回内会重复执行某一些东西
* 空间局部性: 访问了一个地址空间的内容，有极大的概率会访问周边的内存
</code></pre><p> 高速缓存的组成是cacheline，每一个cacheline大概是64kb; 那么如果确定当前地址是否在cache中呢，其实方式依然还是用虚拟地址中的各个地址位来进行判断;目前有三种；</p>
<p> TLB: 我们知道虚拟地址转为物理地址需要通过查找页表来进行；那么我们也知道RAM的速率和cpu相比很慢，如果每次都走一次RAM那基本上就没得玩了；所以TLB就是一个保存virtual-&gt;phyical的一个kv硬件缓存；但是当cr3这个寄存器修改的时候，TLB就会失效；so 切换进程是多么耗时的事情;</p>
</li>
<li><p>物理内存分布</p>
<p> 内核会将下面的页框保留下来，不会被动态分配和交换到磁盘上去 </p>
<ul>
<li>在不可用的物理地址范围内的页框</li>
<li><p>含有内核代码和已初始化的数据结构的页框</p>
<p>内核通常为了能保存在物理内存上连续存储，会选择跳过第一个MB，从0x00100000的物理地址开始使用;</p>
</li>
</ul>
</li>
<li><p>内核页表</p>
<p> 进程的页表在内核部分的页表是公用的；通过的方式是每次生成一个新的进程的时候，新的页表中内核页表是指向原来的进程是一样的；而用户态的页表是使用cow的方式，虽然也是一样的，从一开始来说;</p>
</li>
<li><p>缓存和tlb</p>
<ul>
<li><p>TLB高速缓存的刷新是内核而不是硬件；</p>
<p>  通常情况来说，进程切换的时候就会让tlb失效；内核在进行cr3变更的时候就会触发这个操作; 下面的几个情况，内核会避免TLB切换:</p>
<ul>
<li>当两个使用相同页表集的普通进程之间执行切换的时候；比如线程的切换</li>
<li>当一个普通进程和一个内核线程间进行切换的时候；因为内核线程是没有自己单独的页表的，而是内核统一的页表；所以切换的时候内核其实还是用进程之前的页表;</li>
</ul>
</li>
</ul>
</li>
</ol>
]]></content>
    
    <summary type="html">
    
      &lt;ol&gt;
&lt;li&gt;&lt;p&gt;页表&lt;/p&gt;
&lt;p&gt; 每个进程都会有自己的页表，页表的主要的作用就是将虚拟地址转化为真实的物理地址；通过页表的架构是这样的：&lt;/p&gt;
&lt;p&gt; &lt;img src=&quot;media/9C2C6E33-E0C4-4EEC-9F24-37C2C6E6917E.png&quot;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>关于线程、进程、协程的了解</title>
    <link href="http://yoursite.com/2019/03/29/%E5%85%B3%E4%BA%8E%E7%BA%BF%E7%A8%8B%E3%80%81%E8%BF%9B%E7%A8%8B%E3%80%81%E5%8D%8F%E7%A8%8B%E7%9A%84%E4%BA%86%E8%A7%A3/"/>
    <id>http://yoursite.com/2019/03/29/关于线程、进程、协程的了解/</id>
    <published>2019-03-29T03:02:16.000Z</published>
    <updated>2019-04-02T15:11:10.000Z</updated>
    
    <content type="html"><![CDATA[<ol>
<li><p>虚拟地址、物理地址</p>
<p> linux的内存管理模块将物理地址封装到了底层，也就是说物理地址只有操作系统内核在管理，而程序员或者程序本身能获得的地址都是虚拟地址； 这么做的好处是:</p>
<ul>
<li>每一个进程有着独立和相同范围的虚拟地址; 与物理地址的关系有os来管理，每一个进程都会维护一个页表，这就是对应关系;</li>
<li>对权限管理会更加好做，防止进程访问相互的内存地址空间;</li>
</ul>
</li>
<li><p>进程之间的fork</p>
<p> linux的进程通过fork的方式创建子进程，当子进程创建初期，子进程和父进程是一样的；一样主要体现在页表内容是一致的；也就是表示两个进程的虚拟地址指向的物理地址一样的；如果一致一样肯定是不行的；所以当两个进程谁修改了对应的数据，就会以copy-on-write的方式来进行修改，其实本质就是修改虚拟地址指向其他的物理页;</p>
</li>
<li><p>进程描述符(每一个进程的一生的档案)</p>
<p> linux虽有线程概念，其本质依然还是进程，每一个线程都有进程描述符，但是线程与进程的区别在于有一些东西可以共享；每一个进程(线程)都存在一个pid；操作系统为了能更加好管理pid的空闲状态，通常会使用bitmap来保存使用状态；32bit的操作系统，通过会使用一个页来保存这些信息，这些信息会永久的存放在内存中; 64bit就会更加多一些;</p>
<p> 一个进程通常会有多个线程，线程与进程一致会存在pid，那么进程的pid是什么呢？linux中的方式就是将本线程组的pid设置会当前进程的pid，其实进程的pid就是线程组的tgid;</p>
</li>
<li><p>等待队列</p>
</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">struct wait_queue_t&#123;</span><br><span class="line">    unsigned int flags; // 0: 非互斥唤醒(将进程全部唤醒) 1:互斥唤醒(只唤醒一个等待的进程)</span><br><span class="line">    struct task_struct* task; //唤醒的具体的task</span><br><span class="line">    wait_queue_func_t func; // 等待队列中的睡眠进程应该用什么方式唤醒；</span><br><span class="line">    struct list_head task_list; // 等待线程链表</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">wait_queue_t是等待队列的item;</span><br></pre></td></tr></table></figure>
<p>进程被阻塞或者等待的过程:</p>
<pre><code>1. 定义wait_queue_t的变量，然后使用init_waitqueue_entry来初始化变量
2. 将等待的变量加入到等待队列中去
3. schedule触发cpu调度
4. 当触发事件完成之后，回归到当前进程的第一件事就是删除等待队列这个变量；
</code></pre><p>wake_up的过程:如果某一个事件发生了,那么内核就会找到对应的等待队列，然后进行唤醒:</p>
<pre><code>1. 获得等待队列表头
2. 轮训队列
3. 如果等待的任务是非互斥的任务就进行唤醒
4. 如果等待的任务是互斥的，并且只是第一次被唤醒的话，那么就推出wake_up

这个任务等待队列有两个前提： 1. 非互斥的任务一定是放在互斥的任务之前 2. 任务可能会被超过一次唤醒，不过我猜应该可能保证是否已经被触发过；
</code></pre><ol start="5">
<li><p>进程切换（重点）</p>
<blockquote>
<p>进程切换、任务切换、context切换是指内核有能力挂起cpu上运行的进程，并恢复以前挂起的某一个进程的执行;</p>
</blockquote>
</li>
</ol>
<pre><code>&gt; cs: 代码段寄存器, ip: 指令指针寄存器，指向cpu下一条要运行的指令或者当前正在执行的指令;


进程切换首先需要了解，切换过程涉及到了什么呢？

* 硬件上下文：主要是指进程在恢复到cpu上运行的时候，必须恢复的寄存器数据; 硬件上下文仅仅只是进程切换的一个子集；这个上下文一部分存放在tss段，一部分存放在内核堆栈上;

    * 进程切换只发生在内核态，在进程进程切换之前，**用户态进程使用的所有寄存器**内容都会保存在**内核态堆栈**上，包括了ss和esp这对寄存器内存; 
    * 进程切换大部分是否是在时间中断的时候被触发，触发的过程会导致进程调度，所以才会只有在内核中存在；

* tss(task state segment): 任务状态段,虽然linux不使用硬件切换，但是强制每一个cpu会创建一个tss，原因:

    * 用户态到内核态切换的时候，可以从tss中获得内核堆栈的地址;
    * 进程IO性能的时候好，可以通过tss获得IO位图来检查权限;

    tss反映了CPU上的当前进程的特权级别; 因为linux不是每个进程一个tss，而是一个cpu一个tss，所以在切换的时候需要保存被替换的硬件上下文,这个和intel的原先设计有点出入;

* 进程描述符的thread字段，linux会被硬件上下文保存在这个字段中;

* Linux的进程切换的schedule函数

    1.切换页全局目录以安装一个新的地址空间
    2.切换内核态堆栈和硬件上下文，因为硬件上下文提供了内核执行新进程的所需要的所有信息，包括cpu寄存器

* switch_to(prev,next,last)

    * prev: 当前进程
    * next: 切换到目标的进程
    * last: 指向当前进程，其实就是prev的内存地址;

    1. 通常切换参数为prev,next,last,调用了switch_to之后这些参数通过压stack的方式保存在内核栈中;
    2. 将prev的内容写入到cpu的eax寄存器
    3. 恢复到next进程的内核栈；**注意注意：由于恢复到了next的内核栈，那么prev其实不在是真正的prev的，而是之前next在调用switch_to被切换出去的时候自己**，所以通过eax来将prev替换
    4. 将prev赋值给last

* switch_to 代码
</code></pre><ul>
<li><p>进程创建</p>
<blockquote>
<p>通用寄存器的值是在从用户态切换到内核态时被保存到内核态堆栈中的;</p>
</blockquote>
<p>  Linux进程创建的优化：</p>
<ul>
<li>子进程复制父进程的资源；并非是完全copy；而是使用了COW的方式进行优化</li>
<li>线程和进程，线程其实就是Linux中轻量级的进程，只不过使用了共享父进程的很多资源来保证高效创建；</li>
<li><p>vfork:共享父进程的内存地址空间，又不具有cow性质;</p>
<p>总结：进程创建过程中，子进程必须要申请的资源是task_struct和对应的内核栈的空间，所以内核栈是每个线程或者进程都会存在一个的; 虽然在空间上是分离的，但是在赋值的时候还是会将父进程的大部分东西赋值给子进程，尤其是在操作过程将描述符的很多字段进行赋值；这个过程中有几点需要明确:</p>
<ul>
<li>描述符进行了赋值、thread也进行了部分赋值；但是esp、eax这些寄存器值确是自己的；因为这        是很重要的,esp指向的是子进程内核, eax是存放系统调用的返回值,因为fork会返回两个值，返回父进程的是子进程的pid，而返回给子进程是0; eip用于存储下一条执行的指令;</li>
<li>执行完clone之后，进程就可以被调度了；当子进程被调度到的时候，就会将内核栈存储的硬件上下文装载到cpu，这样可以是cpu恢复到用户态模式；这个时候父进程和子进程有一些不一样的，1是进程描述符不一样，2. 进程内核栈不一样；3.eax不一样的； 但是代码段是共享的，所以通过eax（返回值不一样）可以判断是子进程还是父进程；虽然大部分的资源是共享的，但是通过修改寄存器的值来保证子进程的运行;</li>
</ul>
</li>
</ul>
</li>
<li><p>内核线程</p>
</li>
</ul>
<p>区别点：</p>
<pre><code>* 内核线程只会运行在内核态；普通进程可以在用户态也可以在内核态
* 内核线程只能访问PAGWE_OFFSET以上的线性地址，而普通线程可以是全部的线性地址；
</code></pre><p>自己的理解可能是这样的，内核线程之间是共享地址空间的；类似于一个进程下面的线程一样，使用了相同的地址空间; 所有的内核线程其实使用了一个地址空间，而且地址空间的范围也是一定的；创建内核线程与普通进程创建是一致的；</p>
<pre><code>* 进程0:所有进程的祖先，这个是linux初始化的时候静态分配的，而其他的进程都是动态分配
* 创建pid为1的进程，然后进程0开始执行cpu idle的函数，这个函数主要是用于没有runing进程的时候就开始执行cpuidle的任务
</code></pre><p>其他的内核线程</p>
<pre><code>* keventd(事件)：执行keventd_wq工作队列
* kaqmq：与电源相关的事件
* kswapd: 执行内存回收
* pdflush: pagecache脏页会写
* kblockd: 执行kblock_workqueue工作队列的函数。它周期性地激活块设备驱动
* ksoftirq: 执行tasklet，每个cpu都有这样的内核线程
</code></pre><ul>
<li><p>进程终止</p>
<p>  当父进程使用wait处理了子进程挂的信号，那么这个时候子进程的最后资源就会被回收，这部分资源主要是集中在进程描述符上面，还有就是thread对象和内核栈</p>
</li>
</ul>
<ul>
<li><p>线程和进程的区别在于：</p>
<ul>
<li>在linux下面线程其实被当作进程处理，有着自己的task_struct结构，只不过线程在创建过程中会共享父进程的内存空间地址;</li>
<li>因为是被当作单独的task来处理，所以线程有着自己的内核栈; 当线程因为某一种关系进入内核的时候需要内核栈来保存硬件上下文(寄存器等值)</li>
<li>线程有着自己的寄存器的值</li>
<li><p>线程有着自己的stack；如果公用主线程的stack就会破坏stack结构;</p>
<p>fork如果创建的是一个子进程，也就说flag没有带上CLONE_VM的话，那么就表示子进程有着自己独立的地址空间，只不过只不过一开始的时候内容是和父进程是一样的；但是但是这过程中有一个页表copy的过程；</p>
</li>
</ul>
</li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;ol&gt;
&lt;li&gt;&lt;p&gt;虚拟地址、物理地址&lt;/p&gt;
&lt;p&gt; linux的内存管理模块将物理地址封装到了底层，也就是说物理地址只有操作系统内核在管理，而程序员或者程序本身能获得的地址都是虚拟地址； 这么做的好处是:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;每一个进程有着独立和相同范围的虚拟地址;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>整理</title>
    <link href="http://yoursite.com/2019/01/10/%E6%95%B4%E7%90%86/"/>
    <id>http://yoursite.com/2019/01/10/整理/</id>
    <published>2019-01-10T02:11:15.000Z</published>
    <updated>2019-03-29T03:00:40.000Z</updated>
    
    <content type="html"><![CDATA[<p>2018年末2019年初，又开始新的一年面试;昨天晚上面了一个做存储的公司，全程基本上都是被压着问，通过这次面试给我最大的感悟就是基础知识需要扎实，并且要互联起来; 知识点除了要知道还要知道为什么这么设计; 这次面试对基础询问真的很多很多;</p>
<h3 id="1-问题"><a href="#1-问题" class="headerlink" title="1. 问题"></a>1. 问题</h3><ul>
<li>面试题: 对于一个有序数组，找到第一个大于等于目标value的index; </li>
</ul>
<blockquote>
<p>一看就是一个二分法查询的过程，但是我当时脑中一片混乱，实在是不知道怎么办; 这个对二分法需要进行改造，主要是在小于等于中间值的时候，需要去比较前面一个值的大小，如果小那就指定的值，如果大于目标值那就在二分查找一下;</p>
</blockquote>
<ul>
<li><p>C++系列的问题</p>
<ul>
<li><p>new、delete和free、malloc的区别; 为什么对于数组new和delete需要加上<code>[]</code>来做区别</p>
<ol>
<li>new 除了可以在堆上使用，也可以用户自定义内存地址来申请;</li>
<li>new即会申请内存空间也会调用数据类型的构造函数初始化;</li>
<li>为什么数组new需要带上<code>[]</code>, 本质上依然还是需要告诉编译器去调用构造函数; 而delete带有<code>[]</code>则是为了调用析构函数</li>
</ol>
</li>
</ul>
</li>
<li><p>右值引用是什么? 推出的目的又是什么?</p>
</li>
<li>vector的push_back的时间复杂度是多少? O(1), 均摊下来应该是常量</li>
<li><p>C++ 6种内存模型;</p>
<ul>
<li>内存模型用来解决什么问题</li>
<li>具体的区别什么</li>
</ul>
</li>
<li><p>linux的问题</p>
<ul>
<li>进程、线程、协程之前的区别点;<ul>
<li>进程、线程、协程切换上下文切换需要保存哪些信息</li>
</ul>
</li>
<li>load定义</li>
<li>虚拟地址空间的排布</li>
</ul>
</li>
<li><p>网络</p>
<ul>
<li>tcp三次握手和断开的4次握手;  这边深究了一下为什么三次握手需要三次而不是二次或者其他</li>
<li>epoll的作用，实现原理，为什么高效</li>
</ul>
</li>
<li><p>存储</p>
<ul>
<li>介绍一下LSM-Tree结构</li>
<li><p>rocksdb查询过程; </p>
<ul>
<li>假如没有分层会怎么样,都聚集在L0层查询效率会变差很多</li>
<li>compaction的过程？写放大是如何计算方式?</li>
<li>writeBatch的作用</li>
<li>writeBatch的原子性是如何实现的</li>
<li>rocksdb对读优化有哪些   </li>
</ul>
</li>
</ul>
</li>
<li><p>共识</p>
<ul>
<li>raft整体过程</li>
</ul>
</li>
<li><p>事务</p>
<ul>
<li>acid</li>
<li>隔离性的几种</li>
</ul>
</li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;2018年末2019年初，又开始新的一年面试;昨天晚上面了一个做存储的公司，全程基本上都是被压着问，通过这次面试给我最大的感悟就是基础知识需要扎实，并且要互联起来; 知识点除了要知道还要知道为什么这么设计; 这次面试对基础询问真的很多很多;&lt;/p&gt;
&lt;h3 id=&quot;1-问题
    
    </summary>
    
      <category term="interview" scheme="http://yoursite.com/categories/interview/"/>
    
    
      <category term="存储" scheme="http://yoursite.com/tags/%E5%AD%98%E5%82%A8/"/>
    
  </entry>
  
  <entry>
    <title>进程调度之死循环</title>
    <link href="http://yoursite.com/2017/04/12/%E8%BF%9B%E7%A8%8B%E8%B0%83%E5%BA%A6%E4%B9%8B%E6%AD%BB%E5%BE%AA%E7%8E%AF/"/>
    <id>http://yoursite.com/2017/04/12/进程调度之死循环/</id>
    <published>2017-04-12T14:21:34.000Z</published>
    <updated>2017-04-13T01:52:30.000Z</updated>
    
    <content type="html"><![CDATA[<p>这篇文章主要讲的是Linux的进程调度问题，但是能形象的解释其中的一系列的观点，所以找了一个比较经典问题来做载体. 在具体开始之前，先了解一下什么是进程调度呢？</p>
<blockquote>
<p>个人的理解是: 目前操作系统基本都是多任务操作系统，也就是说一个操作系统中存在有多个进程，但是CPU资源是有限的，不能让所有的进程都能一直在运行；所以调度系统就是一个将cpu资源合理分配给各个可运行状态的进程的内核子系统,是多任务操作系统的基础;</p>
</blockquote>
<p>貌似很复杂难懂的调度系统有着一个非常简单的目标: <strong>最大限度利用CPU的处理时间</strong>; 调度系统的基本任务就是: <strong>从多个可运行状态的进程中挑选出一个合适的进程来运行</strong>, 这里的<strong>合适</strong>也是调度系统的核心算法.</p>
<h4 id="1-提问"><a href="#1-提问" class="headerlink" title="1. 提问"></a>1. 提问</h4><p><em>为什么死循环能让CPU利用达到100%呢?</em> </p>
<p>这个问题也是困扰我多年的问题，当然可能就是因为对Linux操作系统的进程调度没有学好才导致这个问题一直困扰我. 针对上面的问题还能引出几个其他的问题?</p>
<ul>
<li>死循环是否会导致系统响应速度下降;</li>
<li></li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;这篇文章主要讲的是Linux的进程调度问题，但是能形象的解释其中的一系列的观点，所以找了一个比较经典问题来做载体. 在具体开始之前，先了解一下什么是进程调度呢？&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;个人的理解是: 目前操作系统基本都是多任务操作系统，也就是说一个操作系统
    
    </summary>
    
      <category term="Linux" scheme="http://yoursite.com/categories/Linux/"/>
    
    
      <category term="进程调度" scheme="http://yoursite.com/tags/%E8%BF%9B%E7%A8%8B%E8%B0%83%E5%BA%A6/"/>
    
  </entry>
  
  <entry>
    <title>Linux进程管理</title>
    <link href="http://yoursite.com/2017/04/07/Linux%E4%B9%8B%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/"/>
    <id>http://yoursite.com/2017/04/07/Linux之进程管理/</id>
    <published>2017-04-06T23:16:14.000Z</published>
    <updated>2017-04-10T13:48:43.000Z</updated>
    
    <content type="html"><![CDATA[<p>Linux系统本身没有对线程做出特殊的改造，在Linux中线程本身与创建进程的流程是一样的；唯一与进程的区别是在创建过程中，进程的创建是资源独立的，而线程在创建的过程中，会与其他的进程共享一些资源；所以在Linux中，线程本就是进程，一个有着一点点不同的进程.</p>
<p>Linux中每一个进程都会有一个统一的结构<code>task_struct(进程描述符)</code>, 这个结构包含了进程的所有的信息，包括状态、占有的资源、内存空间等一些; Linux将这些进程描述符放在任务队列中来分别进行调用.</p>
<h4 id="1-进程的状态"><a href="#1-进程的状态" class="headerlink" title="1. 进程的状态"></a>1. 进程的状态</h4><ul>
<li>TASK_RUNNING(运行 or 就绪): 这个状态的进程要不就是正在运行或者在运行队列中等待运行; </li>
<li>TASK_INTERRUPTIBLE(中断): 表示当前进程处于等待状态，直到某一个条件为真或者传递一个信号都能唤醒进程;</li>
<li>TASK_UNINTERRUPTIBLE:与TASK_INTERRUPTIBLE类似，只是这个状态的进程不会因为信号而被唤醒;</li>
<li>TASK_STOPPED:进程执行被暂停，当收到到SIGSTOP、SIGTSTP、SIGTTIN、SIGTTOU等信号的时候;</li>
<li>TASK_ZOMBIE: 进程执行被终止，但是父进程还没有调用wait4或waitpid来收集信息;</li>
<li>TASK_DEAD:进程彻底死亡状态</li>
<li>TASK_TRACED:跟踪状态，用于debug</li>
</ul>
<h4 id="2-进程的创建"><a href="#2-进程的创建" class="headerlink" title="2. 进程的创建"></a>2. 进程的创建</h4><p>上面已经说了，Linux的进程和线程的创建几乎是一模一样的，只是后面会有点点小小的区别;Linux创建进程的过程主要依赖两个系统调用fork+exec; </p>
<h5 id="2-1-fork"><a href="#2-1-fork" class="headerlink" title="2.1 fork"></a>2.1 fork</h5><p>进程调用fork就可以创建子进程；之前的fork是比较粗暴，直接复制所有的资源给子进程，但是这样效率比较低效，因为子进程通过会通过exec来加载另外的程序，那么之前的copy过程就是无用功. 所谓的<code>copy-on-write</code>，就是在调用fork的时候只分配一些进程与进程之间必须独立的资源，比如task_struct结构体、页表(内容是copy父进程的)、内核栈等，其他的资源都是父进程的引用而已;通过这种方式来提高性能.</p>
<p>fork的基本流程是如下:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">st=&gt;start: 开始</span><br><span class="line">e=&gt;end: 结束</span><br><span class="line">fork=&gt;operation: fork</span><br><span class="line">clone=&gt;operation: clone</span><br><span class="line">dofork=&gt;operation: do_fork</span><br><span class="line">dup=&gt;operation: copy一个父进程的进程描述符(比如内核栈、task_struct、thread_info，这些可能是每一个进程所必须的结构)</span><br><span class="line">setstate=&gt;operation: 设置子进程状态，并且修改进程描述符做区别</span><br><span class="line">copy=&gt;operation: 根据clone传入的参数来进行资源copy</span><br><span class="line">run=&gt;operation: 平分时间片，然后将子进程唤醒</span><br><span class="line"></span><br><span class="line">st-&gt;fork-&gt;clone-&gt;dofork-&gt;dup-&gt;setstate-&gt;copy-&gt;run-&gt;e</span><br></pre></td></tr></table></figure>
<h5 id="2-2-关于Linux中的线程"><a href="#2-2-关于Linux中的线程" class="headerlink" title="2.2 关于Linux中的线程"></a>2.2 关于Linux中的线程</h5><p>上面说了，Linux的线程其实就是linux的进程，只是在创建的时候传给<code>clone</code>函数的参数上有一些不一样的; </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">clone(CLONE_VM | CLONE_FS | CLONE_FILES | CLONE_SIGHAND, 0);</span><br></pre></td></tr></table></figure>
<p>线程在创建的时候通过传入以上的几个参数，这可能就是与进程创建区别了，这样创建的进程与父进程是共享地址空间、文件系统、打开的文件、信号处理函数；所以从这看出，Linux所谓的线程本质其实就是进程。</p>
<h5 id="2-3-内核线程-Kernal-thread"><a href="#2-3-内核线程-Kernal-thread" class="headerlink" title="2.3 内核线程(Kernal thread)"></a>2.3 内核线程(Kernal thread)</h5><p>内核线程与普通的进程的区别在于</p>
<pre><code>* 内核线程没有独立的地址空间
* 只运行在内核态，从不切换到用户态
</code></pre><p>其他是类似的，可以被抢占，也可以被调度;</p>
<h4 id="3-进程死亡"><a href="#3-进程死亡" class="headerlink" title="3. 进程死亡"></a>3. 进程死亡</h4><p>每一个进程总会面临死亡的过程，那么进程的死亡要经过哪几个步骤呢？一个进程的创建的过程是赋予资源，那么进程死亡就是归还资源的过程;</p>
<p>什么时候进程会面临终结呢? 显示的调用了<code>exit()</code>这个系统调用，或者是被动总结，不管怎么样触发，这个过程都有<code>do_exit</code>完成;</p>
<ul>
<li>释放各种资源</li>
<li>设置进程的状态为TASK_ZOMBIE</li>
<li>发送信号给父进程，说我快终结了</li>
<li>调用schedule函数，主动的放弃cpu</li>
</ul>
<p>到此为止，进程已经释放了大部分的资源，不过还保存着进程描述符、内核栈、thread_info等一些必要的数据结构，直到父进程调用<code>wait4()</code>系统收集子进程的一些状态，那么这进程就真正的终结;Linux将资源清理与进程描述符清理分开执行;</p>
<h4 id="4-总结"><a href="#4-总结" class="headerlink" title="4. 总结"></a>4. 总结</h4><ul>
<li>进程状态</li>
<li>Linux 进程与线程是同样的东西;</li>
<li>进程的创建与死亡</li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Linux系统本身没有对线程做出特殊的改造，在Linux中线程本身与创建进程的流程是一样的；唯一与进程的区别是在创建过程中，进程的创建是资源独立的，而线程在创建的过程中，会与其他的进程共享一些资源；所以在Linux中，线程本就是进程，一个有着一点点不同的进程.&lt;/p&gt;
&lt;p
    
    </summary>
    
      <category term="Linux" scheme="http://yoursite.com/categories/Linux/"/>
    
    
      <category term="进程" scheme="http://yoursite.com/tags/%E8%BF%9B%E7%A8%8B/"/>
    
      <category term="书笔记" scheme="http://yoursite.com/tags/%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title>scylladb 官文安装译文</title>
    <link href="http://yoursite.com/2017/04/04/scylladb-%E5%AE%98%E6%96%87%E5%AE%89%E8%A3%85%E8%AF%91%E6%96%87/"/>
    <id>http://yoursite.com/2017/04/04/scylladb-官文安装译文/</id>
    <published>2017-04-04T11:56:06.000Z</published>
    <updated>2017-04-06T23:16:49.000Z</updated>
    
    <content type="html"><![CDATA[<p>主要的依赖于官方的教程，这边主要是将一些细节进行串联描述，下次安装的时候会更加自动化;</p>
<p>我的安装环境如下：</p>
<ul>
<li>centos7.2</li>
<li>内核版本为3.18</li>
</ul>
<h4 id="1-关于scylladb几个rpm的介绍"><a href="#1-关于scylladb几个rpm的介绍" class="headerlink" title="1. 关于scylladb几个rpm的介绍"></a>1. 关于scylladb几个rpm的介绍</h4><ul>
<li>scylla-server(standard):scylladb主要的server端</li>
<li>scylla-server(debuginfo):scylladb server端并且带有debuginfo</li>
<li>scylla-jmx: 兼容cassandra通过jmx端口进行访问</li>
<li>scylla-tools: scylla为了兼容cassandra而提供的类似的功能:<ul>
<li>nodetool:很强大的功能，用来观察集群状态</li>
<li>cqlsh:</li>
<li>cassandra-stress:压测工具</li>
</ul>
</li>
</ul>
<h4 id="2-前期准备"><a href="#2-前期准备" class="headerlink" title="2.前期准备"></a>2.前期准备</h4><ul>
<li>删除abrt,主要是这个与scylladb本身的coredump配置冲突; <code>yum remove -y abrt</code></li>
<li>必须有sudo权限</li>
<li>预安装的东西, <code>yum install -y wget epel-release</code>, <code>epel-release</code>是一个fedora维护的软件仓库，全名叫做<em>企业版Linux额外软件包</em></li>
</ul>
<h4 id="3-正式开始装"><a href="#3-正式开始装" class="headerlink" title="3. 正式开始装"></a>3. 正式开始装</h4><ul>
<li>下载最新的scylladb源，由于每次更新源都会有一定的变化，所以每一次更新的时候最好要更新一下源;下面的源是1.4版本的</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo wget -O /etc/yum.repos.d/scylla.repo http://downloads.scylladb.com/rpm/centos/scylla-1.4.repo</span><br></pre></td></tr></table></figure>
<ul>
<li><p>是scylla yum源生效; <code>yum clean all; yum makecache</code></p>
</li>
<li><p>安装scylla; <code>yum install -y scylla</code></p>
</li>
</ul>
<p>如果一些顺利的话，到这一步scylladb就已经安装完毕了</p>
<h4 id="4-配置和脚本相关的"><a href="#4-配置和脚本相关的" class="headerlink" title="4. 配置和脚本相关的"></a>4. 配置和脚本相关的</h4><table>
<thead>
<tr>
<th>配置名字</th>
<th>配置作用</th>
<th>配置位置</th>
</tr>
</thead>
<tbody>
<tr>
<td>scylladb的主要配置</td>
<td>设定一些主要的参数，比如存储位置、开放端口和ip，也会有一些性能参数设置</td>
<td>/etc/scylla/scylla.yaml</td>
</tr>
<tr>
<td>scylla启动脚本</td>
<td></td>
<td>/etc/sysconfig/scylla-server</td>
</tr>
<tr>
<td>系统资源限制</td>
<td>去掉对scylla用户的资源限制</td>
<td>/etc/security/limits.d/scylla.conf</td>
</tr>
<tr>
<td>启动脚本</td>
<td>设置参数、启动scylladb脚本</td>
<td>/etc/sysconfig/scylla-server</td>
</tr>
<tr>
<td>coredump配置文件</td>
<td>设置coredump的配置文件</td>
<td>/etc/sysconfig/sysctl.d/99-scylla.conf</td>
</tr>
<tr>
<td>collectd配置文件</td>
<td>设置collectd的一些配置</td>
<td>/etc/collectd.d/scylla.conf</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th>配置名字</th>
<th>配置作用</th>
<th>配置位置</th>
</tr>
</thead>
<tbody>
<tr>
<td>内核设置</td>
<td>在bootloader中设置内核参数</td>
<td>/usr/lib/scylla/scylla_bootparam_setup</td>
</tr>
<tr>
<td>coredump配置文件生成器</td>
<td></td>
<td>/usr/lib/scylla/scylla_coredump_setup</td>
</tr>
<tr>
<td>ntp协议配置生成器</td>
<td></td>
<td>/usr/lib/scylla/scylla_ntp_setup</td>
</tr>
<tr>
<td>网络配置设定</td>
<td></td>
<td>/usr/lib/scylla/scylla_prepare</td>
</tr>
<tr>
<td>配置raid和文件系统的脚本</td>
<td></td>
<td>/usr/lib/scylla/scylla_raid_setup</td>
</tr>
<tr>
<td>压缩coredump脚本</td>
<td>only ubuntu有效</td>
<td>/usr/lib/scylla/save_coredump</td>
</tr>
<tr>
<td>重新设置网络模式</td>
<td>如果scylladb运行的virtio或者DPDK的话，就重新设置网络模式</td>
<td>/usr/lib/scylla/scylla_stop</td>
</tr>
<tr>
<td>重新设置网络参数</td>
<td></td>
<td>/usr/lib/scylla/posix_net_conf.sh</td>
</tr>
<tr>
<td>io.conf生成器</td>
<td>用于测试io性能，并且把文件提供给scylladb</td>
<td>/usr/lib/scylla/scylla_io_setup </td>
</tr>
</tbody>
</table>
<p>上面这些脚本都是在<code>/usr/lib/scylla</code>目录下面的，并且还有其他的脚本，这些脚本会在运行scylla_setup的时候会调用;详情请看<a href="http://www.scylladb.com/doc/system-configuration/" target="_blank" rel="noopener">url</a></p>
<table>
<thead>
<tr>
<th>作用</th>
<th>端口值</th>
</tr>
</thead>
<tbody>
<tr>
<td>cql</td>
<td>9042</td>
</tr>
<tr>
<td>内部rpc</td>
<td>7000</td>
</tr>
<tr>
<td>ssl内部rpc</td>
<td>7001</td>
</tr>
<tr>
<td>jmx 端口</td>
<td>7199</td>
</tr>
<tr>
<td>scylla rest api</td>
<td>10000</td>
</tr>
<tr>
<td>Scylla Prometheus API(不知道是什么)</td>
<td>9180</td>
</tr>
<tr>
<td>node_exporter</td>
<td>9100</td>
</tr>
</tbody>
</table>
<h4 id="5-具体的配置"><a href="#5-具体的配置" class="headerlink" title="5. 具体的配置"></a>5. 具体的配置</h4><table>
<thead>
<tr>
<th>配置项</th>
<th>含义</th>
</tr>
</thead>
<tbody>
<tr>
<td>seeds</td>
<td>种子ip列表，建议多几个ip</td>
</tr>
<tr>
<td>listen_address</td>
<td>scylladb内部通信的ip</td>
</tr>
<tr>
<td>rpc_address</td>
<td>客户端连接scylladb的ip</td>
</tr>
<tr>
<td>broadcast_address</td>
<td>默认listen_address，从其他节点角度看这个node的ip，可能是不同网络之间不同，而通过外网来进行互联</td>
</tr>
<tr>
<td>broadcast_rpc_address</td>
<td>默认是rpc_address,从client角度上来你应该是什么ip，同上</td>
</tr>
</tbody>
</table>
<h4 id="6-scylladb管理命令"><a href="#6-scylladb管理命令" class="headerlink" title="6. scylladb管理命令"></a>6. scylladb管理命令</h4><table>
<thead>
<tr>
<th>命令</th>
<th>作用</th>
</tr>
</thead>
<tbody>
<tr>
<td>scylla –version</td>
<td>查看版本</td>
</tr>
<tr>
<td>nodetool snapshot</td>
<td>将node数据进行快照;关于scylladb snapshot的原理是：通过linux的hardlink来进行备份，因为scylladb的文件产生之后会不会改变所以这样能很好的保证备份的作用，并且用来了hardlink保证文件的可用性，和不需要通过拷贝也加重系统的负载;</td>
</tr>
<tr>
<td>恢复备份</td>
<td>1. 清空commitlog 2. 清空data目录下面的数据文件 3. 把snapshot备份的文件mv过来即可 4. 重启</td>
</tr>
<tr>
<td>提供rest接口</td>
<td></td>
</tr>
<tr>
<td>scyllatop</td>
<td>scylla自己的top, 目测可以与collectd一起使用，并且提供比较好的功能</td>
</tr>
<tr>
<td>Prometheus</td>
<td>scylla自己的监控系统</td>
</tr>
<tr>
<td>collectd</td>
<td>scylladb本地会启动collectd的进程，用来接收scylladb抛送过来的数据，可以通过插件的方式来修改，比较方便，并且会增加scyllatop看到的数据</td>
</tr>
<tr>
<td>log</td>
<td>scylla log是通过centos7的 journalctl 来控制的；最常用的有<code>journalctl _COMM=scylla -p warning</code> 或者 <code>journalctl _COMM=scylla --since &quot;2015-01-10&quot; --until &quot;2015-01-11 03:00</code> 或者 <code>journalctl _COMM=scylla -b(从最近一次重启的日志)</code></td>
</tr>
</tbody>
</table>
<p>node tool命令介绍</p>
<table>
<thead>
<tr>
<th>命令</th>
<th>作用</th>
</tr>
</thead>
<tbody>
<tr>
<td>nodetool status</td>
<td>看集群的状态,<a href="http://www.scylladb.com/doc/nodetool-commands/status/" target="_blank" rel="noopener">详情</a></td>
</tr>
<tr>
<td>nodetool snapshot</td>
<td>上面已提过</td>
</tr>
<tr>
<td>nodetool cfhistograms</td>
<td>提供每一个表的静态数据，包括sstable的个数、读写延迟、分区的尺寸和列簇的个数;<code>nodetoll sfhistograms keyspace tablename</code>,<a href="http://www.scylladb.com/doc/nodetool-commands/cfhistograms/" target="_blank" rel="noopener">详情</a></td>
</tr>
<tr>
<td>nodetool cfstats</td>
<td>提供对特定的表的一个深层的分析;<code>nodetool cfstats keyspace.tablename</code>,<a href="http://www.scylladb.com/doc/nodetool-commands/cfstats/" target="_blank" rel="noopener">详情</a></td>
</tr>
<tr>
<td>nodetool cleanup</td>
<td>立即触发清理不属于本机的key；<code>nodetool cleanup -h 127.0.0.1 keyspace</code></td>
</tr>
<tr>
<td>nodetool clearsnapshot</td>
<td>清理snapshot文件,<code>nodetool clearsnapshot keyspace</code>,不写keyspace就默认删除全部的snapshot </td>
</tr>
<tr>
<td>compactionhistory</td>
<td>打印compact的历史</td>
</tr>
<tr>
<td>compactionstats</td>
<td>打印目前正在compact的进度和一些信息</td>
</tr>
<tr>
<td>compact</td>
<td>对可能的keyspac而进行强制的compact操作; <code>nodetool compact keyspace</code></td>
</tr>
<tr>
<td>describecluster</td>
<td>打印一些信息</td>
</tr>
<tr>
<td>decommission</td>
<td></td>
</tr>
<tr>
<td>describering</td>
<td>打印某一个keyspace的一致性hash分布情况</td>
</tr>
<tr>
<td>disablebackup</td>
<td>关闭增量备份</td>
</tr>
<tr>
<td>disablebinary</td>
<td>关闭cql</td>
</tr>
<tr>
<td>statusbinary</td>
<td>看cql当前运行的状态</td>
</tr>
<tr>
<td>enablebinary</td>
<td>开启cql</td>
</tr>
<tr>
<td>statusgossip</td>
<td>gossip协议的运行状态</td>
</tr>
<tr>
<td>disablegossip</td>
<td>关闭gossip</td>
</tr>
<tr>
<td>enablegossip</td>
<td>开启gossip</td>
</tr>
<tr>
<td>drain</td>
<td>通常用于升级scylladb之前使用，主要的操作是将所有的memtable全部写入到sstable，然后停止listen各种端口，之后要恢复必须通过重启</td>
</tr>
<tr>
<td>flush</td>
<td>将当然的memtable刷成sstable</td>
</tr>
<tr>
<td>getendpoints</td>
<td><code>nodetool getendpoints keyspace tablename key</code>,现在还不知道用来做什么</td>
</tr>
<tr>
<td>getlogginglevels</td>
<td>获得运行时中的日志等级</td>
</tr>
<tr>
<td>gossipinfo</td>
<td>展示gossip协议中传播的东西</td>
</tr>
<tr>
<td>info</td>
<td>展现当前节点的一些信息; <a href="http://www.scylladb.com/doc/nodetool-commands/info/" target="_blank" rel="noopener">详情</a></td>
</tr>
<tr>
<td>listsnapshots</td>
<td>展示所有的snapshot在磁盘上的占用率</td>
</tr>
<tr>
<td>move</td>
<td>将node 分配到新的token</td>
</tr>
<tr>
<td>netstats</td>
<td>打印一些网络信息</td>
</tr>
<tr>
<td>proxyhistograms</td>
<td>对于网络操作打印一些静态统计</td>
</tr>
<tr>
<td>rebuild <src-dc-name></src-dc-name></td>
<td>从另外一个节点重建数据</td>
</tr>
<tr>
<td>refrash <keyspace> <tablename></tablename></keyspace></td>
<td>在不重启的前提下，重新reload文件中的sstable</td>
</tr>
<tr>
<td>removenode <id></id></td>
<td>移除名为id的节点</td>
</tr>
<tr>
<td>repair</td>
<td>修复一个或者多个的列簇； 参数比较多，使用前查询;</td>
</tr>
<tr>
<td>ring</td>
<td>显示一致性hash的列表</td>
</tr>
<tr>
<td>setlogginglevel <class> <threshold></threshold></class></td>
<td>设置某一个类的运行时日志等级</td>
</tr>
<tr>
<td>settraceprobability – <value></value></td>
<td>设置跟踪请求的概率，value在0~1之间</td>
</tr>
<tr>
<td>snapshot [-t tag] [-cf tablename] <keyspace></keyspace></td>
<td>针对具体的表或keyspace做快照</td>
</tr>
<tr>
<td>statusbackup</td>
<td>增量backup的状态</td>
</tr>
<tr>
<td>stop</td>
<td>停止compact任务</td>
</tr>
<tr>
<td>version</td>
<td>db的版本  </td>
</tr>
</tbody>
</table>
<p>nodetool info几个参数介绍</p>
<table>
<thead>
<tr>
<th>参数</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>Gossip active</td>
<td>gossip状态</td>
</tr>
<tr>
<td>Thrift active</td>
<td>thrift 状态</td>
</tr>
<tr>
<td>native transport active</td>
<td>cql的状态</td>
</tr>
<tr>
<td>Load</td>
<td>sstable占磁盘多少空间</td>
</tr>
<tr>
<td>Generation NO</td>
<td>主版本，当节点重启、token更新，这个版本就会往上增加</td>
</tr>
<tr>
<td>Uptime</td>
<td>scylla没有这个</td>
</tr>
<tr>
<td>Heap Memory</td>
<td>scylla没有这个</td>
</tr>
<tr>
<td>off Heap memory (MB)</td>
<td>所有的memtables、bloom filters 、indexs、compression metadata占用的内存</td>
</tr>
<tr>
<td>Data center</td>
<td>这个节点所在的数据中心</td>
</tr>
<tr>
<td>Rack</td>
<td>？？、</td>
</tr>
<tr>
<td>Exception</td>
<td>scylla没有这个</td>
</tr>
<tr>
<td>Key Cache</td>
<td>scylla没有这个</td>
</tr>
<tr>
<td>Row Cache</td>
<td>Row cache的信息</td>
</tr>
<tr>
<td>Counter Cache</td>
<td>scylla没有这个</td>
</tr>
<tr>
<td>Token</td>
<td>token展示</td>
</tr>
</tbody>
</table>
<h4 id="7-关于scylladb的monitor安装-由于官方教程变化太大-以官方为准"><a href="#7-关于scylladb的monitor安装-由于官方教程变化太大-以官方为准" class="headerlink" title="7. 关于scylladb的monitor安装[由于官方教程变化太大,以官方为准]"></a>7. 关于scylladb的monitor安装[由于官方教程变化太大,以官方为准]</h4><p>目前scylladb的监控是使用<a href="https://github.com/scylladb/scylla-grafana-monitoring" target="_blank" rel="noopener">Grafana and Prometheus
</a>, 具体的安装过程如下:</p>
<ol>
<li>首先安装docker在服务器上; <code>sudo yum install -y docker</code></li>
<li>启动docker服务;<code>sudo service docker start</code></li>
<li>验证docker安装情况; <code>sudo docker ps -a or sudo docker images</code></li>
</ol>
<p>其实监控安装比较简单，但是由于网络问题安装就变成很蛋疼的过程;</p>
<ul>
<li>首先通过mac翻墙下载docker 镜像; prom/prometheus and grafana/grafana</li>
</ul>
<pre><code>docker pull prom/prometheus:v1.5.2
docker pull grafana/grafana:4.1.1
</code></pre><ul>
<li>将镜像导出成tar格式的文件</li>
</ul>
<pre><code>docker save imageid -o xxx.tar
</code></pre><p>镜像id可以通过<code>docker images</code>来得到</p>
<pre><code>$ docker images
REPOSITORY          TAG                 IMAGE ID            CREATED             SIZE
grafana/grafana     latest              a892c250adfa        11 days ago         266.2 MB
prom/prometheus     latest              bdeacb538ef9        2 weeks ago         79.25 MB
</code></pre><ul>
<li>将tar文件上传到服务器，然后导入服务器的docker</li>
</ul>
<pre><code>docker load -i xxx.tar
#修改对应的name和版本
docker tag imageId name:tag

sudo docker tag  047fd14b7251 prom/prometheus:v1.0.0
sudo docker tag d7528263f75a grafana/grafana:3.1.0
</code></pre><ul>
<li>下载 scylla-grafana-monitoring 项目</li>
</ul>
<pre><code>git clone https://github.com/scylladb/scylla-grafana-monitoring.git
</code></pre><ul>
<li>修改prometheus的配置文件</li>
</ul>
<pre><code>global:
# 采集周期
  scrape_interval: 15s # By default, scrape targets every 15 seconds.

  # Attach these labels to any time series or alerts when communicating with
  # external systems (federation, remote storage, Alertmanager).
  external_labels:
    monitor: &apos;scylla-monitor&apos;

scrape_configs:
    - job_name: scylla
  honor_labels: true
  static_configs:
  # 这个是scylladb服务的地址，这边是主动采集为主，不是被动上报，主要收集scylla的metric信息
      - targets: [&quot;10.19.11.23:9180&quot;]
    - job_name: node_exporter
  honor_labels: true
  static_configs:
  # 这部分主要是收集scylla的机器的信息，需要通过node_exporter 来开启这个上报;
      - targets: [&apos;10.19.11.23:9100&apos;]

## two servers example: - targets: [&quot;172.17.0.3:9103&quot;,&quot;172.17.0.2:9103&quot;]
</code></pre><ul>
<li>用启动脚本启动</li>
</ul>
<pre><code>sudo sh start-all.sh -d data_dir -v 1.6
</code></pre><p>data路径最好要配置一个，不然两次启动会把数据删除<br>-v: 用来表示加载哪个系统版本</p>
<p>这个可能会碰到一个问题，</p>
<pre><code>598cf3f9e16f0e5df2a1f0cf79df8be2ee0909f80307e392911d140b2ff6dac8
Wait for Prometheus container to start..        4721e32c86ea09f1e16d270a194eb979cbf61f249c066435234e7d5cafee8631
Wait for Grafana container to start........curl: (7) Failed connect to localhost:3000; Connection refused
curl: (7) Failed connect to localhost:3000; Connection refused
curl: (7) Failed connect to localhost:3000; Connection refused        curl: (7) Failed connect to localhost:3000; Connection refused
</code></pre><p>Grafana 没有起来 或者起来，但是还没有监听端口，然后脚本最多只是重试7次，这个时候就会报错，其实后期grafana是成功起来的；</p>
<p>解决方式有两个：</p>
<pre><code>1. 先执行脚本，然后等到grafana起来，然后关掉prometheus,然后修改start-all.sh中的脚本，把docker run grafana那个部分去掉，然后在执行start-all.sh, 这样就ok了
2. 将重试几次增大
</code></pre><ul>
<li>关闭监控</li>
</ul>
<pre><code>sudo sh kill-all.sh
</code></pre>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;主要的依赖于官方的教程，这边主要是将一些细节进行串联描述，下次安装的时候会更加自动化;&lt;/p&gt;
&lt;p&gt;我的安装环境如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;centos7.2&lt;/li&gt;
&lt;li&gt;内核版本为3.18&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&quot;1-关于scylladb几个r
    
    </summary>
    
      <category term="scylladb" scheme="http://yoursite.com/categories/scylladb/"/>
    
    
      <category term="scylladb" scheme="http://yoursite.com/tags/scylladb/"/>
    
  </entry>
  
  <entry>
    <title>为新的jmxtrans添加新的outputwriter</title>
    <link href="http://yoursite.com/2017/03/27/%E4%B8%BA%E6%96%B0%E7%9A%84jmxtrans%E6%B7%BB%E5%8A%A0%E6%96%B0%E7%9A%84outputwriter/"/>
    <id>http://yoursite.com/2017/03/27/为新的jmxtrans添加新的outputwriter/</id>
    <published>2017-03-27T13:52:00.000Z</published>
    <updated>2017-04-06T23:17:14.000Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://github.com/jmxtrans/jmxtrans" target="_blank" rel="noopener">jmxtrans</a>是一个开源产品，主要的作用是通过定时轮训程序的jmx端口来获得程序内部的信息，并且输出到对应的外界监控系统，比如ganglia、es、influxdb等；由于它的这种作用，所以不少的人将它使用在对一些开源组件的监控. 而我主要用它来将kafka中的broker信息输出到我们内部的监控。</p>
<p>年前已经将监控信息输出到了ganglia，但是这不能与我们的报警系统好好的融合起来，我基本不可能时时刻刻盯着监控图标在看的，为此所以我就必须将让kafka的监控数据输出到我们内部的监控，并且对一些特定的metric设置报警，这样就可以对kafka内部的一些状态进行监控，也能更加快的发现问题。</p>
<h4 id="1-安装一个稳定版本的jmxtrans"><a href="#1-安装一个稳定版本的jmxtrans" class="headerlink" title="1. 安装一个稳定版本的jmxtrans"></a>1. 安装一个稳定版本的jmxtrans</h4><p>jmxtrans提供了rpm包，你可以直接通过如下命令来安装；</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rpm -ivh jmxtrans-260.rpm</span><br></pre></td></tr></table></figure>
<p>安装完之后，jmxtrans会在几个目录存放对应的配置文件、日志、pid等，对此我也是很纠结，就不能想其他的程序一样放的正规一点吗，几个目录还不在一起;</p>
<ul>
<li>/var/log/jmxtrans/jmxtrans.log: jmxtrans运行的日志</li>
<li>/var/run/jmxtrans/jmxtrans.pid: 存放jmxtrans对应的pid</li>
<li>/usr/shared/jmxtrans/:这个目录下面存放的jmxtrans的库文件、可执行文件、一些jmx的配置</li>
<li>/var/lib/jmxtrans/:这个目录下面存放的需要采集的配置文件，通常是json;</li>
</ul>
<h4 id="2-下载对应版本的jmxtrans"><a href="#2-下载对应版本的jmxtrans" class="headerlink" title="2. 下载对应版本的jmxtrans"></a>2. 下载对应版本的jmxtrans</h4><p>我使用的260版本的jmxtrans，于是我从它们的github网址下载了源码:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wget https://github.com/jmxtrans/jmxtrans/archive/jmxtrans-parent-260.tar.gz</span><br></pre></td></tr></table></figure>
<p>然后用intellij打开对应的工程;</p>
<h4 id="3-添加自己的outputwriter"><a href="#3-添加自己的outputwriter" class="headerlink" title="3. 添加自己的outputwriter"></a>3. 添加自己的outputwriter</h4><p>这个部分我就大概说一下，具体可以看<code>jmxtrans-output-log4j中KeyOutWriter</code>这个类，因为很简单，很快就模拟然后进行自己的改造;</p>
<ul>
<li>创建自己的outputwriter模块，比如我就自己在jmxtrans-output创建了一个<code>jmxtrans-output-sentry</code>模块，pom.xml只需要将对应的依赖加上的，记得一定会依赖如下几个依赖:</li>
</ul>
<pre><code>&lt;dependency&gt;
   &lt;groupId&gt;org.jmxtrans&lt;/groupId&gt;
   &lt;artifactId&gt;jmxtrans-core&lt;/artifactId&gt;
&lt;/dependency&gt;

&lt;dependency&gt;
   &lt;groupId&gt;org.jmxtrans&lt;/groupId&gt;
   &lt;artifactId&gt;jmxtrans-utils&lt;/artifactId&gt;
&lt;/dependency&gt; 
&lt;dependency&gt;
   &lt;groupId&gt;org.jmxtrans&lt;/groupId&gt;
   &lt;artifactId&gt;jmxtrans-test-utils&lt;/artifactId&gt;
   &lt;scope&gt;test&lt;/scope&gt;
&lt;/dependency&gt;
</code></pre><ul>
<li><p>创建你自己的outputwriter类，并且继承<code>BaseOutputWriter</code>;下面的代码中我把公司内部的代码给去掉了，但是其实是一个很简单的输出端，不影响整个过程，下面的循环就对应的后面配置中的每一次你需要的查询；代码中的<code>metric</code> 和 <code>value</code>就是对应的key和value;</p>
  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line">	public class SentryOutWriter extends BaseOutputWriter &#123;</span><br><span class="line">    private static Logger logger = LoggerFactory.getLogger(SentryOutWriter.class);</span><br><span class="line">    private Map&lt;String, String&gt; fixTags = new HashMap&lt;&gt;();</span><br><span class="line">    private String clustername;</span><br><span class="line"></span><br><span class="line">    @JsonCreator</span><br><span class="line">    public SentryOutWriter(@JsonProperty(&quot;typeNames&quot;) ImmutableList&lt;String&gt; typeNames,</span><br><span class="line">                           @JsonProperty(&quot;booleanAsNumber&quot;) boolean booleanAsNumber,</span><br><span class="line">                           @JsonProperty(&quot;debug&quot;) Boolean debugEnabled,</span><br><span class="line">                           @JsonProperty(&quot;settings&quot;) Map&lt;String, Object&gt; settings,</span><br><span class="line">                           @JsonProperty(&quot;clustername&quot;) String clustername) &#123;</span><br><span class="line">        super(typeNames, booleanAsNumber, debugEnabled, settings);</span><br><span class="line">        logger.info(&quot;SentryOutWriter is init&quot;);</span><br><span class="line"></span><br><span class="line">        this.clustername = clustername;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public void validateSetup(Server server, Query query) throws ValidationException &#123;&#125;</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    protected void internalWrite(Server server, Query query, ImmutableList&lt;Result&gt; results) throws Exception &#123;</span><br><span class="line">        List&lt;String&gt; typeNames = getTypeNames();</span><br><span class="line">        long now = System.currentTimeMillis()/1000;</span><br><span class="line">        for (Result result : results) &#123;</span><br><span class="line">            Map&lt;String, Object&gt; resultValues = result.getValues();</span><br><span class="line">            for (Map.Entry&lt;String, Object&gt; values : resultValues.entrySet()) &#123;</span><br><span class="line">                if (isNumeric(values.getValue())) &#123;</span><br><span class="line">                    String mbeanAlias = Util.getMBeanIdentifier(query, result);</span><br><span class="line">                    String key = Util.getKeyString(query, result, values);</span><br><span class="line"></span><br><span class="line">                    if(Strings.isNullOrEmpty(mbeanAlias) || Strings.isNullOrEmpty(key))&#123;</span><br><span class="line">                        continue;</span><br><span class="line">                    &#125;</span><br><span class="line"></span><br><span class="line">                    String metric = mbeanAlias + &quot;.&quot; + key;</span><br><span class="line">                    Double value = null;</span><br><span class="line">                   </span><br><span class="line">                    if(values.getValue() instanceof Double)&#123;</span><br><span class="line">                          value = (Double) values.getValue();</span><br><span class="line">                    &#125;else if(values.getValue() instanceof Long)&#123;</span><br><span class="line">                        value = Double.valueof((Long) values.getValue());</span><br><span class="line">                    &#125;else if(values.getValue() instanceof Integer) &#123;</span><br><span class="line">                        value = Long.valueOf((Integer)values.getValue());</span><br><span class="line">                    &#125; else if(values.getValue() instanceof String)&#123;</span><br><span class="line">                        value = Double.valueOf((String)values.getValue());</span><br><span class="line">                    &#125;else&#123;</span><br><span class="line">                        try&#123;</span><br><span class="line">                            value =  Double.valueOf((Double)values.getValue());</span><br><span class="line">                        &#125;catch (Exception e)&#123;</span><br><span class="line">                            logger.error(&quot;to double is error,&#123;&#125;&quot;, e);</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;</span><br><span class="line">                    logger.error(&quot;metrci:&#123;&#125;&quot;, metric);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
</ul>
<ul>
<li>将你自己的模块打包</li>
</ul>
<h4 id="4-将你的包导入的之前已经安装完的稳定版本中"><a href="#4-将你的包导入的之前已经安装完的稳定版本中" class="headerlink" title="4. 将你的包导入的之前已经安装完的稳定版本中"></a>4. 将你的包导入的之前已经安装完的稳定版本中</h4><p>其实jmxtrans没有提供很好的方式可以将自定义的包放到它们的stable版本中，起码我没有很好的方式；但是在模仿其他包的时候我还是发现了一些可行的方式来导入自己的包；</p>
<ol>
<li><p>确定你的jar依赖的其他的jar包；</p>
<p> 因为你自定义的jar可能还依赖出jmxtrans本身的其他的jar，所以你实现应该确定好有哪些jar包需要额外依赖；比如我就额外的包就是我司内部的监控client jar包;</p>
</li>
<li><p>将你的包上传到jmxtrans的服务端</p>
<ul>
<li>/usr/shared/jmxtrans/lib/这目录下面就是用来存放对应的jar包的,其中<code>/usr/share/jmxtrans/lib/org/jmxtrans</code>就是用来存放对应输出端的jar，所以你要把你自定的jar包放在这里;比如我就放在<code>/usr/share/jmxtrans/lib/org/jmxtrans/jmxtrans-output-sentry/260/</code>下面，jar包名字叫做<code>jmxtrans-output-sentry-260.jar</code></li>
<li>上传额外依赖包，按照标准的方式存放即可，lib目录下面有很多的例子可以模仿</li>
</ul>
</li>
<li><p>修改wrapper.conf文件</p>
<p> <code>/usr/share/jmxtrans/etc/wrapper.conf</code>是jmxtrans的启动配置文件，里面包含了启动需要加载那些包，所以需要添加jar的依赖;</p>
</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">wrapper.java.classpath.89=%REPO_DIR%/org/slf4j/slf4j-log4j12/1.7.21/slf4j-log4j12-1.7.21.jar</span><br><span class="line">wrapper.java.classpath.90=%REPO_DIR%/org/jmxtrans/jmxtrans-output-sentry/260/jmxtrans-output-sentry-260.jar</span><br><span class="line">wrapper.java.classpath.91=%REPO_DIR%/com/xxxx/xxxx/xxx.jar</span><br></pre></td></tr></table></figure>
<ol start="4">
<li><p>去修改<code>/var/lib/jmxtrans/kafka.json</code>修改outputwriter的类型</p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br><span class="line">328</span><br><span class="line">329</span><br><span class="line">330</span><br><span class="line">331</span><br><span class="line">332</span><br><span class="line">333</span><br><span class="line">334</span><br><span class="line">335</span><br></pre></td><td class="code"><pre><span class="line">	&#123;</span><br><span class="line">  &quot;servers&quot;: [</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;port&quot;: &quot;your sever jmx port&quot;,</span><br><span class="line">      &quot;host&quot;: &quot;your server ip&quot;,</span><br><span class="line">      &quot;queries&quot;: [</span><br><span class="line">        &#123;</span><br><span class="line">          &quot;outputWriters&quot;: [</span><br><span class="line">            &#123;</span><br><span class="line">              &quot;@class&quot;: &quot;com.googlecode.jmxtrans.model.output.SentryOutWriter&quot;,</span><br><span class="line">              &quot;clustername&quot;: &quot;offline-kafka&quot;</span><br><span class="line">            &#125;</span><br><span class="line">          ],</span><br><span class="line">          &quot;obj&quot;: &quot;java.lang:type=Memory&quot;,</span><br><span class="line">          &quot;resultAlias&quot;: &quot;memory&quot;,</span><br><span class="line">          &quot;attr&quot;: [</span><br><span class="line">            &quot;HeapMemoryUsage&quot;</span><br><span class="line">          ]</span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">          &quot;outputWriters&quot;: [</span><br><span class="line">            &#123;</span><br><span class="line">              &quot;@class&quot;: &quot;com.googlecode.jmxtrans.model.output.SentryOutWriter&quot;,</span><br><span class="line">              &quot;clustername&quot;: &quot;offline-kafka&quot;</span><br><span class="line">            &#125;</span><br><span class="line">          ],</span><br><span class="line">          &quot;obj&quot;: &quot;java.lang:type=GarbageCollector,name=G1 Old Generation&quot;,</span><br><span class="line">          &quot;resultAlias&quot;: &quot;FullGC&quot;,</span><br><span class="line">          &quot;attr&quot;: [</span><br><span class="line">            &quot;CollectionCount&quot;,</span><br><span class="line">            &quot;CollectionTime&quot;</span><br><span class="line">          ]</span><br><span class="line">        &#125;,</span><br><span class="line"></span><br><span class="line">        &#123;</span><br><span class="line">          &quot;outputWriters&quot;: [</span><br><span class="line">            &#123;</span><br><span class="line">              &quot;@class&quot;: &quot;com.googlecode.jmxtrans.model.output.SentryOutWriter&quot;,</span><br><span class="line">              &quot;clustername&quot;: &quot;offline-kafka&quot;</span><br><span class="line">            &#125;</span><br><span class="line">          ],</span><br><span class="line">          &quot;obj&quot;: &quot;kafka.server:type=BrokerTopicMetrics,name=MessagesInPerSec&quot;,</span><br><span class="line">          &quot;resultAlias&quot;: &quot;MessagesIn&quot;,</span><br><span class="line">          &quot;attr&quot;: [</span><br><span class="line">            &quot;OneMinuteRate&quot;</span><br><span class="line">          ]</span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">          &quot;outputWriters&quot;: [</span><br><span class="line">            &#123;</span><br><span class="line">              &quot;@class&quot;: &quot;com.googlecode.jmxtrans.model.output.SentryOutWriter&quot;,</span><br><span class="line">              &quot;clustername&quot;: &quot;offline-kafka&quot;</span><br><span class="line">            &#125;</span><br><span class="line">          ],</span><br><span class="line">          &quot;obj&quot;: &quot;kafka.server:type=BrokerTopicMetrics,name=BytesInPerSec&quot;,</span><br><span class="line">          &quot;resultAlias&quot;: &quot;BytesIn&quot;,</span><br><span class="line">          &quot;attr&quot;: [</span><br><span class="line">            &quot;OneMinuteRate&quot;</span><br><span class="line">          ]</span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">          &quot;outputWriters&quot;: [</span><br><span class="line">            &#123;</span><br><span class="line">              &quot;@class&quot;: &quot;com.googlecode.jmxtrans.model.output.SentryOutWriter&quot;,</span><br><span class="line">              &quot;clustername&quot;: &quot;offline-kafka&quot;</span><br><span class="line">            &#125;</span><br><span class="line">          ],</span><br><span class="line">          &quot;obj&quot;: &quot;kafka.server:type=BrokerTopicMetrics,name=BytesOutPerSec&quot;,</span><br><span class="line">          &quot;resultAlias&quot;: &quot;BytesOut&quot;,</span><br><span class="line">          &quot;attr&quot;: [</span><br><span class="line">            &quot;OneMinuteRate&quot;</span><br><span class="line">          ]</span><br><span class="line">        &#125;,</span><br><span class="line"></span><br><span class="line">        &#123;</span><br><span class="line">          &quot;outputWriters&quot;: [</span><br><span class="line">            &#123;</span><br><span class="line">              &quot;@class&quot;: &quot;com.googlecode.jmxtrans.model.output.SentryOutWriter&quot;,</span><br><span class="line">              &quot;clustername&quot;: &quot;offline-kafka&quot;</span><br><span class="line">            &#125;</span><br><span class="line">          ],</span><br><span class="line">          &quot;obj&quot;: &quot;kafka.network:type=RequestMetrics,name=RequestsPerSec,request=Produce&quot;,</span><br><span class="line">          &quot;resultAlias&quot;: &quot;ProduceRequests&quot;,</span><br><span class="line">          &quot;attr&quot;: [</span><br><span class="line">            &quot;OneMinuteRate&quot;</span><br><span class="line">          ]</span><br><span class="line">        &#125;,</span><br><span class="line"></span><br><span class="line">        &#123;</span><br><span class="line">          &quot;outputWriters&quot;: [</span><br><span class="line">            &#123;</span><br><span class="line">              &quot;@class&quot;: &quot;com.googlecode.jmxtrans.model.output.SentryOutWriter&quot;,</span><br><span class="line">              &quot;clustername&quot;: &quot;offline-kafka&quot;</span><br><span class="line">            &#125;</span><br><span class="line">          ],</span><br><span class="line">          &quot;obj&quot;: &quot;kafka.network:type=RequestMetrics,name=RequestsPerSec,request=FetchConsumer&quot;,</span><br><span class="line">          &quot;resultAlias&quot;: &quot;FetchConsumerRequests&quot;,</span><br><span class="line">          &quot;attr&quot;: [</span><br><span class="line">            &quot;OneMinuteRate&quot;</span><br><span class="line">          ]</span><br><span class="line">        &#125;,</span><br><span class="line"></span><br><span class="line">        &#123;</span><br><span class="line">          &quot;outputWriters&quot;: [</span><br><span class="line">            &#123;</span><br><span class="line">              &quot;@class&quot;: &quot;com.googlecode.jmxtrans.model.output.SentryOutWriter&quot;,</span><br><span class="line">              &quot;clustername&quot;: &quot;offline-kafka&quot;</span><br><span class="line">            &#125;</span><br><span class="line">          ],</span><br><span class="line">          &quot;obj&quot;: &quot;kafka.network:type=RequestMetrics,name=RequestsPerSec,request=FetchFollower&quot;,</span><br><span class="line">          &quot;resultAlias&quot;: &quot;FetchFollowerRequests&quot;,</span><br><span class="line">          &quot;attr&quot;: [</span><br><span class="line">            &quot;OneMinuteRate&quot;</span><br><span class="line">          ]</span><br><span class="line">        &#125;,</span><br><span class="line"></span><br><span class="line">        &#123;</span><br><span class="line">          &quot;outputWriters&quot;: [</span><br><span class="line">            &#123;</span><br><span class="line">              &quot;@class&quot;: &quot;com.googlecode.jmxtrans.model.output.SentryOutWriter&quot;,</span><br><span class="line">              &quot;clustername&quot;: &quot;offline-kafka&quot;</span><br><span class="line"></span><br><span class="line">            &#125;</span><br><span class="line">          ],</span><br><span class="line">          &quot;obj&quot;: &quot;kafka.log:type=LogFlushStats,name=LogFlushRateAndTimeMs&quot;,</span><br><span class="line">          &quot;resultAlias&quot;: &quot;LogflushRateAndTime&quot;,</span><br><span class="line">          &quot;attr&quot;: [</span><br><span class="line">            &quot;OneMinuteRate&quot;,</span><br><span class="line">            &quot;999thPercentile&quot;</span><br><span class="line">          ]</span><br><span class="line">        &#125;,</span><br><span class="line"></span><br><span class="line">        &#123;</span><br><span class="line">          &quot;outputWriters&quot;: [</span><br><span class="line">            &#123;</span><br><span class="line">              &quot;@class&quot;: &quot;com.googlecode.jmxtrans.model.output.SentryOutWriter&quot;,</span><br><span class="line">              &quot;clustername&quot;: &quot;offline-kafka&quot;</span><br><span class="line"></span><br><span class="line">            &#125;</span><br><span class="line">          ],</span><br><span class="line">          &quot;obj&quot;: &quot;kafka.log:type=ReplicaManager,name=UnderReplicatedPartitions&quot;,</span><br><span class="line">          &quot;resultAlias&quot;: &quot;UnISRPartitionCnt&quot;,</span><br><span class="line">          &quot;attr&quot;: [</span><br><span class="line">            &quot;Value&quot;</span><br><span class="line">          ]</span><br><span class="line">        &#125;,</span><br><span class="line"></span><br><span class="line">        &#123;</span><br><span class="line">          &quot;outputWriters&quot;: [</span><br><span class="line">            &#123;</span><br><span class="line">              &quot;@class&quot;: &quot;com.googlecode.jmxtrans.model.output.SentryOutWriter&quot;,</span><br><span class="line">              &quot;clustername&quot;: &quot;offline-kafka&quot;</span><br><span class="line"></span><br><span class="line">            &#125;</span><br><span class="line">          ],</span><br><span class="line">          &quot;obj&quot;: &quot;kafka.controller:type=KafkaController,name=ActiveControllerCount&quot;,</span><br><span class="line">          &quot;resultAlias&quot;: &quot;ActiveControllerCnt&quot;,</span><br><span class="line">          &quot;attr&quot;: [</span><br><span class="line">            &quot;Value&quot;</span><br><span class="line">          ]</span><br><span class="line">        &#125;,</span><br><span class="line"></span><br><span class="line">        &#123;</span><br><span class="line">          &quot;outputWriters&quot;: [</span><br><span class="line">            &#123;</span><br><span class="line">              &quot;@class&quot;: &quot;com.googlecode.jmxtrans.model.output.SentryOutWriter&quot;,</span><br><span class="line">              &quot;clustername&quot;: &quot;offline-kafka&quot;</span><br><span class="line">            &#125;</span><br><span class="line">          ],</span><br><span class="line">          &quot;obj&quot;: &quot;kafka.controller:type=ControllerStats,name=LeaderElectionRateAndTimeMs&quot;,</span><br><span class="line">          &quot;resultAlias&quot;: &quot;LeaderRateAndTime&quot;,</span><br><span class="line">          &quot;attr&quot;: [</span><br><span class="line">            &quot;999thPercentile&quot;,</span><br><span class="line">            &quot;OneMinuteRate&quot;</span><br><span class="line">          ]</span><br><span class="line">        &#125;,</span><br><span class="line"></span><br><span class="line">        &#123;</span><br><span class="line">          &quot;outputWriters&quot;: [</span><br><span class="line">            &#123;</span><br><span class="line">              &quot;@class&quot;: &quot;com.googlecode.jmxtrans.model.output.SentryOutWriter&quot;,</span><br><span class="line">              &quot;clustername&quot;: &quot;offline-kafka&quot;</span><br><span class="line">            &#125;</span><br><span class="line">          ],</span><br><span class="line">          &quot;obj&quot;: &quot;kafka.controller:type=ControllerStats,name=UncleanLeaderElectionsPerSec&quot;,</span><br><span class="line">          &quot;resultAlias&quot;: &quot;UncleanLeaderRateAndTime&quot;,</span><br><span class="line">          &quot;attr&quot;: [</span><br><span class="line">            &quot;999thPercentile&quot;,</span><br><span class="line">            &quot;OneMinuteRate&quot;</span><br><span class="line">          ]</span><br><span class="line">        &#125;,</span><br><span class="line"></span><br><span class="line">        &#123;</span><br><span class="line">          &quot;outputWriters&quot;: [</span><br><span class="line">            &#123;</span><br><span class="line">              &quot;@class&quot;: &quot;com.googlecode.jmxtrans.model.output.SentryOutWriter&quot;,</span><br><span class="line">              &quot;clustername&quot;: &quot;offline-kafka&quot;</span><br><span class="line">            &#125;</span><br><span class="line">          ],</span><br><span class="line">          &quot;obj&quot;: &quot;kafka.server:type=ReplicaManager,name=PartitionCount&quot;,</span><br><span class="line">          &quot;resultAlias&quot;: &quot;PartitionCnt&quot;,</span><br><span class="line">          &quot;attr&quot;: [</span><br><span class="line">            &quot;Value&quot;</span><br><span class="line">          ]</span><br><span class="line">        &#125;,</span><br><span class="line"></span><br><span class="line">        &#123;</span><br><span class="line">          &quot;outputWriters&quot;: [</span><br><span class="line">            &#123;</span><br><span class="line">              &quot;@class&quot;: &quot;com.googlecode.jmxtrans.model.output.SentryOutWriter&quot;,</span><br><span class="line">              &quot;clustername&quot;: &quot;offline-kafka&quot;</span><br><span class="line">            &#125;</span><br><span class="line">          ],</span><br><span class="line">          &quot;obj&quot;: &quot;kafka.server:type=ReplicaManager,name=LeaderCount&quot;,</span><br><span class="line">          &quot;resultAlias&quot;: &quot;LeaderCnt&quot;,</span><br><span class="line">          &quot;attr&quot;: [</span><br><span class="line">            &quot;Value&quot;</span><br><span class="line">          ]</span><br><span class="line">        &#125;,</span><br><span class="line"></span><br><span class="line">        &#123;</span><br><span class="line">          &quot;outputWriters&quot;: [</span><br><span class="line">            &#123;</span><br><span class="line">              &quot;@class&quot;: &quot;com.googlecode.jmxtrans.model.output.SentryOutWriter&quot;,</span><br><span class="line">              &quot;clustername&quot;: &quot;offline-kafka&quot;</span><br><span class="line">            &#125;</span><br><span class="line">          ],</span><br><span class="line">          &quot;obj&quot;: &quot;kafka.server:type=DelayedOperationPurgatory,name=PurgatorySize,delayedOperation=Produce&quot;,</span><br><span class="line">          &quot;resultAlias&quot;: &quot;ProducerPurgatorySize&quot;,</span><br><span class="line">          &quot;attr&quot;: [</span><br><span class="line">            &quot;Value&quot;</span><br><span class="line">          ]</span><br><span class="line">        &#125;,</span><br><span class="line"></span><br><span class="line">        &#123;</span><br><span class="line">          &quot;outputWriters&quot;: [</span><br><span class="line">            &#123;</span><br><span class="line">              &quot;@class&quot;: &quot;com.googlecode.jmxtrans.model.output.SentryOutWriter&quot;,</span><br><span class="line">              &quot;clustername&quot;: &quot;offline-kafka&quot;</span><br><span class="line">            &#125;</span><br><span class="line">          ],</span><br><span class="line">          &quot;obj&quot;: &quot;kafka.server:type=DelayedOperationPurgatory,name=PurgatorySize,delayedOperation=Fetch&quot;,</span><br><span class="line">          &quot;resultAlias&quot;: &quot;FetchPurgatorySize&quot;,</span><br><span class="line">          &quot;attr&quot;: [</span><br><span class="line">            &quot;Value&quot;</span><br><span class="line">          ]</span><br><span class="line">        &#125;,</span><br><span class="line"></span><br><span class="line">        &#123;</span><br><span class="line">          &quot;outputWriters&quot;: [</span><br><span class="line">            &#123;</span><br><span class="line">              &quot;@class&quot;: &quot;com.googlecode.jmxtrans.model.output.SentryOutWriter&quot;,</span><br><span class="line">              &quot;clustername&quot;: &quot;offline-kafka&quot;</span><br><span class="line">            &#125;</span><br><span class="line">          ],</span><br><span class="line">          &quot;obj&quot;: &quot;kafka.network:type=RequestMetrics,name=RequestQueueTimeMs,request=FetchConsumer&quot;,</span><br><span class="line">          &quot;resultAlias&quot;: &quot;FetchConsumerWait&quot;,</span><br><span class="line">          &quot;attr&quot;: [</span><br><span class="line">            &quot;999thPercentile&quot;</span><br><span class="line">          ]</span><br><span class="line">        &#125;,</span><br><span class="line"></span><br><span class="line">        &#123;</span><br><span class="line">          &quot;outputWriters&quot;: [</span><br><span class="line">            &#123;</span><br><span class="line">              &quot;@class&quot;: &quot;com.googlecode.jmxtrans.model.output.SentryOutWriter&quot;,</span><br><span class="line">              &quot;clustername&quot;: &quot;offline-kafka&quot;</span><br><span class="line">            &#125;</span><br><span class="line">          ],</span><br><span class="line">          &quot;obj&quot;: &quot;kafka.network:type=RequestMetrics,name=RequestQueueTimeMs,request=Produce&quot;,</span><br><span class="line">          &quot;resultAlias&quot;: &quot;ProduceWait&quot;,</span><br><span class="line">          &quot;attr&quot;: [</span><br><span class="line">            &quot;999thPercentile&quot;</span><br><span class="line">          ]</span><br><span class="line">        &#125;,</span><br><span class="line"></span><br><span class="line">        &#123;</span><br><span class="line">          &quot;outputWriters&quot;: [</span><br><span class="line">            &#123;</span><br><span class="line">              &quot;@class&quot;: &quot;com.googlecode.jmxtrans.model.output.SentryOutWriter&quot;,</span><br><span class="line">              &quot;clustername&quot;: &quot;offline-kafka&quot;</span><br><span class="line">            &#125;</span><br><span class="line">          ],</span><br><span class="line">          &quot;obj&quot;: &quot;kafka.network:type=RequestMetrics,name=LocalTimeMs,request=FetchConsumer&quot;,</span><br><span class="line">          &quot;resultAlias&quot;: &quot;FetchConsumerProcessTime&quot;,</span><br><span class="line">          &quot;attr&quot;: [</span><br><span class="line">            &quot;999thPercentile&quot;</span><br><span class="line">          ]</span><br><span class="line">        &#125;,</span><br><span class="line"></span><br><span class="line">        &#123;</span><br><span class="line">          &quot;outputWriters&quot;: [</span><br><span class="line">            &#123;</span><br><span class="line">              &quot;@class&quot;: &quot;com.googlecode.jmxtrans.model.output.SentryOutWriter&quot;,</span><br><span class="line">              &quot;clustername&quot;: &quot;offline-kafka&quot;</span><br><span class="line">            &#125;</span><br><span class="line">          ],</span><br><span class="line">          &quot;obj&quot;: &quot;kafka.network:type=RequestMetrics,name=LocalTimeMs,request=Produce&quot;,</span><br><span class="line">          &quot;resultAlias&quot;: &quot;ProduceProcessTime&quot;,</span><br><span class="line">          &quot;attr&quot;: [</span><br><span class="line">            &quot;999thPercentile&quot;</span><br><span class="line">          ]</span><br><span class="line">        &#125;,</span><br><span class="line"></span><br><span class="line">        &#123;</span><br><span class="line">          &quot;outputWriters&quot;: [</span><br><span class="line">            &#123;</span><br><span class="line">              &quot;@class&quot;: &quot;com.googlecode.jmxtrans.model.output.SentryOutWriter&quot;,</span><br><span class="line">              &quot;clustername&quot;: &quot;offline-kafka&quot;</span><br><span class="line">            &#125;</span><br><span class="line">          ],</span><br><span class="line">          &quot;obj&quot;: &quot;kafka.server:type=SessionExpireListener,name=ZooKeeperDisconnectsPerSec&quot;,</span><br><span class="line">          &quot;resultAlias&quot;: &quot;ZKDisConnectCnt&quot;,</span><br><span class="line">          &quot;attr&quot;: [</span><br><span class="line">            &quot;OneMinuteRate&quot;</span><br><span class="line">          ]</span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">          &quot;outputWriters&quot;: [</span><br><span class="line">            &#123;</span><br><span class="line">              &quot;@class&quot;: &quot;com.googlecode.jmxtrans.model.output.SentryOutWriter&quot;,</span><br><span class="line">              &quot;clustername&quot;: &quot;offline-kafka&quot;</span><br><span class="line">            &#125;</span><br><span class="line">          ],</span><br><span class="line">          &quot;obj&quot;: &quot;kafka.server:type=SessionExpireListener,name=ZooKeeperExpiredPerSec&quot;,</span><br><span class="line">          &quot;resultAlias&quot;: &quot;ZKExpiredCnt&quot;,</span><br><span class="line">          &quot;attr&quot;: [</span><br><span class="line">            &quot;OneMinuteRate&quot;</span><br><span class="line">          ]</span><br><span class="line">        &#125;</span><br><span class="line">      ],</span><br><span class="line">      &quot;numQueryThreads&quot;: 1</span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
</ol>
<h4 id="5-总结"><a href="#5-总结" class="headerlink" title="5. 总结"></a>5. 总结</h4><p>这样就可以把数据输出到我自己的监控;关于kafka的监控信息可以看<a href="http://andrewrong.github.io/2017/03/26/kafka-broker%E7%9A%84%E7%9B%91%E6%8E%A7%E4%BF%A1%E6%81%AF/" target="_blank" rel="noopener">这篇文章</a>，有什么问题可以通过<a href="https://twitter.com/andrew_rong" target="_blank" rel="noopener">twitter</a>私信给我;</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;https://github.com/jmxtrans/jmxtrans&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;jmxtrans&lt;/a&gt;是一个开源产品，主要的作用是通过定时轮训程序的jmx端口来获得程序内部的信息，并且输出到对应的
    
    </summary>
    
      <category term="kafka" scheme="http://yoursite.com/categories/kafka/"/>
    
    
      <category term="monitor" scheme="http://yoursite.com/tags/monitor/"/>
    
      <category term="jmxtrans" scheme="http://yoursite.com/tags/jmxtrans/"/>
    
  </entry>
  
  <entry>
    <title>kafka broker的监控信息</title>
    <link href="http://yoursite.com/2017/03/26/kafka-broker%E7%9A%84%E7%9B%91%E6%8E%A7%E4%BF%A1%E6%81%AF/"/>
    <id>http://yoursite.com/2017/03/26/kafka-broker的监控信息/</id>
    <published>2017-03-26T13:35:09.000Z</published>
    <updated>2017-04-06T23:17:27.000Z</updated>
    
    <content type="html"><![CDATA[<h3 id="1-broker的监控信息"><a href="#1-broker的监控信息" class="headerlink" title="1. broker的监控信息"></a>1. broker的监控信息</h3><table>
<thead>
<tr>
<th>标题</th>
<th>mbean name</th>
<th>解释</th>
</tr>
</thead>
<tbody>
<tr>
<td>Message in rate</td>
<td><code>kafka.server:type=BrokerTopicMetrics,name=MessagesInPerSec</code></td>
<td>当前broker每秒的消息个数</td>
</tr>
<tr>
<td>Byte in rate</td>
<td><code>kafka.server:type=BrokerTopicMetrics,name=BytesInPerSec</code></td>
<td>当前broker的每秒的入口流量</td>
</tr>
<tr>
<td>Byte out rate</td>
<td><code>kafka.server:type=BrokerTopicMetrics,name=BytesOutPerSec</code></td>
<td>当前broker的每秒的出口流量</td>
</tr>
<tr>
<td>Request rate</td>
<td><code>kafka.network:type=RequestMetrics,name=RequestsPerSec,request={Produce or FetchConsumer or FetchFollower}</code></td>
<td>当前broker的每秒的请求量; 根据request的不同会返回不同类型的数据</td>
</tr>
<tr>
<td>Log flush rate and time</td>
<td><code>kafka.log:type=LogFlushStats,name=LogFlushRateAndTimeMs</code></td>
<td>日志刷盘的频率和时间；其中<em>OneMinuteRate:表示一分钟内每秒钟的刷盘次数; </em>999thPercentile:99.9%的刷盘需要的时间</td>
</tr>
<tr>
<td>of under replicated partitions</td>
<td><code>kafka.server:type=ReplicaManager,name=UnderReplicatedPartitions</code></td>
<td>ISR &lt; 备份次数的分区个数，这样的分区应该=0，如果大于0就进行报警最好;</td>
</tr>
<tr>
<td>Is controller active on broker</td>
<td><code>kafka.controller:type=KafkaController,name=ActiveControllerCount</code></td>
<td>当前集群中controller的个数,一个集群只能有一个controller</td>
</tr>
<tr>
<td>Leader election rate</td>
<td><code>kafka.controller:type=ControllerStats,name=LeaderElectionRateAndTimeMs</code></td>
<td>leader选举的频率和需要的时间；其中<em>OneMinuteRate:表示一分钟内出现选举的次数; </em>999thPercentile:99.9%的选举需要的时间</td>
</tr>
<tr>
<td>Unclean leader election rate</td>
<td><code>kafka.controller:type=ControllerStats,name=UncleanLeaderElectionsPerSec</code></td>
<td>非正常的备份被选举成leader的频率;</td>
</tr>
<tr>
<td>Partition counts</td>
<td><code>kafka.server:type=ReplicaManager,name=PartitionCount</code></td>
<td>当前broker的分区个数,就是在存储数据的目录下面的分区个数;</td>
</tr>
<tr>
<td>Leader replica counts</td>
<td><code>kafka.server:type=ReplicaManager,name=LeaderCount</code></td>
<td>当前broker中的leader分区的个数</td>
</tr>
<tr>
<td>ISR shrink rate</td>
<td><code>kafka.server:type=ReplicaManager,name=IsrShrinksPerSec</code></td>
<td>当前broker每分钟分区缩减的频率;</td>
</tr>
<tr>
<td>ISR expansion rate</td>
<td><code>kafka.server:type=ReplicaManager,name=IsrExpandsPerSec</code></td>
<td>当前broker每分钟分区扩展的频率;</td>
</tr>
<tr>
<td>Max lag in messages btw follower and leader replicas</td>
<td><code>kafka.server:type=ReplicaFetcherManager,name=MaxLag,clientId=Replica</code></td>
<td>当前broker中分区与leader之前同步的最大lag数</td>
</tr>
<tr>
<td>Lag in messages per follower replica</td>
<td><code>kafka.server:type=FetcherLagMetrics,name=ConsumerLag,clientId=([-.\w]+),topic=([-.\w]+),partition=([0-9]+)</code></td>
<td>当前broker中备本分区与leader之间的lag数</td>
</tr>
<tr>
<td>Requests waiting in the producer purgatory</td>
<td><code>kafka.server:type=DelayedOperationPurgatory,name=PurgatorySize,delayedOperation=Produce</code></td>
<td>broker中，在等待ack的producer请求个数;还有Fetch、topic、Rebalance、Heartbeat请求</td>
</tr>
<tr>
<td>Request total time</td>
<td><code>kafka.network:type=RequestMetrics,name=TotalTimeMs,request={Produce or FetchConsumer or FetchFollower}</code></td>
<td>请求所需要的全部时间;根据不同的类型求个不一样的结果</td>
</tr>
<tr>
<td>Time the request waits in the request queue</td>
<td><code>kafka.network:type=RequestMetrics,name=RequestQueueTimeMs,request={Produce or FetchConsumer or FetchFollower}</code></td>
<td>请求在队列中等待的时间</td>
</tr>
<tr>
<td>Time the request is processed at the leader</td>
<td><code>kafka.network:type=RequestMetrics,name=LocalTimeMs,request={Produce or FetchConsumer or FetchFollower}</code></td>
<td>请求被leader节点处理的时间</td>
</tr>
<tr>
<td>Time the request waits for the follower</td>
<td><code>kafka.network:type=RequestMetrics,name=RemoteTimeMs,request={Produce or FetchConsumer or FetchFollower}</code></td>
<td>一个请求等待follower的时间;假如ack=all，那么这个值就是非0</td>
</tr>
<tr>
<td>Time the request waits in the response queue</td>
<td><code>kafka.network:type=RequestMetrics,name=ResponseQueueTimeMs,request={Produce or FetchConsumer or FetchFollower}</code></td>
<td>一个请求在response队列中的时间</td>
</tr>
<tr>
<td>Time to send the response</td>
<td><code>kafka.network:type=RequestMetrics,name=ResponseSendTimeMs,request={Produce or FetchConsumer or FetchFollower}</code></td>
<td>发送请求的时间</td>
</tr>
<tr>
<td>Number of messages the consumer lags behind the producer by. Published by the consumer, not broker.</td>
<td><code>Old consumer: kafka.consumer:type=ConsumerFetcherManager,name=MaxLag,clientId=([-.\w]+) New consumer: kafka.consumer:type=consumer-fetch-manager-metrics,client-id={client-id} Attribute: records-lag-max</code></td>
<td>consumer落后producer的lag</td>
</tr>
<tr>
<td>The average fraction of time the network processors are idle</td>
<td><code>kafka.network:type=SocketServer,name=NetworkProcessorAvgIdlePercent</code></td>
<td>网络处理空闲的因子，在0，1之间，通常是&gt; 0.3</td>
</tr>
<tr>
<td>The average fraction of time the request handler threads are idle</td>
<td><code>kafka.server:type=KafkaRequestHandlerPool,name=RequestHandlerAvgIdlePercent</code></td>
<td>网络请求线程空闲的平均值，在0，1之间，通常是&gt; 0.3</td>
</tr>
</tbody>
</table>
<h3 id="2-关于zookeeper相关的监控信息"><a href="#2-关于zookeeper相关的监控信息" class="headerlink" title="2. 关于zookeeper相关的监控信息"></a>2. 关于zookeeper相关的监控信息</h3><table>
<thead>
<tr>
<th>mbean name</th>
<th>解释</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>kafka.server:type=SessionExpireListener,name=ZooKeeperDisconnectedPerSec</code></td>
<td>当前broker与zk之间的每秒断链的次数；也就是频率</td>
</tr>
<tr>
<td><code>kafka.server:type=SessionExpireListener,name=ZooKeeperSyncConnectedPerSec</code></td>
<td>ZooKeeper client is connected to the ensemble and ready to execute operations</td>
</tr>
<tr>
<td><code>kafka.server:type=SessionExpireListener,name=ZooKeeperAuthFailedPerSec</code></td>
<td>与zk进行连接并且是因为认证失败的每秒的次数</td>
</tr>
<tr>
<td><code>kafka.server:type=SessionExpireListener,name=ZooKeeperConnectedReadOnlyPerSec</code></td>
<td>The server the client is connected to is currently LOOKING, which means that it is neither FOLLOWING nor LEADING. Consequently, the client can only read the ZooKeeper state, but not make any changes (create, delete, or set the data of znodes).</td>
</tr>
<tr>
<td><code>kafka.server:type=SessionExpireListener,name=ZooKeeperSaslAuthenticatedPerSec</code></td>
<td>zkclient被验证成功每秒的次数</td>
</tr>
<tr>
<td><code>kafka.server:type=SessionExpireListener,name=ZooKeeperExpiredPerSec</code></td>
<td>当前zkclient被过期的每秒次数</td>
</tr>
</tbody>
</table>
<h3 id="3-consumer和producer的监控信息"><a href="#3-consumer和producer的监控信息" class="headerlink" title="3. consumer和producer的监控信息"></a>3. consumer和producer的监控信息</h3><ul>
<li><a href="http://docs.confluent.io/3.0.0/kafka/monitoring.html#producer-global-request-metrics" target="_blank" rel="noopener">confluent doc</a></li>
<li><a href="https://kafka.apache.org/documentation/#monitoring" target="_blank" rel="noopener">kafka doc</a></li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;1-broker的监控信息&quot;&gt;&lt;a href=&quot;#1-broker的监控信息&quot; class=&quot;headerlink&quot; title=&quot;1. broker的监控信息&quot;&gt;&lt;/a&gt;1. broker的监控信息&lt;/h3&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;标题
    
    </summary>
    
      <category term="kafka" scheme="http://yoursite.com/categories/kafka/"/>
    
    
      <category term="monitor" scheme="http://yoursite.com/tags/monitor/"/>
    
  </entry>
  
  <entry>
    <title>同步、异步、阻塞、非阻塞</title>
    <link href="http://yoursite.com/2017/03/03/%E5%90%8C%E6%AD%A5%E3%80%81%E5%BC%82%E6%AD%A5%E3%80%81%E9%98%BB%E5%A1%9E%E3%80%81%E9%9D%9E%E9%98%BB%E5%A1%9E/"/>
    <id>http://yoursite.com/2017/03/03/同步、异步、阻塞、非阻塞/</id>
    <published>2017-03-03T09:35:52.000Z</published>
    <updated>2017-04-06T23:17:49.000Z</updated>
    
    <content type="html"><![CDATA[<p>同步异步阻塞非阻塞这几个概念其实很早就出现在我的脑中，但是到现在为止都还是很难把它理解清楚，尤其是这几个概念总是会被混淆一起来讲。最近算是工作比较闲，在网上查询了大量的文章，发现一些人对这几个概念有着与众不同的解释，也正好能完美的解决我心中的疑云.</p>
<p>先引用几个别人对此的理解，我觉得他们理解的特别有理;</p>
<blockquote>
<pre><code>•    阻塞与非阻塞：区别在于完成一件事情时，当事情还没有完成时，处理这件事情的人除此之外不能再做别的事情；
•    同步与异步：是自己去做这件事情，还是等别人做好了来通知有结果，然后再自己去拿结果。注意这里说的是拿结果，如果只是别人告诉你可以做某事，然后自己去操作，这种情况下也是同步的操作;[link](http://h2ex.com/639)
</code></pre></blockquote>
<p>还有一个知乎上的回答，觉得<a href="https://www.zhihu.com/question/19732473" target="_blank" rel="noopener">严肃回答</a>的也是特别好.</p>
<h5 id="阻塞非阻塞"><a href="#阻塞非阻塞" class="headerlink" title="阻塞非阻塞"></a>阻塞非阻塞</h5><p>是程序在等待调用的时候的状态; 说大白话就是: 程序调用了某一个接口的时候，他是否还有<strong>可能</strong>去做其他的事情, 如果有可能那就是非阻塞，如果没有可能那就是阻塞; 这里举个大家都知道的例子,比如<code>read</code>(反正大家都喜欢用这个例子):</p>
<p>这有两个角色:</p>
<pre><code>* 调用者: 调用read的线程或者进程
* 被调用者: read本身
</code></pre><p>Linux文件在open的过程可以选择(block | noblock)两种方式，而这两种方式的最大区别点在于：block模式下，调用read之后会阻塞(阻塞的原因在<a href="http://blog.csdn.net/historyasamirror/article/details/5778378" target="_blank" rel="noopener">这篇文章</a>中有很详细的介绍), 就调用者在此时此刻它是会被操作系统挂起，它在此刻没有<strong>可能</strong>去做其他的事情, 这就是阻塞(<strong>没有可能性</strong>).</p>
<p>如果是在非阻塞的模式下，调用read之后会很快的返回, 这个返回有两种可能: error 或者 读到了数据; 虽然我们在使用非阻塞的时候，总是在外围加上while循环,类似于:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">do &#123;</span><br><span class="line">	read(fd, buf, count);</span><br><span class="line">&#125;while(errno == EWOULDBLOCK);</span><br></pre></td></tr></table></figure>
<p>通过这种方式去不断询问内核是否已经把数据准备好，而这个过程中，虽然大部分用法是选择不停的询问，但是这只是一种做法，调用者还是其他的更多的方式可以选择，比如调用者发现数据还没有准备好，那它可以把之前的数据排一个序什么的，这表示调用者在此刻是有选择做其他的事情的<strong>可能性</strong>的;</p>
<p>在思考阻塞和非阻塞的时候，需要先把角色分成为调用者与被调用者，这是一个很简单的一点，不要去思考被调用者内部是如何实现的，只需要在调用者与被调用者这个层面: <em>思考调用者调用的时候是否还有可能去做其他的事情为依据来进行区别</em>; 为什么要在同一个层面来看呢？因为层次不同得到的结果也不一样; 这里在举一个例子: 我封装了一个函数A，A内部的实现就是上面的实例代码，那A本身是否是阻塞呢？回答是:YES, 因为其他人在调用A时候，没有可能去做其他的事情了，这个时候它整体都在等待A的返回，所以这就是阻塞.</p>
<h5 id="同步与异步"><a href="#同步与异步" class="headerlink" title="同步与异步"></a>同步与异步</h5><ul>
<li>同步: 调用者为了获得结果，主动等待结果的返回(<strong>结果已经完成</strong>);</li>
<li>异步: 调用者获得的结果的方式被动通知，当接受到通知的时候就表示调用者需要的<strong>结果已经完成</strong>;</li>
</ul>
<p><code>结果已经完成</code>的定义是:调用者获得了一开始就想要的结果;</p>
<p>所以区别同步异步的关键点是在于:</p>
<ul>
<li>调用者是否主动等待</li>
<li>在被通知获得结果的时候，调用者想要获得结果是否已经完成</li>
</ul>
<p>按照上面的理论我们来分析几个调用是同步还是异步？还是分为两个角色:</p>
<ul>
<li>调用者</li>
<li>被调用者</li>
</ul>
<ol>
<li><p>read</p>
<p> 依然是上面的那个例子；当调用者调用read(被调用者)，这个时候调用者就主动在等待结果的返回，直到read返回，调用者才得到自己想要的东西; 所以是主动等待，所以这是同步操作</p>
</li>
<li><p>AIO(异步IO)</p>
<p> 应用层发起AIO操作之后，被调用者直接返回; 调用者这个时候就不在关心这个事情了; 当操作系统把数据准备好并且copy到对应的应用层内存之后，就会通过类似于事件通知的方式来通知应用程序; 这个过程中</p>
<ul>
<li>调用者是被动通知结果</li>
<li><p>调用者在收到通知的那时它想获得结果已经完成(需要读取的数据已经放在对应的应用层的内存中了)</p>
<p>所以AIO是异步的</p>
</li>
</ul>
</li>
<li><p>多路复用IO</p>
</li>
</ol>
<p>select、poll、epoll都是多路IO; 那么它们是同步还是异步呢？这可能是大部分人难以弄清楚的事情；而且很多文章本身也是没有搞清楚或者是错误的理论; 先说一个结果</p>
<blockquote>
<p>多路IO都是同步的</p>
</blockquote>
<p>下面分析一下原因:</p>
<p>通过多路IO本身是通过将读写事件注册到统一的地方，有内核通过某一种方式(select、poll、epoll的实现方式都不一样)来统一的做轮训，这样的好处就是一个线程管理多个连接; 如果不是这样的话每一个链接都需要阻塞，非常浪费资源; 但是从异步的两个关键点来说:</p>
<ul>
<li>多路IO是通知调用者的</li>
<li>多路IO在通知的时候，只是告诉你可以读写了，但没有真正的读写操作完成，还是需要调用者自己去完成读写操作;</li>
</ul>
<p>所以多路IO是同步,而非异步;</p>
<p>和阻塞非阻塞一样，同步与异步的也是有层次的划分的；就目前操作系统来说，真正的异步io就只有AIO，其他的IO都是同步IO，原因是不管怎么样从内核到应用层的内存copy都需要调用者自己也操作，所以都是同步io；但是如果将异步同步这个概念放宽一些，从不同层次上来思考的话，我们发现现在很多市面上的网络框架都能达到异步的一个概念；比如seastar、folly的future，node.js等，这些框架可能在实现上都不一样但是不管怎么样，在概念上都已经是异步了.</p>
<h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><p>个人感觉(对自己而言)思考的已经很清楚了；异步同步、阻塞非阻塞，虽然相关但是其实关注的维度是不一样的，所以谈论的过程中不要尝试混淆.</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;同步异步阻塞非阻塞这几个概念其实很早就出现在我的脑中，但是到现在为止都还是很难把它理解清楚，尤其是这几个概念总是会被混淆一起来讲。最近算是工作比较闲，在网上查询了大量的文章，发现一些人对这几个概念有着与众不同的解释，也正好能完美的解决我心中的疑云.&lt;/p&gt;
&lt;p&gt;先引用几个
    
    </summary>
    
      <category term="Linux" scheme="http://yoursite.com/categories/Linux/"/>
    
    
      <category term="异步同步" scheme="http://yoursite.com/tags/%E5%BC%82%E6%AD%A5%E5%90%8C%E6%AD%A5/"/>
    
  </entry>
  
</feed>
