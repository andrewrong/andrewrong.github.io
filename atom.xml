<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>nomoshen</title>
  <subtitle>尽可能努力一点点</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2017-04-04T12:19:13.000Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>nomoshen</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>scylladb 官文安装译文</title>
    <link href="http://yoursite.com/2017/04/04/scylladb-%E5%AE%98%E6%96%87%E5%AE%89%E8%A3%85%E8%AF%91%E6%96%87/"/>
    <id>http://yoursite.com/2017/04/04/scylladb-官文安装译文/</id>
    <published>2017-04-04T11:56:06.000Z</published>
    <updated>2017-04-04T12:19:13.000Z</updated>
    
    <content type="html"><![CDATA[<p>主要的依赖于官方的教程，这边主要是将一些细节进行串联描述，下次安装的时候会更加自动化;</p>
<p>我的安装环境如下：</p>
<ul>
<li>centos7.2</li>
<li>内核版本为3.18</li>
</ul>
<h4 id="1-关于scylladb几个rpm的介绍"><a href="#1-关于scylladb几个rpm的介绍" class="headerlink" title="1. 关于scylladb几个rpm的介绍"></a>1. 关于scylladb几个rpm的介绍</h4><ul>
<li>scylla-server(standard):scylladb主要的server端</li>
<li>scylla-server(debuginfo):scylladb server端并且带有debuginfo</li>
<li>scylla-jmx: 兼容cassandra通过jmx端口进行访问</li>
<li>scylla-tools: scylla为了兼容cassandra而提供的类似的功能:<ul>
<li>nodetool:很强大的功能，用来观察集群状态</li>
<li>cqlsh:</li>
<li>cassandra-stress:压测工具</li>
</ul>
</li>
</ul>
<h4 id="2-前期准备"><a href="#2-前期准备" class="headerlink" title="2.前期准备"></a>2.前期准备</h4><ul>
<li>删除abrt,主要是这个与scylladb本身的coredump配置冲突; <code>yum remove -y abrt</code></li>
<li>必须有sudo权限</li>
<li>预安装的东西, <code>yum install -y wget epel-release</code>, <code>epel-release</code>是一个fedora维护的软件仓库，全名叫做<em>企业版Linux额外软件包</em></li>
</ul>
<h4 id="3-正式开始装"><a href="#3-正式开始装" class="headerlink" title="3. 正式开始装"></a>3. 正式开始装</h4><ul>
<li>下载最新的scylladb源，由于每次更新源都会有一定的变化，所以每一次更新的时候最好要更新一下源;下面的源是1.4版本的</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">sudo wget -O /etc/yum.repos.d/scylla.repo http://downloads.scylladb.com/rpm/centos/scylla-1.4.repo</div></pre></td></tr></table></figure>
<ul>
<li><p>是scylla yum源生效; <code>yum clean all; yum makecache</code></p>
</li>
<li><p>安装scylla; <code>yum install -y scylla</code></p>
</li>
</ul>
<p>如果一些顺利的话，到这一步scylladb就已经安装完毕了</p>
<h4 id="4-配置和脚本相关的"><a href="#4-配置和脚本相关的" class="headerlink" title="4. 配置和脚本相关的"></a>4. 配置和脚本相关的</h4><table>
<thead>
<tr>
<th>配置名字</th>
<th>配置作用</th>
<th>配置位置</th>
</tr>
</thead>
<tbody>
<tr>
<td>scylladb的主要配置</td>
<td>设定一些主要的参数，比如存储位置、开放端口和ip，也会有一些性能参数设置</td>
<td>/etc/scylla/scylla.yaml</td>
</tr>
<tr>
<td>scylla启动脚本</td>
<td></td>
<td>/etc/sysconfig/scylla-server</td>
</tr>
<tr>
<td>系统资源限制</td>
<td>去掉对scylla用户的资源限制</td>
<td>/etc/security/limits.d/scylla.conf</td>
</tr>
<tr>
<td>启动脚本</td>
<td>设置参数、启动scylladb脚本</td>
<td>/etc/sysconfig/scylla-server</td>
</tr>
<tr>
<td>coredump配置文件</td>
<td>设置coredump的配置文件</td>
<td>/etc/sysconfig/sysctl.d/99-scylla.conf</td>
</tr>
<tr>
<td>collectd配置文件</td>
<td>设置collectd的一些配置</td>
<td>/etc/collectd.d/scylla.conf</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th>配置名字</th>
<th>配置作用</th>
<th>配置位置</th>
</tr>
</thead>
<tbody>
<tr>
<td>内核设置</td>
<td>在bootloader中设置内核参数</td>
<td>/usr/lib/scylla/scylla_bootparam_setup</td>
</tr>
<tr>
<td>coredump配置文件生成器</td>
<td></td>
<td>/usr/lib/scylla/scylla_coredump_setup</td>
</tr>
<tr>
<td>ntp协议配置生成器</td>
<td></td>
<td>/usr/lib/scylla/scylla_ntp_setup</td>
</tr>
<tr>
<td>网络配置设定</td>
<td></td>
<td>/usr/lib/scylla/scylla_prepare</td>
</tr>
<tr>
<td>配置raid和文件系统的脚本</td>
<td></td>
<td>/usr/lib/scylla/scylla_raid_setup</td>
</tr>
<tr>
<td>压缩coredump脚本</td>
<td>only ubuntu有效</td>
<td>/usr/lib/scylla/save_coredump</td>
</tr>
<tr>
<td>重新设置网络模式</td>
<td>如果scylladb运行的virtio或者DPDK的话，就重新设置网络模式</td>
<td>/usr/lib/scylla/scylla_stop</td>
</tr>
<tr>
<td>重新设置网络参数</td>
<td></td>
<td>/usr/lib/scylla/posix_net_conf.sh</td>
</tr>
<tr>
<td>io.conf生成器</td>
<td>用于测试io性能，并且把文件提供给scylladb</td>
<td>/usr/lib/scylla/scylla_io_setup </td>
</tr>
</tbody>
</table>
<p>上面这些脚本都是在<code>/usr/lib/scylla</code>目录下面的，并且还有其他的脚本，这些脚本会在运行scylla_setup的时候会调用;详情请看<a href="http://www.scylladb.com/doc/system-configuration/" target="_blank" rel="external">url</a></p>
<table>
<thead>
<tr>
<th>作用</th>
<th>端口值</th>
</tr>
</thead>
<tbody>
<tr>
<td>cql</td>
<td>9042</td>
</tr>
<tr>
<td>内部rpc</td>
<td>7000</td>
</tr>
<tr>
<td>ssl内部rpc</td>
<td>7001</td>
</tr>
<tr>
<td>jmx 端口</td>
<td>7199</td>
</tr>
<tr>
<td>scylla rest api</td>
<td>10000</td>
</tr>
<tr>
<td>Scylla Prometheus API(不知道是什么)</td>
<td>9180</td>
</tr>
<tr>
<td>node_exporter</td>
<td>9100</td>
</tr>
</tbody>
</table>
<h4 id="5-具体的配置"><a href="#5-具体的配置" class="headerlink" title="5. 具体的配置"></a>5. 具体的配置</h4><table>
<thead>
<tr>
<th>配置项</th>
<th>含义</th>
</tr>
</thead>
<tbody>
<tr>
<td>seeds</td>
<td>种子ip列表，建议多几个ip</td>
</tr>
<tr>
<td>listen_address</td>
<td>scylladb内部通信的ip</td>
</tr>
<tr>
<td>rpc_address</td>
<td>客户端连接scylladb的ip</td>
</tr>
<tr>
<td>broadcast_address</td>
<td>默认listen_address，从其他节点角度看这个node的ip，可能是不同网络之间不同，而通过外网来进行互联</td>
</tr>
<tr>
<td>broadcast_rpc_address</td>
<td>默认是rpc_address,从client角度上来你应该是什么ip，同上</td>
</tr>
</tbody>
</table>
<h4 id="6-scylladb管理命令"><a href="#6-scylladb管理命令" class="headerlink" title="6. scylladb管理命令"></a>6. scylladb管理命令</h4><table>
<thead>
<tr>
<th>命令</th>
<th>作用</th>
</tr>
</thead>
<tbody>
<tr>
<td>scylla –version</td>
<td>查看版本</td>
</tr>
<tr>
<td>nodetool snapshot</td>
<td>将node数据进行快照;关于scylladb snapshot的原理是：通过linux的hardlink来进行备份，因为scylladb的文件产生之后会不会改变所以这样能很好的保证备份的作用，并且用来了hardlink保证文件的可用性，和不需要通过拷贝也加重系统的负载;</td>
</tr>
<tr>
<td>恢复备份</td>
<td>1. 清空commitlog 2. 清空data目录下面的数据文件 3. 把snapshot备份的文件mv过来即可 4. 重启</td>
</tr>
<tr>
<td>提供rest接口</td>
<td></td>
</tr>
<tr>
<td>scyllatop</td>
<td>scylla自己的top, 目测可以与collectd一起使用，并且提供比较好的功能</td>
</tr>
<tr>
<td>Prometheus</td>
<td>scylla自己的监控系统</td>
</tr>
<tr>
<td>collectd</td>
<td>scylladb本地会启动collectd的进程，用来接收scylladb抛送过来的数据，可以通过插件的方式来修改，比较方便，并且会增加scyllatop看到的数据</td>
</tr>
<tr>
<td>log</td>
<td>scylla log是通过centos7的 journalctl 来控制的；最常用的有<code>journalctl _COMM=scylla -p warning</code> 或者 <code>journalctl _COMM=scylla --since &quot;2015-01-10&quot; --until &quot;2015-01-11 03:00</code> 或者 <code>journalctl _COMM=scylla -b(从最近一次重启的日志)</code></td>
</tr>
</tbody>
</table>
<p>node tool命令介绍</p>
<table>
<thead>
<tr>
<th>命令</th>
<th>作用</th>
</tr>
</thead>
<tbody>
<tr>
<td>nodetool status</td>
<td>看集群的状态,<a href="http://www.scylladb.com/doc/nodetool-commands/status/" target="_blank" rel="external">详情</a></td>
</tr>
<tr>
<td>nodetool snapshot</td>
<td>上面已提过</td>
</tr>
<tr>
<td>nodetool cfhistograms</td>
<td>提供每一个表的静态数据，包括sstable的个数、读写延迟、分区的尺寸和列簇的个数;<code>nodetoll sfhistograms keyspace tablename</code>,<a href="http://www.scylladb.com/doc/nodetool-commands/cfhistograms/" target="_blank" rel="external">详情</a></td>
</tr>
<tr>
<td>nodetool cfstats</td>
<td>提供对特定的表的一个深层的分析;<code>nodetool cfstats keyspace.tablename</code>,<a href="http://www.scylladb.com/doc/nodetool-commands/cfstats/" target="_blank" rel="external">详情</a></td>
</tr>
<tr>
<td>nodetool cleanup</td>
<td>立即触发清理不属于本机的key；<code>nodetool cleanup -h 127.0.0.1 keyspace</code></td>
</tr>
<tr>
<td>nodetool clearsnapshot</td>
<td>清理snapshot文件,<code>nodetool clearsnapshot keyspace</code>,不写keyspace就默认删除全部的snapshot </td>
</tr>
<tr>
<td>compactionhistory</td>
<td>打印compact的历史</td>
</tr>
<tr>
<td>compactionstats</td>
<td>打印目前正在compact的进度和一些信息</td>
</tr>
<tr>
<td>compact</td>
<td>对可能的keyspac而进行强制的compact操作; <code>nodetool compact keyspace</code></td>
</tr>
<tr>
<td>describecluster</td>
<td>打印一些信息</td>
</tr>
<tr>
<td>decommission</td>
<td></td>
</tr>
<tr>
<td>describering</td>
<td>打印某一个keyspace的一致性hash分布情况</td>
</tr>
<tr>
<td>disablebackup</td>
<td>关闭增量备份</td>
</tr>
<tr>
<td>disablebinary</td>
<td>关闭cql</td>
</tr>
<tr>
<td>statusbinary</td>
<td>看cql当前运行的状态</td>
</tr>
<tr>
<td>enablebinary</td>
<td>开启cql</td>
</tr>
<tr>
<td>statusgossip</td>
<td>gossip协议的运行状态</td>
</tr>
<tr>
<td>disablegossip</td>
<td>关闭gossip</td>
</tr>
<tr>
<td>enablegossip</td>
<td>开启gossip</td>
</tr>
<tr>
<td>drain</td>
<td>通常用于升级scylladb之前使用，主要的操作是将所有的memtable全部写入到sstable，然后停止listen各种端口，之后要恢复必须通过重启</td>
</tr>
<tr>
<td>flush</td>
<td>将当然的memtable刷成sstable</td>
</tr>
<tr>
<td>getendpoints</td>
<td><code>nodetool getendpoints keyspace tablename key</code>,现在还不知道用来做什么</td>
</tr>
<tr>
<td>getlogginglevels</td>
<td>获得运行时中的日志等级</td>
</tr>
<tr>
<td>gossipinfo</td>
<td>展示gossip协议中传播的东西</td>
</tr>
<tr>
<td>info</td>
<td>展现当前节点的一些信息; <a href="http://www.scylladb.com/doc/nodetool-commands/info/" target="_blank" rel="external">详情</a></td>
</tr>
<tr>
<td>listsnapshots</td>
<td>展示所有的snapshot在磁盘上的占用率</td>
</tr>
<tr>
<td>move</td>
<td>将node 分配到新的token</td>
</tr>
<tr>
<td>netstats</td>
<td>打印一些网络信息</td>
</tr>
<tr>
<td>proxyhistograms</td>
<td>对于网络操作打印一些静态统计</td>
</tr>
<tr>
<td>rebuild <src-dc-name></src-dc-name></td>
<td>从另外一个节点重建数据</td>
</tr>
<tr>
<td>refrash <keyspace> <tablename></tablename></keyspace></td>
<td>在不重启的前提下，重新reload文件中的sstable</td>
</tr>
<tr>
<td>removenode <id></id></td>
<td>移除名为id的节点</td>
</tr>
<tr>
<td>repair</td>
<td>修复一个或者多个的列簇； 参数比较多，使用前查询;</td>
</tr>
<tr>
<td>ring</td>
<td>显示一致性hash的列表</td>
</tr>
<tr>
<td>setlogginglevel <class> <threshold></threshold></class></td>
<td>设置某一个类的运行时日志等级</td>
</tr>
<tr>
<td>settraceprobability – <value></value></td>
<td>设置跟踪请求的概率，value在0~1之间</td>
</tr>
<tr>
<td>snapshot [-t tag] [-cf tablename] <keyspace></keyspace></td>
<td>针对具体的表或keyspace做快照</td>
</tr>
<tr>
<td>statusbackup</td>
<td>增量backup的状态</td>
</tr>
<tr>
<td>stop</td>
<td>停止compact任务</td>
</tr>
<tr>
<td>version</td>
<td>db的版本  </td>
</tr>
</tbody>
</table>
<p>nodetool info几个参数介绍</p>
<table>
<thead>
<tr>
<th>参数</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>Gossip active</td>
<td>gossip状态</td>
</tr>
<tr>
<td>Thrift active</td>
<td>thrift 状态</td>
</tr>
<tr>
<td>native transport active</td>
<td>cql的状态</td>
</tr>
<tr>
<td>Load</td>
<td>sstable占磁盘多少空间</td>
</tr>
<tr>
<td>Generation NO</td>
<td>主版本，当节点重启、token更新，这个版本就会往上增加</td>
</tr>
<tr>
<td>Uptime</td>
<td>scylla没有这个</td>
</tr>
<tr>
<td>Heap Memory</td>
<td>scylla没有这个</td>
</tr>
<tr>
<td>off Heap memory (MB)</td>
<td>所有的memtables、bloom filters 、indexs、compression metadata占用的内存</td>
</tr>
<tr>
<td>Data center</td>
<td>这个节点所在的数据中心</td>
</tr>
<tr>
<td>Rack</td>
<td>？？、</td>
</tr>
<tr>
<td>Exception</td>
<td>scylla没有这个</td>
</tr>
<tr>
<td>Key Cache</td>
<td>scylla没有这个</td>
</tr>
<tr>
<td>Row Cache</td>
<td>Row cache的信息</td>
</tr>
<tr>
<td>Counter Cache</td>
<td>scylla没有这个</td>
</tr>
<tr>
<td>Token</td>
<td>token展示</td>
</tr>
</tbody>
</table>
<h4 id="7-关于scylladb的monitor安装-由于官方教程变化太大-以官方为准"><a href="#7-关于scylladb的monitor安装-由于官方教程变化太大-以官方为准" class="headerlink" title="7. 关于scylladb的monitor安装[由于官方教程变化太大,以官方为准]"></a>7. 关于scylladb的monitor安装[由于官方教程变化太大,以官方为准]</h4><p>目前scylladb的监控是使用<a href="https://github.com/scylladb/scylla-grafana-monitoring" target="_blank" rel="external">Grafana and Prometheus
</a>, 具体的安装过程如下:</p>
<ol>
<li>首先安装docker在服务器上; <code>sudo yum install -y docker</code></li>
<li>启动docker服务;<code>sudo service docker start</code></li>
<li>验证docker安装情况; <code>sudo docker ps -a or sudo docker images</code></li>
</ol>
<p>其实监控安装比较简单，但是由于网络问题安装就变成很蛋疼的过程;</p>
<ul>
<li>首先通过mac翻墙下载docker 镜像; <code>prom/prometheus</code> and <code>grafana/grafana</code>;</li>
</ul>
<pre><code>    <figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">			docker pull prom/prometheus:v1.5.2</div><div class="line">			docker pull grafana/grafana:4.1.1</div><div class="line">		``` </div><div class="line">	</div><div class="line">* 将镜像导出成tar格式的文件</div></pre></td></tr></table></figure>

        docker save imageid -o xxx.tar
    <figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"></div><div class="line"></div><div class="line">镜像id可以通过`docker images`来得到</div></pre></td></tr></table></figure>

    $ docker images
    REPOSITORY          TAG                 IMAGE ID            CREATED             SIZE
    grafana/grafana     latest              a892c250adfa        11 days ago         266.2 MB
    prom/prometheus     latest              bdeacb538ef9        2 weeks ago         79.25 MB
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"></div><div class="line">* 将tar文件上传到服务器，然后导入服务器的docker</div></pre></td></tr></table></figure>

    docker load -i xxx.tar
    #修改对应的name和版本
    docker tag imageId name:tag

    sudo docker tag  047fd14b7251 prom/prometheus:v1.0.0
    sudo docker tag d7528263f75a grafana/grafana:3.1.0

<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"></div><div class="line">* 下载 scylla-grafana-monitoring 项目</div></pre></td></tr></table></figure>

    git clone https://github.com/scylladb/scylla-grafana-monitoring.git
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"></div><div class="line">* 修改prometheus的配置文件</div></pre></td></tr></table></figure>

    global:
    # 采集周期
      scrape_interval: 15s # By default, scrape targets every 15 seconds.

      # Attach these labels to any time series or alerts when communicating with
      # external systems (federation, remote storage, Alertmanager).
      external_labels:
        monitor: &apos;scylla-monitor&apos;

    scrape_configs:
        - job_name: scylla
      honor_labels: true
      static_configs:
      # 这个是scylladb服务的地址，这边是主动采集为主，不是被动上报，主要收集scylla的metric信息
          - targets: [&quot;10.19.11.23:9180&quot;]
        - job_name: node_exporter
      honor_labels: true
      static_configs:
      # 这部分主要是收集scylla的机器的信息，需要通过node_exporter 来开启这个上报;
          - targets: [&apos;10.19.11.23:9100&apos;]

    ## two servers example: - targets: [&quot;172.17.0.3:9103&quot;,&quot;172.17.0.2:9103&quot;]
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"></div><div class="line"></div><div class="line">* 用启动脚本启动</div></pre></td></tr></table></figure>

    sudo sh start-all.sh -d data_dir -v 1.6
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"></div><div class="line">data路径最好要配置一个，不然两次启动会把数据删除</div><div class="line">-v: 用来表示加载哪个系统版本</div><div class="line"></div><div class="line">这个可能会碰到一个问题，</div></pre></td></tr></table></figure>

    598cf3f9e16f0e5df2a1f0cf79df8be2ee0909f80307e392911d140b2ff6dac8
    Wait for Prometheus container to start..        4721e32c86ea09f1e16d270a194eb979cbf61f249c066435234e7d5cafee8631
    Wait for Grafana container to start........curl: (7) Failed connect to localhost:3000; Connection refused
    curl: (7) Failed connect to localhost:3000; Connection refused
    curl: (7) Failed connect to localhost:3000; Connection refused        curl: (7) Failed connect to localhost:3000; Connection refused
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"></div><div class="line">Grafana 没有起来 或者起来，但是还没有监听端口，然后脚本最多只是重试7次，这个时候就会报错，其实后期grafana是成功起来的；</div><div class="line"></div><div class="line">解决方式有两个：</div><div class="line"></div><div class="line">	1. 先执行脚本，然后等到grafana起来，然后关掉prometheus,然后修改start-all.sh中的脚本，把docker run grafana那个部分去掉，然后在执行start-all.sh, 这样就ok了</div><div class="line">	2. 将重试几次增大</div><div class="line"></div><div class="line"></div><div class="line">* 关闭监控</div></pre></td></tr></table></figure>

    sudo sh kill-all.sh
```
</code></pre>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;主要的依赖于官方的教程，这边主要是将一些细节进行串联描述，下次安装的时候会更加自动化;&lt;/p&gt;
&lt;p&gt;我的安装环境如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;centos7.2&lt;/li&gt;
&lt;li&gt;内核版本为3.18&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&quot;1-关于scylladb几个r
    
    </summary>
    
    
      <category term="scylladb" scheme="http://yoursite.com/tags/scylladb/"/>
    
  </entry>
  
  <entry>
    <title>为新的jmxtrans添加新的outputwriter</title>
    <link href="http://yoursite.com/2017/03/27/%E4%B8%BA%E6%96%B0%E7%9A%84jmxtrans%E6%B7%BB%E5%8A%A0%E6%96%B0%E7%9A%84outputwriter/"/>
    <id>http://yoursite.com/2017/03/27/为新的jmxtrans添加新的outputwriter/</id>
    <published>2017-03-27T13:52:00.000Z</published>
    <updated>2017-03-27T14:59:07.000Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://github.com/jmxtrans/jmxtrans" target="_blank" rel="external">jmxtrans</a>是一个开源产品，主要的作用是通过定时轮训程序的jmx端口来获得程序内部的信息，并且输出到对应的外界监控系统，比如ganglia、es、influxdb等；由于它的这种作用，所以不少的人将它使用在对一些开源组件的监控. 而我主要用它来将kafka中的broker信息输出到我们内部的监控。</p>
<p>年前已经将监控信息输出到了ganglia，但是这不能与我们的报警系统好好的融合起来，我基本不可能时时刻刻盯着监控图标在看的，为此所以我就必须将让kafka的监控数据输出到我们内部的监控，并且对一些特定的metric设置报警，这样就可以对kafka内部的一些状态进行监控，也能更加快的发现问题。</p>
<h4 id="1-安装一个稳定版本的jmxtrans"><a href="#1-安装一个稳定版本的jmxtrans" class="headerlink" title="1. 安装一个稳定版本的jmxtrans"></a>1. 安装一个稳定版本的jmxtrans</h4><p>jmxtrans提供了rpm包，你可以直接通过如下命令来安装；</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">rpm -ivh jmxtrans-260.rpm</div></pre></td></tr></table></figure>
<p>安装完之后，jmxtrans会在几个目录存放对应的配置文件、日志、pid等，对此我也是很纠结，就不能想其他的程序一样放的正规一点吗，几个目录还不在一起;</p>
<ul>
<li>/var/log/jmxtrans/jmxtrans.log: jmxtrans运行的日志</li>
<li>/var/run/jmxtrans/jmxtrans.pid: 存放jmxtrans对应的pid</li>
<li>/usr/shared/jmxtrans/:这个目录下面存放的jmxtrans的库文件、可执行文件、一些jmx的配置</li>
<li>/var/lib/jmxtrans/:这个目录下面存放的需要采集的配置文件，通常是json;</li>
</ul>
<h4 id="2-下载对应版本的jmxtrans"><a href="#2-下载对应版本的jmxtrans" class="headerlink" title="2. 下载对应版本的jmxtrans"></a>2. 下载对应版本的jmxtrans</h4><p>我使用的260版本的jmxtrans，于是我从它们的github网址下载了源码:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">wget https://github.com/jmxtrans/jmxtrans/archive/jmxtrans-parent-260.tar.gz</div></pre></td></tr></table></figure>
<p>然后用intellij打开对应的工程;</p>
<h4 id="3-添加自己的outputwriter"><a href="#3-添加自己的outputwriter" class="headerlink" title="3. 添加自己的outputwriter"></a>3. 添加自己的outputwriter</h4><p>这个部分我就大概说一下，具体可以看<code>jmxtrans-output-log4j中KeyOutWriter</code>这个类，因为很简单，很快就模拟然后进行自己的改造;</p>
<ul>
<li>创建自己的outputwriter模块，比如我就自己在jmxtrans-output创建了一个<code>jmxtrans-output-sentry</code>模块，pom.xml只需要将对应的依赖加上的，记得一定会依赖如下几个依赖:</li>
</ul>
<pre><code>&lt;dependency&gt;
   &lt;groupId&gt;org.jmxtrans&lt;/groupId&gt;
   &lt;artifactId&gt;jmxtrans-core&lt;/artifactId&gt;
&lt;/dependency&gt;

&lt;dependency&gt;
   &lt;groupId&gt;org.jmxtrans&lt;/groupId&gt;
   &lt;artifactId&gt;jmxtrans-utils&lt;/artifactId&gt;
&lt;/dependency&gt; 
&lt;dependency&gt;
   &lt;groupId&gt;org.jmxtrans&lt;/groupId&gt;
   &lt;artifactId&gt;jmxtrans-test-utils&lt;/artifactId&gt;
   &lt;scope&gt;test&lt;/scope&gt;
&lt;/dependency&gt;
</code></pre><ul>
<li><p>创建你自己的outputwriter类，并且继承<code>BaseOutputWriter</code>;下面的代码中我把公司内部的代码给去掉了，但是其实是一个很简单的输出端，不影响整个过程，下面的循环就对应的后面配置中的每一次你需要的查询；代码中的<code>metric</code> 和 <code>value</code>就是对应的key和value;</p>
  <figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div></pre></td><td class="code"><pre><div class="line">	public class SentryOutWriter extends BaseOutputWriter &#123;</div><div class="line">    private static Logger logger = LoggerFactory.getLogger(SentryOutWriter.class);</div><div class="line">    private Map&lt;String, String&gt; fixTags = new HashMap&lt;&gt;();</div><div class="line">    private String clustername;</div><div class="line"></div><div class="line">    @JsonCreator</div><div class="line">    public SentryOutWriter(@JsonProperty(&quot;typeNames&quot;) ImmutableList&lt;String&gt; typeNames,</div><div class="line">                           @JsonProperty(&quot;booleanAsNumber&quot;) boolean booleanAsNumber,</div><div class="line">                           @JsonProperty(&quot;debug&quot;) Boolean debugEnabled,</div><div class="line">                           @JsonProperty(&quot;settings&quot;) Map&lt;String, Object&gt; settings,</div><div class="line">                           @JsonProperty(&quot;clustername&quot;) String clustername) &#123;</div><div class="line">        super(typeNames, booleanAsNumber, debugEnabled, settings);</div><div class="line">        logger.info(&quot;SentryOutWriter is init&quot;);</div><div class="line"></div><div class="line">        this.clustername = clustername;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    @Override</div><div class="line">    public void validateSetup(Server server, Query query) throws ValidationException &#123;&#125;</div><div class="line"></div><div class="line">    @Override</div><div class="line">    protected void internalWrite(Server server, Query query, ImmutableList&lt;Result&gt; results) throws Exception &#123;</div><div class="line">        List&lt;String&gt; typeNames = getTypeNames();</div><div class="line">        long now = System.currentTimeMillis()/1000;</div><div class="line">        for (Result result : results) &#123;</div><div class="line">            Map&lt;String, Object&gt; resultValues = result.getValues();</div><div class="line">            for (Map.Entry&lt;String, Object&gt; values : resultValues.entrySet()) &#123;</div><div class="line">                if (isNumeric(values.getValue())) &#123;</div><div class="line">                    String mbeanAlias = Util.getMBeanIdentifier(query, result);</div><div class="line">                    String key = Util.getKeyString(query, result, values);</div><div class="line"></div><div class="line">                    if(Strings.isNullOrEmpty(mbeanAlias) || Strings.isNullOrEmpty(key))&#123;</div><div class="line">                        continue;</div><div class="line">                    &#125;</div><div class="line"></div><div class="line">                    String metric = mbeanAlias + &quot;.&quot; + key;</div><div class="line">                    Double value = null;</div><div class="line">                   </div><div class="line">                    if(values.getValue() instanceof Double)&#123;</div><div class="line">                          value = (Double) values.getValue();</div><div class="line">                    &#125;else if(values.getValue() instanceof Long)&#123;</div><div class="line">                        value = Double.valueof((Long) values.getValue());</div><div class="line">                    &#125;else if(values.getValue() instanceof Integer) &#123;</div><div class="line">                        value = Long.valueOf((Integer)values.getValue());</div><div class="line">                    &#125; else if(values.getValue() instanceof String)&#123;</div><div class="line">                        value = Double.valueOf((String)values.getValue());</div><div class="line">                    &#125;else&#123;</div><div class="line">                        try&#123;</div><div class="line">                            value =  Double.valueOf((Double)values.getValue());</div><div class="line">                        &#125;catch (Exception e)&#123;</div><div class="line">                            logger.error(&quot;to double is error,&#123;&#125;&quot;, e);</div><div class="line">                        &#125;</div><div class="line">                    &#125;</div><div class="line">                    logger.error(&quot;metrci:&#123;&#125;&quot;, metric);</div><div class="line">                &#125;</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
</li>
</ul>
<ul>
<li>将你自己的模块打包</li>
</ul>
<h4 id="4-将你的包导入的之前已经安装完的稳定版本中"><a href="#4-将你的包导入的之前已经安装完的稳定版本中" class="headerlink" title="4. 将你的包导入的之前已经安装完的稳定版本中"></a>4. 将你的包导入的之前已经安装完的稳定版本中</h4><p>其实jmxtrans没有提供很好的方式可以将自定义的包放到它们的stable版本中，起码我没有很好的方式；但是在模仿其他包的时候我还是发现了一些可行的方式来导入自己的包；</p>
<ol>
<li><p>确定你的jar依赖的其他的jar包；</p>
<p> 因为你自定义的jar可能还依赖出jmxtrans本身的其他的jar，所以你实现应该确定好有哪些jar包需要额外依赖；比如我就额外的包就是我司内部的监控client jar包;</p>
</li>
<li><p>将你的包上传到jmxtrans的服务端</p>
<ul>
<li>/usr/shared/jmxtrans/lib/这目录下面就是用来存放对应的jar包的,其中<code>/usr/share/jmxtrans/lib/org/jmxtrans</code>就是用来存放对应输出端的jar，所以你要把你自定的jar包放在这里;比如我就放在<code>/usr/share/jmxtrans/lib/org/jmxtrans/jmxtrans-output-sentry/260/</code>下面，jar包名字叫做<code>jmxtrans-output-sentry-260.jar</code></li>
<li>上传额外依赖包，按照标准的方式存放即可，lib目录下面有很多的例子可以模仿</li>
</ul>
</li>
<li><p>修改wrapper.conf文件</p>
<p> <code>/usr/share/jmxtrans/etc/wrapper.conf</code>是jmxtrans的启动配置文件，里面包含了启动需要加载那些包，所以需要添加jar的依赖;</p>
</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">wrapper.java.classpath.89=%REPO_DIR%/org/slf4j/slf4j-log4j12/1.7.21/slf4j-log4j12-1.7.21.jar</div><div class="line">wrapper.java.classpath.90=%REPO_DIR%/org/jmxtrans/jmxtrans-output-sentry/260/jmxtrans-output-sentry-260.jar</div><div class="line">wrapper.java.classpath.91=%REPO_DIR%/com/xxxx/xxxx/xxx.jar</div></pre></td></tr></table></figure>
<ol>
<li><p>去修改<code>/var/lib/jmxtrans/kafka.json</code>修改outputwriter的类型</p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div><div class="line">127</div><div class="line">128</div><div class="line">129</div><div class="line">130</div><div class="line">131</div><div class="line">132</div><div class="line">133</div><div class="line">134</div><div class="line">135</div><div class="line">136</div><div class="line">137</div><div class="line">138</div><div class="line">139</div><div class="line">140</div><div class="line">141</div><div class="line">142</div><div class="line">143</div><div class="line">144</div><div class="line">145</div><div class="line">146</div><div class="line">147</div><div class="line">148</div><div class="line">149</div><div class="line">150</div><div class="line">151</div><div class="line">152</div><div class="line">153</div><div class="line">154</div><div class="line">155</div><div class="line">156</div><div class="line">157</div><div class="line">158</div><div class="line">159</div><div class="line">160</div><div class="line">161</div><div class="line">162</div><div class="line">163</div><div class="line">164</div><div class="line">165</div><div class="line">166</div><div class="line">167</div><div class="line">168</div><div class="line">169</div><div class="line">170</div><div class="line">171</div><div class="line">172</div><div class="line">173</div><div class="line">174</div><div class="line">175</div><div class="line">176</div><div class="line">177</div><div class="line">178</div><div class="line">179</div><div class="line">180</div><div class="line">181</div><div class="line">182</div><div class="line">183</div><div class="line">184</div><div class="line">185</div><div class="line">186</div><div class="line">187</div><div class="line">188</div><div class="line">189</div><div class="line">190</div><div class="line">191</div><div class="line">192</div><div class="line">193</div><div class="line">194</div><div class="line">195</div><div class="line">196</div><div class="line">197</div><div class="line">198</div><div class="line">199</div><div class="line">200</div><div class="line">201</div><div class="line">202</div><div class="line">203</div><div class="line">204</div><div class="line">205</div><div class="line">206</div><div class="line">207</div><div class="line">208</div><div class="line">209</div><div class="line">210</div><div class="line">211</div><div class="line">212</div><div class="line">213</div><div class="line">214</div><div class="line">215</div><div class="line">216</div><div class="line">217</div><div class="line">218</div><div class="line">219</div><div class="line">220</div><div class="line">221</div><div class="line">222</div><div class="line">223</div><div class="line">224</div><div class="line">225</div><div class="line">226</div><div class="line">227</div><div class="line">228</div><div class="line">229</div><div class="line">230</div><div class="line">231</div><div class="line">232</div><div class="line">233</div><div class="line">234</div><div class="line">235</div><div class="line">236</div><div class="line">237</div><div class="line">238</div><div class="line">239</div><div class="line">240</div><div class="line">241</div><div class="line">242</div><div class="line">243</div><div class="line">244</div><div class="line">245</div><div class="line">246</div><div class="line">247</div><div class="line">248</div><div class="line">249</div><div class="line">250</div><div class="line">251</div><div class="line">252</div><div class="line">253</div><div class="line">254</div><div class="line">255</div><div class="line">256</div><div class="line">257</div><div class="line">258</div><div class="line">259</div><div class="line">260</div><div class="line">261</div><div class="line">262</div><div class="line">263</div><div class="line">264</div><div class="line">265</div><div class="line">266</div><div class="line">267</div><div class="line">268</div><div class="line">269</div><div class="line">270</div><div class="line">271</div><div class="line">272</div><div class="line">273</div><div class="line">274</div><div class="line">275</div><div class="line">276</div><div class="line">277</div><div class="line">278</div><div class="line">279</div><div class="line">280</div><div class="line">281</div><div class="line">282</div><div class="line">283</div><div class="line">284</div><div class="line">285</div><div class="line">286</div><div class="line">287</div><div class="line">288</div><div class="line">289</div><div class="line">290</div><div class="line">291</div><div class="line">292</div><div class="line">293</div><div class="line">294</div><div class="line">295</div><div class="line">296</div><div class="line">297</div><div class="line">298</div><div class="line">299</div><div class="line">300</div><div class="line">301</div><div class="line">302</div><div class="line">303</div><div class="line">304</div><div class="line">305</div><div class="line">306</div><div class="line">307</div><div class="line">308</div><div class="line">309</div><div class="line">310</div><div class="line">311</div><div class="line">312</div><div class="line">313</div><div class="line">314</div><div class="line">315</div><div class="line">316</div><div class="line">317</div><div class="line">318</div><div class="line">319</div><div class="line">320</div><div class="line">321</div><div class="line">322</div><div class="line">323</div><div class="line">324</div><div class="line">325</div><div class="line">326</div><div class="line">327</div><div class="line">328</div><div class="line">329</div><div class="line">330</div><div class="line">331</div><div class="line">332</div><div class="line">333</div><div class="line">334</div><div class="line">335</div></pre></td><td class="code"><pre><div class="line">	&#123;</div><div class="line">  &quot;servers&quot;: [</div><div class="line">    &#123;</div><div class="line">      &quot;port&quot;: &quot;your sever jmx port&quot;,</div><div class="line">      &quot;host&quot;: &quot;your server ip&quot;,</div><div class="line">      &quot;queries&quot;: [</div><div class="line">        &#123;</div><div class="line">          &quot;outputWriters&quot;: [</div><div class="line">            &#123;</div><div class="line">              &quot;@class&quot;: &quot;com.googlecode.jmxtrans.model.output.SentryOutWriter&quot;,</div><div class="line">              &quot;clustername&quot;: &quot;offline-kafka&quot;</div><div class="line">            &#125;</div><div class="line">          ],</div><div class="line">          &quot;obj&quot;: &quot;java.lang:type=Memory&quot;,</div><div class="line">          &quot;resultAlias&quot;: &quot;memory&quot;,</div><div class="line">          &quot;attr&quot;: [</div><div class="line">            &quot;HeapMemoryUsage&quot;</div><div class="line">          ]</div><div class="line">        &#125;,</div><div class="line">        &#123;</div><div class="line">          &quot;outputWriters&quot;: [</div><div class="line">            &#123;</div><div class="line">              &quot;@class&quot;: &quot;com.googlecode.jmxtrans.model.output.SentryOutWriter&quot;,</div><div class="line">              &quot;clustername&quot;: &quot;offline-kafka&quot;</div><div class="line">            &#125;</div><div class="line">          ],</div><div class="line">          &quot;obj&quot;: &quot;java.lang:type=GarbageCollector,name=G1 Old Generation&quot;,</div><div class="line">          &quot;resultAlias&quot;: &quot;FullGC&quot;,</div><div class="line">          &quot;attr&quot;: [</div><div class="line">            &quot;CollectionCount&quot;,</div><div class="line">            &quot;CollectionTime&quot;</div><div class="line">          ]</div><div class="line">        &#125;,</div><div class="line"></div><div class="line">        &#123;</div><div class="line">          &quot;outputWriters&quot;: [</div><div class="line">            &#123;</div><div class="line">              &quot;@class&quot;: &quot;com.googlecode.jmxtrans.model.output.SentryOutWriter&quot;,</div><div class="line">              &quot;clustername&quot;: &quot;offline-kafka&quot;</div><div class="line">            &#125;</div><div class="line">          ],</div><div class="line">          &quot;obj&quot;: &quot;kafka.server:type=BrokerTopicMetrics,name=MessagesInPerSec&quot;,</div><div class="line">          &quot;resultAlias&quot;: &quot;MessagesIn&quot;,</div><div class="line">          &quot;attr&quot;: [</div><div class="line">            &quot;OneMinuteRate&quot;</div><div class="line">          ]</div><div class="line">        &#125;,</div><div class="line">        &#123;</div><div class="line">          &quot;outputWriters&quot;: [</div><div class="line">            &#123;</div><div class="line">              &quot;@class&quot;: &quot;com.googlecode.jmxtrans.model.output.SentryOutWriter&quot;,</div><div class="line">              &quot;clustername&quot;: &quot;offline-kafka&quot;</div><div class="line">            &#125;</div><div class="line">          ],</div><div class="line">          &quot;obj&quot;: &quot;kafka.server:type=BrokerTopicMetrics,name=BytesInPerSec&quot;,</div><div class="line">          &quot;resultAlias&quot;: &quot;BytesIn&quot;,</div><div class="line">          &quot;attr&quot;: [</div><div class="line">            &quot;OneMinuteRate&quot;</div><div class="line">          ]</div><div class="line">        &#125;,</div><div class="line">        &#123;</div><div class="line">          &quot;outputWriters&quot;: [</div><div class="line">            &#123;</div><div class="line">              &quot;@class&quot;: &quot;com.googlecode.jmxtrans.model.output.SentryOutWriter&quot;,</div><div class="line">              &quot;clustername&quot;: &quot;offline-kafka&quot;</div><div class="line">            &#125;</div><div class="line">          ],</div><div class="line">          &quot;obj&quot;: &quot;kafka.server:type=BrokerTopicMetrics,name=BytesOutPerSec&quot;,</div><div class="line">          &quot;resultAlias&quot;: &quot;BytesOut&quot;,</div><div class="line">          &quot;attr&quot;: [</div><div class="line">            &quot;OneMinuteRate&quot;</div><div class="line">          ]</div><div class="line">        &#125;,</div><div class="line"></div><div class="line">        &#123;</div><div class="line">          &quot;outputWriters&quot;: [</div><div class="line">            &#123;</div><div class="line">              &quot;@class&quot;: &quot;com.googlecode.jmxtrans.model.output.SentryOutWriter&quot;,</div><div class="line">              &quot;clustername&quot;: &quot;offline-kafka&quot;</div><div class="line">            &#125;</div><div class="line">          ],</div><div class="line">          &quot;obj&quot;: &quot;kafka.network:type=RequestMetrics,name=RequestsPerSec,request=Produce&quot;,</div><div class="line">          &quot;resultAlias&quot;: &quot;ProduceRequests&quot;,</div><div class="line">          &quot;attr&quot;: [</div><div class="line">            &quot;OneMinuteRate&quot;</div><div class="line">          ]</div><div class="line">        &#125;,</div><div class="line"></div><div class="line">        &#123;</div><div class="line">          &quot;outputWriters&quot;: [</div><div class="line">            &#123;</div><div class="line">              &quot;@class&quot;: &quot;com.googlecode.jmxtrans.model.output.SentryOutWriter&quot;,</div><div class="line">              &quot;clustername&quot;: &quot;offline-kafka&quot;</div><div class="line">            &#125;</div><div class="line">          ],</div><div class="line">          &quot;obj&quot;: &quot;kafka.network:type=RequestMetrics,name=RequestsPerSec,request=FetchConsumer&quot;,</div><div class="line">          &quot;resultAlias&quot;: &quot;FetchConsumerRequests&quot;,</div><div class="line">          &quot;attr&quot;: [</div><div class="line">            &quot;OneMinuteRate&quot;</div><div class="line">          ]</div><div class="line">        &#125;,</div><div class="line"></div><div class="line">        &#123;</div><div class="line">          &quot;outputWriters&quot;: [</div><div class="line">            &#123;</div><div class="line">              &quot;@class&quot;: &quot;com.googlecode.jmxtrans.model.output.SentryOutWriter&quot;,</div><div class="line">              &quot;clustername&quot;: &quot;offline-kafka&quot;</div><div class="line">            &#125;</div><div class="line">          ],</div><div class="line">          &quot;obj&quot;: &quot;kafka.network:type=RequestMetrics,name=RequestsPerSec,request=FetchFollower&quot;,</div><div class="line">          &quot;resultAlias&quot;: &quot;FetchFollowerRequests&quot;,</div><div class="line">          &quot;attr&quot;: [</div><div class="line">            &quot;OneMinuteRate&quot;</div><div class="line">          ]</div><div class="line">        &#125;,</div><div class="line"></div><div class="line">        &#123;</div><div class="line">          &quot;outputWriters&quot;: [</div><div class="line">            &#123;</div><div class="line">              &quot;@class&quot;: &quot;com.googlecode.jmxtrans.model.output.SentryOutWriter&quot;,</div><div class="line">              &quot;clustername&quot;: &quot;offline-kafka&quot;</div><div class="line"></div><div class="line">            &#125;</div><div class="line">          ],</div><div class="line">          &quot;obj&quot;: &quot;kafka.log:type=LogFlushStats,name=LogFlushRateAndTimeMs&quot;,</div><div class="line">          &quot;resultAlias&quot;: &quot;LogflushRateAndTime&quot;,</div><div class="line">          &quot;attr&quot;: [</div><div class="line">            &quot;OneMinuteRate&quot;,</div><div class="line">            &quot;999thPercentile&quot;</div><div class="line">          ]</div><div class="line">        &#125;,</div><div class="line"></div><div class="line">        &#123;</div><div class="line">          &quot;outputWriters&quot;: [</div><div class="line">            &#123;</div><div class="line">              &quot;@class&quot;: &quot;com.googlecode.jmxtrans.model.output.SentryOutWriter&quot;,</div><div class="line">              &quot;clustername&quot;: &quot;offline-kafka&quot;</div><div class="line"></div><div class="line">            &#125;</div><div class="line">          ],</div><div class="line">          &quot;obj&quot;: &quot;kafka.log:type=ReplicaManager,name=UnderReplicatedPartitions&quot;,</div><div class="line">          &quot;resultAlias&quot;: &quot;UnISRPartitionCnt&quot;,</div><div class="line">          &quot;attr&quot;: [</div><div class="line">            &quot;Value&quot;</div><div class="line">          ]</div><div class="line">        &#125;,</div><div class="line"></div><div class="line">        &#123;</div><div class="line">          &quot;outputWriters&quot;: [</div><div class="line">            &#123;</div><div class="line">              &quot;@class&quot;: &quot;com.googlecode.jmxtrans.model.output.SentryOutWriter&quot;,</div><div class="line">              &quot;clustername&quot;: &quot;offline-kafka&quot;</div><div class="line"></div><div class="line">            &#125;</div><div class="line">          ],</div><div class="line">          &quot;obj&quot;: &quot;kafka.controller:type=KafkaController,name=ActiveControllerCount&quot;,</div><div class="line">          &quot;resultAlias&quot;: &quot;ActiveControllerCnt&quot;,</div><div class="line">          &quot;attr&quot;: [</div><div class="line">            &quot;Value&quot;</div><div class="line">          ]</div><div class="line">        &#125;,</div><div class="line"></div><div class="line">        &#123;</div><div class="line">          &quot;outputWriters&quot;: [</div><div class="line">            &#123;</div><div class="line">              &quot;@class&quot;: &quot;com.googlecode.jmxtrans.model.output.SentryOutWriter&quot;,</div><div class="line">              &quot;clustername&quot;: &quot;offline-kafka&quot;</div><div class="line">            &#125;</div><div class="line">          ],</div><div class="line">          &quot;obj&quot;: &quot;kafka.controller:type=ControllerStats,name=LeaderElectionRateAndTimeMs&quot;,</div><div class="line">          &quot;resultAlias&quot;: &quot;LeaderRateAndTime&quot;,</div><div class="line">          &quot;attr&quot;: [</div><div class="line">            &quot;999thPercentile&quot;,</div><div class="line">            &quot;OneMinuteRate&quot;</div><div class="line">          ]</div><div class="line">        &#125;,</div><div class="line"></div><div class="line">        &#123;</div><div class="line">          &quot;outputWriters&quot;: [</div><div class="line">            &#123;</div><div class="line">              &quot;@class&quot;: &quot;com.googlecode.jmxtrans.model.output.SentryOutWriter&quot;,</div><div class="line">              &quot;clustername&quot;: &quot;offline-kafka&quot;</div><div class="line">            &#125;</div><div class="line">          ],</div><div class="line">          &quot;obj&quot;: &quot;kafka.controller:type=ControllerStats,name=UncleanLeaderElectionsPerSec&quot;,</div><div class="line">          &quot;resultAlias&quot;: &quot;UncleanLeaderRateAndTime&quot;,</div><div class="line">          &quot;attr&quot;: [</div><div class="line">            &quot;999thPercentile&quot;,</div><div class="line">            &quot;OneMinuteRate&quot;</div><div class="line">          ]</div><div class="line">        &#125;,</div><div class="line"></div><div class="line">        &#123;</div><div class="line">          &quot;outputWriters&quot;: [</div><div class="line">            &#123;</div><div class="line">              &quot;@class&quot;: &quot;com.googlecode.jmxtrans.model.output.SentryOutWriter&quot;,</div><div class="line">              &quot;clustername&quot;: &quot;offline-kafka&quot;</div><div class="line">            &#125;</div><div class="line">          ],</div><div class="line">          &quot;obj&quot;: &quot;kafka.server:type=ReplicaManager,name=PartitionCount&quot;,</div><div class="line">          &quot;resultAlias&quot;: &quot;PartitionCnt&quot;,</div><div class="line">          &quot;attr&quot;: [</div><div class="line">            &quot;Value&quot;</div><div class="line">          ]</div><div class="line">        &#125;,</div><div class="line"></div><div class="line">        &#123;</div><div class="line">          &quot;outputWriters&quot;: [</div><div class="line">            &#123;</div><div class="line">              &quot;@class&quot;: &quot;com.googlecode.jmxtrans.model.output.SentryOutWriter&quot;,</div><div class="line">              &quot;clustername&quot;: &quot;offline-kafka&quot;</div><div class="line">            &#125;</div><div class="line">          ],</div><div class="line">          &quot;obj&quot;: &quot;kafka.server:type=ReplicaManager,name=LeaderCount&quot;,</div><div class="line">          &quot;resultAlias&quot;: &quot;LeaderCnt&quot;,</div><div class="line">          &quot;attr&quot;: [</div><div class="line">            &quot;Value&quot;</div><div class="line">          ]</div><div class="line">        &#125;,</div><div class="line"></div><div class="line">        &#123;</div><div class="line">          &quot;outputWriters&quot;: [</div><div class="line">            &#123;</div><div class="line">              &quot;@class&quot;: &quot;com.googlecode.jmxtrans.model.output.SentryOutWriter&quot;,</div><div class="line">              &quot;clustername&quot;: &quot;offline-kafka&quot;</div><div class="line">            &#125;</div><div class="line">          ],</div><div class="line">          &quot;obj&quot;: &quot;kafka.server:type=DelayedOperationPurgatory,name=PurgatorySize,delayedOperation=Produce&quot;,</div><div class="line">          &quot;resultAlias&quot;: &quot;ProducerPurgatorySize&quot;,</div><div class="line">          &quot;attr&quot;: [</div><div class="line">            &quot;Value&quot;</div><div class="line">          ]</div><div class="line">        &#125;,</div><div class="line"></div><div class="line">        &#123;</div><div class="line">          &quot;outputWriters&quot;: [</div><div class="line">            &#123;</div><div class="line">              &quot;@class&quot;: &quot;com.googlecode.jmxtrans.model.output.SentryOutWriter&quot;,</div><div class="line">              &quot;clustername&quot;: &quot;offline-kafka&quot;</div><div class="line">            &#125;</div><div class="line">          ],</div><div class="line">          &quot;obj&quot;: &quot;kafka.server:type=DelayedOperationPurgatory,name=PurgatorySize,delayedOperation=Fetch&quot;,</div><div class="line">          &quot;resultAlias&quot;: &quot;FetchPurgatorySize&quot;,</div><div class="line">          &quot;attr&quot;: [</div><div class="line">            &quot;Value&quot;</div><div class="line">          ]</div><div class="line">        &#125;,</div><div class="line"></div><div class="line">        &#123;</div><div class="line">          &quot;outputWriters&quot;: [</div><div class="line">            &#123;</div><div class="line">              &quot;@class&quot;: &quot;com.googlecode.jmxtrans.model.output.SentryOutWriter&quot;,</div><div class="line">              &quot;clustername&quot;: &quot;offline-kafka&quot;</div><div class="line">            &#125;</div><div class="line">          ],</div><div class="line">          &quot;obj&quot;: &quot;kafka.network:type=RequestMetrics,name=RequestQueueTimeMs,request=FetchConsumer&quot;,</div><div class="line">          &quot;resultAlias&quot;: &quot;FetchConsumerWait&quot;,</div><div class="line">          &quot;attr&quot;: [</div><div class="line">            &quot;999thPercentile&quot;</div><div class="line">          ]</div><div class="line">        &#125;,</div><div class="line"></div><div class="line">        &#123;</div><div class="line">          &quot;outputWriters&quot;: [</div><div class="line">            &#123;</div><div class="line">              &quot;@class&quot;: &quot;com.googlecode.jmxtrans.model.output.SentryOutWriter&quot;,</div><div class="line">              &quot;clustername&quot;: &quot;offline-kafka&quot;</div><div class="line">            &#125;</div><div class="line">          ],</div><div class="line">          &quot;obj&quot;: &quot;kafka.network:type=RequestMetrics,name=RequestQueueTimeMs,request=Produce&quot;,</div><div class="line">          &quot;resultAlias&quot;: &quot;ProduceWait&quot;,</div><div class="line">          &quot;attr&quot;: [</div><div class="line">            &quot;999thPercentile&quot;</div><div class="line">          ]</div><div class="line">        &#125;,</div><div class="line"></div><div class="line">        &#123;</div><div class="line">          &quot;outputWriters&quot;: [</div><div class="line">            &#123;</div><div class="line">              &quot;@class&quot;: &quot;com.googlecode.jmxtrans.model.output.SentryOutWriter&quot;,</div><div class="line">              &quot;clustername&quot;: &quot;offline-kafka&quot;</div><div class="line">            &#125;</div><div class="line">          ],</div><div class="line">          &quot;obj&quot;: &quot;kafka.network:type=RequestMetrics,name=LocalTimeMs,request=FetchConsumer&quot;,</div><div class="line">          &quot;resultAlias&quot;: &quot;FetchConsumerProcessTime&quot;,</div><div class="line">          &quot;attr&quot;: [</div><div class="line">            &quot;999thPercentile&quot;</div><div class="line">          ]</div><div class="line">        &#125;,</div><div class="line"></div><div class="line">        &#123;</div><div class="line">          &quot;outputWriters&quot;: [</div><div class="line">            &#123;</div><div class="line">              &quot;@class&quot;: &quot;com.googlecode.jmxtrans.model.output.SentryOutWriter&quot;,</div><div class="line">              &quot;clustername&quot;: &quot;offline-kafka&quot;</div><div class="line">            &#125;</div><div class="line">          ],</div><div class="line">          &quot;obj&quot;: &quot;kafka.network:type=RequestMetrics,name=LocalTimeMs,request=Produce&quot;,</div><div class="line">          &quot;resultAlias&quot;: &quot;ProduceProcessTime&quot;,</div><div class="line">          &quot;attr&quot;: [</div><div class="line">            &quot;999thPercentile&quot;</div><div class="line">          ]</div><div class="line">        &#125;,</div><div class="line"></div><div class="line">        &#123;</div><div class="line">          &quot;outputWriters&quot;: [</div><div class="line">            &#123;</div><div class="line">              &quot;@class&quot;: &quot;com.googlecode.jmxtrans.model.output.SentryOutWriter&quot;,</div><div class="line">              &quot;clustername&quot;: &quot;offline-kafka&quot;</div><div class="line">            &#125;</div><div class="line">          ],</div><div class="line">          &quot;obj&quot;: &quot;kafka.server:type=SessionExpireListener,name=ZooKeeperDisconnectsPerSec&quot;,</div><div class="line">          &quot;resultAlias&quot;: &quot;ZKDisConnectCnt&quot;,</div><div class="line">          &quot;attr&quot;: [</div><div class="line">            &quot;OneMinuteRate&quot;</div><div class="line">          ]</div><div class="line">        &#125;,</div><div class="line">        &#123;</div><div class="line">          &quot;outputWriters&quot;: [</div><div class="line">            &#123;</div><div class="line">              &quot;@class&quot;: &quot;com.googlecode.jmxtrans.model.output.SentryOutWriter&quot;,</div><div class="line">              &quot;clustername&quot;: &quot;offline-kafka&quot;</div><div class="line">            &#125;</div><div class="line">          ],</div><div class="line">          &quot;obj&quot;: &quot;kafka.server:type=SessionExpireListener,name=ZooKeeperExpiredPerSec&quot;,</div><div class="line">          &quot;resultAlias&quot;: &quot;ZKExpiredCnt&quot;,</div><div class="line">          &quot;attr&quot;: [</div><div class="line">            &quot;OneMinuteRate&quot;</div><div class="line">          ]</div><div class="line">        &#125;</div><div class="line">      ],</div><div class="line">      &quot;numQueryThreads&quot;: 1</div><div class="line">    &#125;</div><div class="line">  ]</div><div class="line">&#125;</div></pre></td></tr></table></figure>
</li>
</ol>
<h4 id="5-总结"><a href="#5-总结" class="headerlink" title="5. 总结"></a>5. 总结</h4><p>这样就可以把数据输出到我自己的监控;关于kafka的监控信息可以看<a href="http://andrewrong.github.io/2017/03/26/kafka-broker%E7%9A%84%E7%9B%91%E6%8E%A7%E4%BF%A1%E6%81%AF/" target="_blank" rel="external">这篇文章</a>，有什么问题可以通过<a href="https://twitter.com/andrew_rong" target="_blank" rel="external">twitter</a>私信给我;</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;https://github.com/jmxtrans/jmxtrans&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;jmxtrans&lt;/a&gt;是一个开源产品，主要的作用是通过定时轮训程序的jmx端口来获得程序内部的信息，并且输出到对应的
    
    </summary>
    
    
      <category term="jmxtrans,kafka" scheme="http://yoursite.com/tags/jmxtrans-kafka/"/>
    
  </entry>
  
  <entry>
    <title>kafka broker的监控信息</title>
    <link href="http://yoursite.com/2017/03/26/kafka-broker%E7%9A%84%E7%9B%91%E6%8E%A7%E4%BF%A1%E6%81%AF/"/>
    <id>http://yoursite.com/2017/03/26/kafka-broker的监控信息/</id>
    <published>2017-03-26T13:35:09.000Z</published>
    <updated>2017-03-27T06:34:39.000Z</updated>
    
    <content type="html"><![CDATA[<h3 id="1-broker的监控信息"><a href="#1-broker的监控信息" class="headerlink" title="1. broker的监控信息"></a>1. broker的监控信息</h3><table>
<thead>
<tr>
<th>标题</th>
<th>mbean name</th>
<th>解释</th>
</tr>
</thead>
<tbody>
<tr>
<td>Message in rate</td>
<td><code>kafka.server:type=BrokerTopicMetrics,name=MessagesInPerSec</code></td>
<td>当前broker每秒的消息个数</td>
</tr>
<tr>
<td>Byte in rate</td>
<td><code>kafka.server:type=BrokerTopicMetrics,name=BytesInPerSec</code></td>
<td>当前broker的每秒的入口流量</td>
</tr>
<tr>
<td>Byte out rate</td>
<td><code>kafka.server:type=BrokerTopicMetrics,name=BytesOutPerSec</code></td>
<td>当前broker的每秒的出口流量</td>
</tr>
<tr>
<td>Request rate</td>
<td><code>kafka.network:type=RequestMetrics,name=RequestsPerSec,request={Produce or FetchConsumer or FetchFollower}</code></td>
<td>当前broker的每秒的请求量; 根据request的不同会返回不同类型的数据</td>
</tr>
<tr>
<td>Log flush rate and time</td>
<td><code>kafka.log:type=LogFlushStats,name=LogFlushRateAndTimeMs</code></td>
<td>日志刷盘的频率和时间；其中<em>OneMinuteRate:表示一分钟内每秒钟的刷盘次数; </em>999thPercentile:99.9%的刷盘需要的时间</td>
</tr>
<tr>
<td>of under replicated partitions</td>
<td><code>kafka.server:type=ReplicaManager,name=UnderReplicatedPartitions</code></td>
<td>ISR &lt; 备份次数的分区个数，这样的分区应该=0，如果大于0就进行报警最好;</td>
</tr>
<tr>
<td>Is controller active on broker</td>
<td><code>kafka.controller:type=KafkaController,name=ActiveControllerCount</code></td>
<td>当前集群中controller的个数,一个集群只能有一个controller</td>
</tr>
<tr>
<td>Leader election rate</td>
<td><code>kafka.controller:type=ControllerStats,name=LeaderElectionRateAndTimeMs</code></td>
<td>leader选举的频率和需要的时间；其中<em>OneMinuteRate:表示一分钟内出现选举的次数; </em>999thPercentile:99.9%的选举需要的时间</td>
</tr>
<tr>
<td>Unclean leader election rate</td>
<td><code>kafka.controller:type=ControllerStats,name=UncleanLeaderElectionsPerSec</code></td>
<td>非正常的备份被选举成leader的频率;</td>
</tr>
<tr>
<td>Partition counts</td>
<td><code>kafka.server:type=ReplicaManager,name=PartitionCount</code></td>
<td>当前broker的分区个数,就是在存储数据的目录下面的分区个数;</td>
</tr>
<tr>
<td>Leader replica counts</td>
<td><code>kafka.server:type=ReplicaManager,name=LeaderCount</code></td>
<td>当前broker中的leader分区的个数</td>
</tr>
<tr>
<td>ISR shrink rate</td>
<td><code>kafka.server:type=ReplicaManager,name=IsrShrinksPerSec</code></td>
<td>当前broker每分钟分区缩减的频率;</td>
</tr>
<tr>
<td>ISR expansion rate</td>
<td><code>kafka.server:type=ReplicaManager,name=IsrExpandsPerSec</code></td>
<td>当前broker每分钟分区扩展的频率;</td>
</tr>
<tr>
<td>Max lag in messages btw follower and leader replicas</td>
<td><code>kafka.server:type=ReplicaFetcherManager,name=MaxLag,clientId=Replica</code></td>
<td>当前broker中分区与leader之前同步的最大lag数</td>
</tr>
<tr>
<td>Lag in messages per follower replica</td>
<td><code>kafka.server:type=FetcherLagMetrics,name=ConsumerLag,clientId=([-.\w]+),topic=([-.\w]+),partition=([0-9]+)</code></td>
<td>当前broker中备本分区与leader之间的lag数</td>
</tr>
<tr>
<td>Requests waiting in the producer purgatory</td>
<td><code>kafka.server:type=DelayedOperationPurgatory,name=PurgatorySize,delayedOperation=Produce</code></td>
<td>broker中，在等待ack的producer请求个数;还有Fetch、topic、Rebalance、Heartbeat请求</td>
</tr>
<tr>
<td>Request total time</td>
<td><code>kafka.network:type=RequestMetrics,name=TotalTimeMs,request={Produce or FetchConsumer or FetchFollower}</code></td>
<td>请求所需要的全部时间;根据不同的类型求个不一样的结果</td>
</tr>
<tr>
<td>Time the request waits in the request queue</td>
<td><code>kafka.network:type=RequestMetrics,name=RequestQueueTimeMs,request={Produce or FetchConsumer or FetchFollower}</code></td>
<td>请求在队列中等待的时间</td>
</tr>
<tr>
<td>Time the request is processed at the leader</td>
<td><code>kafka.network:type=RequestMetrics,name=LocalTimeMs,request={Produce or FetchConsumer or FetchFollower}</code></td>
<td>请求被leader节点处理的时间</td>
</tr>
<tr>
<td>Time the request waits for the follower</td>
<td><code>kafka.network:type=RequestMetrics,name=RemoteTimeMs,request={Produce or FetchConsumer or FetchFollower}</code></td>
<td>一个请求等待follower的时间;假如ack=all，那么这个值就是非0</td>
</tr>
<tr>
<td>Time the request waits in the response queue</td>
<td><code>kafka.network:type=RequestMetrics,name=ResponseQueueTimeMs,request={Produce or FetchConsumer or FetchFollower}</code></td>
<td>一个请求在response队列中的时间</td>
</tr>
<tr>
<td>Time to send the response</td>
<td><code>kafka.network:type=RequestMetrics,name=ResponseSendTimeMs,request={Produce or FetchConsumer or FetchFollower}</code></td>
<td>发送请求的时间</td>
</tr>
<tr>
<td>Number of messages the consumer lags behind the producer by. Published by the consumer, not broker.</td>
<td><code>Old consumer: kafka.consumer:type=ConsumerFetcherManager,name=MaxLag,clientId=([-.\w]+) New consumer: kafka.consumer:type=consumer-fetch-manager-metrics,client-id={client-id} Attribute: records-lag-max</code></td>
<td>consumer落后producer的lag</td>
</tr>
<tr>
<td>The average fraction of time the network processors are idle</td>
<td><code>kafka.network:type=SocketServer,name=NetworkProcessorAvgIdlePercent</code></td>
<td>网络处理空闲的因子，在0，1之间，通常是&gt; 0.3</td>
</tr>
<tr>
<td>The average fraction of time the request handler threads are idle</td>
<td><code>kafka.server:type=KafkaRequestHandlerPool,name=RequestHandlerAvgIdlePercent</code></td>
<td>网络请求线程空闲的平均值，在0，1之间，通常是&gt; 0.3</td>
</tr>
</tbody>
</table>
<h3 id="2-关于zookeeper相关的监控信息"><a href="#2-关于zookeeper相关的监控信息" class="headerlink" title="2. 关于zookeeper相关的监控信息"></a>2. 关于zookeeper相关的监控信息</h3><table>
<thead>
<tr>
<th>mbean name</th>
<th>解释</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>kafka.server:type=SessionExpireListener,name=ZooKeeperDisconnectedPerSec</code></td>
<td>当前broker与zk之间的每秒断链的次数；也就是频率</td>
</tr>
<tr>
<td><code>kafka.server:type=SessionExpireListener,name=ZooKeeperSyncConnectedPerSec</code></td>
<td>ZooKeeper client is connected to the ensemble and ready to execute operations</td>
</tr>
<tr>
<td><code>kafka.server:type=SessionExpireListener,name=ZooKeeperAuthFailedPerSec</code></td>
<td>与zk进行连接并且是因为认证失败的每秒的次数</td>
</tr>
<tr>
<td><code>kafka.server:type=SessionExpireListener,name=ZooKeeperConnectedReadOnlyPerSec</code></td>
<td>The server the client is connected to is currently LOOKING, which means that it is neither FOLLOWING nor LEADING. Consequently, the client can only read the ZooKeeper state, but not make any changes (create, delete, or set the data of znodes).</td>
</tr>
<tr>
<td><code>kafka.server:type=SessionExpireListener,name=ZooKeeperSaslAuthenticatedPerSec</code></td>
<td>zkclient被验证成功每秒的次数</td>
</tr>
<tr>
<td><code>kafka.server:type=SessionExpireListener,name=ZooKeeperExpiredPerSec</code></td>
<td>当前zkclient被过期的每秒次数</td>
</tr>
</tbody>
</table>
<h3 id="3-consumer和producer的监控信息"><a href="#3-consumer和producer的监控信息" class="headerlink" title="3. consumer和producer的监控信息"></a>3. consumer和producer的监控信息</h3><ul>
<li><a href="http://docs.confluent.io/3.0.0/kafka/monitoring.html#producer-global-request-metrics" target="_blank" rel="external">confluent doc</a></li>
<li><a href="https://kafka.apache.org/documentation/#monitoring" target="_blank" rel="external">kafka doc</a></li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;1-broker的监控信息&quot;&gt;&lt;a href=&quot;#1-broker的监控信息&quot; class=&quot;headerlink&quot; title=&quot;1. broker的监控信息&quot;&gt;&lt;/a&gt;1. broker的监控信息&lt;/h3&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;标题
    
    </summary>
    
    
      <category term="kafka,monitor" scheme="http://yoursite.com/tags/kafka-monitor/"/>
    
  </entry>
  
  <entry>
    <title>同步、异步、阻塞、非阻塞</title>
    <link href="http://yoursite.com/2017/03/03/%E5%90%8C%E6%AD%A5%E3%80%81%E5%BC%82%E6%AD%A5%E3%80%81%E9%98%BB%E5%A1%9E%E3%80%81%E9%9D%9E%E9%98%BB%E5%A1%9E/"/>
    <id>http://yoursite.com/2017/03/03/同步、异步、阻塞、非阻塞/</id>
    <published>2017-03-03T09:35:52.000Z</published>
    <updated>2017-03-05T06:21:27.000Z</updated>
    
    <content type="html"><![CDATA[<p>同步异步阻塞非阻塞这几个概念其实很早就出现在我的脑中，但是到现在为止都还是很难把它理解清楚，尤其是这几个概念总是会被混淆一起来讲。最近算是工作比较闲，在网上查询了大量的文章，发现一些人对这几个概念有着与众不同的解释，也正好能完美的解决我心中的疑云.</p>
<p>先引用几个别人对此的理解，我觉得他们理解的特别有理;</p>
<blockquote>
<pre><code>•    阻塞与非阻塞：区别在于完成一件事情时，当事情还没有完成时，处理这件事情的人除此之外不能再做别的事情；
•    同步与异步：是自己去做这件事情，还是等别人做好了来通知有结果，然后再自己去拿结果。注意这里说的是拿结果，如果只是别人告诉你可以做某事，然后自己去操作，这种情况下也是同步的操作;[link](http://h2ex.com/639)
</code></pre></blockquote>
<p>还有一个知乎上的回答，觉得<a href="https://www.zhihu.com/question/19732473" target="_blank" rel="external">严肃回答</a>的也是特别好.</p>
<h5 id="阻塞非阻塞"><a href="#阻塞非阻塞" class="headerlink" title="阻塞非阻塞"></a>阻塞非阻塞</h5><p>是程序在等待调用的时候的状态; 说大白话就是: 程序调用了某一个接口的时候，他是否还有<strong>可能</strong>去做其他的事情, 如果有可能那就是非阻塞，如果没有可能那就是阻塞; 这里举个大家都知道的例子,比如<code>read</code>(反正大家都喜欢用这个例子):</p>
<p>这有两个角色:</p>
<pre><code>* 调用者: 调用read的线程或者进程
* 被调用者: read本身
</code></pre><p>Linux文件在open的过程可以选择(block | noblock)两种方式，而这两种方式的最大区别点在于：block模式下，调用read之后会阻塞(阻塞的原因在<a href="http://blog.csdn.net/historyasamirror/article/details/5778378" target="_blank" rel="external">这篇文章</a>中有很详细的介绍), 就调用者在此时此刻它是会被操作系统挂起，它在此刻没有<strong>可能</strong>去做其他的事情, 这就是阻塞(<strong>没有可能性</strong>).</p>
<p>如果是在非阻塞的模式下，调用read之后会很快的返回, 这个返回有两种可能: error 或者 读到了数据; 虽然我们在使用非阻塞的时候，总是在外围加上while循环,类似于:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">do &#123;</div><div class="line">	read(fd, buf, count);</div><div class="line">&#125;while(errno == EWOULDBLOCK);</div></pre></td></tr></table></figure>
<p>通过这种方式去不断询问内核是否已经把数据准备好，而这个过程中，虽然大部分用法是选择不停的询问，但是这只是一种做法，调用者还是其他的更多的方式可以选择，比如调用者发现数据还没有准备好，那它可以把之前的数据排一个序什么的，这表示调用者在此刻是有选择做其他的事情的<strong>可能性</strong>的;</p>
<p>在思考阻塞和非阻塞的时候，需要先把角色分成为调用者与被调用者，这是一个很简单的一点，不要去思考被调用者内部是如何实现的，只需要在调用者与被调用者这个层面: <em>思考调用者调用的时候是否还有可能去做其他的事情为依据来进行区别</em>; 为什么要在同一个层面来看呢？因为层次不同得到的结果也不一样; 这里在举一个例子: 我封装了一个函数A，A内部的实现就是上面的实例代码，那A本身是否是阻塞呢？回答是:YES, 因为其他人在调用A时候，没有可能去做其他的事情了，这个时候它整体都在等待A的返回，所以这就是阻塞.</p>
<h5 id="同步与异步"><a href="#同步与异步" class="headerlink" title="同步与异步"></a>同步与异步</h5><ul>
<li>同步: 调用者为了获得结果，主动等待结果的返回(<strong>结果已经完成</strong>);</li>
<li>异步: 调用者获得的结果的方式被动通知，当接受到通知的时候就表示调用者需要的<strong>结果已经完成</strong>;</li>
</ul>
<p><code>结果已经完成</code>的定义是:调用者获得了一开始就想要的结果;</p>
<p>所以区别同步异步的关键点是在于:</p>
<ul>
<li>调用者是否主动等待</li>
<li>在被通知获得结果的时候，调用者想要获得结果是否已经完成</li>
</ul>
<p>按照上面的理论我们来分析几个调用是同步还是异步？还是分为两个角色:</p>
<ul>
<li>调用者</li>
<li>被调用者</li>
</ul>
<ol>
<li><p>read</p>
<p> 依然是上面的那个例子；当调用者调用read(被调用者)，这个时候调用者就主动在等待结果的返回，直到read返回，调用者才得到自己想要的东西; 所以是主动等待，所以这是同步操作</p>
</li>
<li><p>AIO(异步IO)</p>
<p> 应用层发起AIO操作之后，被调用者直接返回; 调用者这个时候就不在关心这个事情了; 当操作系统把数据准备好并且copy到对应的应用层内存之后，就会通过类似于事件通知的方式来通知应用程序; 这个过程中</p>
<ul>
<li>调用者是被动通知结果</li>
<li><p>调用者在收到通知的那时它想获得结果已经完成(需要读取的数据已经放在对应的应用层的内存中了)</p>
<p>所以AIO是异步的</p>
</li>
</ul>
</li>
<li><p>多路复用IO</p>
</li>
</ol>
<p>select、poll、epoll都是多路IO; 那么它们是同步还是异步呢？这可能是大部分人难以弄清楚的事情；而且很多文章本身也是没有搞清楚或者是错误的理论; 先说一个结果</p>
<blockquote>
<p>多路IO都是同步的</p>
</blockquote>
<p>下面分析一下原因:</p>
<p>通过多路IO本身是通过将读写事件注册到统一的地方，有内核通过某一种方式(select、poll、epoll的实现方式都不一样)来统一的做轮训，这样的好处就是一个线程管理多个连接; 如果不是这样的话每一个链接都需要阻塞，非常浪费资源; 但是从异步的两个关键点来说:</p>
<ul>
<li>多路IO是通知调用者的</li>
<li>多路IO在通知的时候，只是告诉你可以读写了，但没有真正的读写操作完成，还是需要调用者自己去完成读写操作;</li>
</ul>
<p>所以多路IO是同步,而非异步;</p>
<p>和阻塞非阻塞一样，同步与异步的也是有层次的划分的；就目前操作系统来说，真正的异步io就只有AIO，其他的IO都是同步IO，原因是不管怎么样从内核到应用层的内存copy都需要调用者自己也操作，所以都是同步io；但是如果将异步同步这个概念放宽一些，从不同层次上来思考的话，我们发现现在很多市面上的网络框架都能达到异步的一个概念；比如seastar、folly的future，node.js等，这些框架可能在实现上都不一样但是不管怎么样，在概念上都已经是异步了.</p>
<h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><p>个人感觉(对自己而言)思考的已经很清楚了；异步同步、阻塞非阻塞，虽然相关但是其实关注的维度是不一样的，所以谈论的过程中不要尝试混淆.</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;同步异步阻塞非阻塞这几个概念其实很早就出现在我的脑中，但是到现在为止都还是很难把它理解清楚，尤其是这几个概念总是会被混淆一起来讲。最近算是工作比较闲，在网上查询了大量的文章，发现一些人对这几个概念有着与众不同的解释，也正好能完美的解决我心中的疑云.&lt;/p&gt;
&lt;p&gt;先引用几个
    
    </summary>
    
    
  </entry>
  
</feed>
